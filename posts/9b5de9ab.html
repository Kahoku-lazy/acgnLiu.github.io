<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>yolov5:模型推理与使用 | Kahoku丶懒`Blong</title><meta name="keywords" content="Kahoku, OTaku, liuxingyu, 刘星宇"><meta name="author" content="刘星宇,283977856@qq.com"><meta name="copyright" content="刘星宇"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="YOLO: 使用detect.py 推理模型一、模型推理基本命令 bash命令 12# 控制台指令python detect.py  --weights &quot;模型文件&quot; --source &quot;输入文件&quot; --class_dir &quot;输出文件&quot; --conf-thres 0.8  命令解析  detect.py:  python运行的py文件名称">
<meta property="og:type" content="article">
<meta property="og:title" content="yolov5:模型推理与使用">
<meta property="og:url" content="https://acgnliu.github.io/posts/9b5de9ab.html">
<meta property="og:site_name" content="Kahoku丶懒&#96;Blong">
<meta property="og:description" content="YOLO: 使用detect.py 推理模型一、模型推理基本命令 bash命令 12# 控制台指令python detect.py  --weights &quot;模型文件&quot; --source &quot;输入文件&quot; --class_dir &quot;输出文件&quot; --conf-thres 0.8  命令解析  detect.py:  python运行的py文件名称">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://images2.alphacoders.com/691/691077.jpg">
<meta property="article:published_time" content="2023-03-16T13:21:29.000Z">
<meta property="article:modified_time" content="2023-03-16T13:24:04.965Z">
<meta property="article:author" content="刘星宇">
<meta property="article:tag" content="Kahoku, OTaku, liuxingyu, 刘星宇">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://images2.alphacoders.com/691/691077.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://acgnliu.github.io/posts/9b5de9ab"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'yolov5:模型推理与使用',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-03-16 21:24:04'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload="this.media='all'"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu@1.0.6/lib/clock.min.css" /><link rel="stylesheet" href="https://npm.elemecdn.com/anzhiyu-blog@2.0.4/css/runtime/runtime.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-wowjs/lib/animate.min.css" media="print" onload="this.media='screen'"><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script src="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"><link rel="alternate" href="/atom.xml" title="Kahoku丶懒`Blong" type="application/atom+xml">
</head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">7</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/bangumis/index.html"><i class="fa-fw fas fa-home"></i><span> 追番</span></a></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fas fa-envelope"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/fcircle/"><i class="fa-fw fas fa-circle"></i><span> 朋友圈</span></a></div><div class="menus_item"><a class="site-page" href="/flexcard"><span> flink_style</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://images2.alphacoders.com/691/691077.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Kahoku丶懒`Blong</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/bangumis/index.html"><i class="fa-fw fas fa-home"></i><span> 追番</span></a></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fas fa-envelope"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/fcircle/"><i class="fa-fw fas fa-circle"></i><span> 朋友圈</span></a></div><div class="menus_item"><a class="site-page" href="/flexcard"><span> flink_style</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">yolov5:模型推理与使用</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-03-16T13:21:29.000Z" title="发表于 2023-03-16 21:21:29">2023-03-16</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-03-16T13:24:04.965Z" title="更新于 2023-03-16 21:24:04">2023-03-16</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="yolov5:模型推理与使用"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="YOLO-使用detect-py-推理模型"><a href="#YOLO-使用detect-py-推理模型" class="headerlink" title="YOLO: 使用detect.py 推理模型"></a>YOLO: 使用detect.py 推理模型</h1><h3 id="一、模型推理基本命令"><a href="#一、模型推理基本命令" class="headerlink" title="一、模型推理基本命令"></a>一、模型推理基本命令</h3><ol>
<li><p><code>bash</code><strong>命令</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 控制台指令</span></span><br><span class="line">python detect.py  --weights <span class="string">&quot;模型文件&quot;</span> --<span class="built_in">source</span> <span class="string">&quot;输入文件&quot;</span> --class_dir <span class="string">&quot;输出文件&quot;</span> --conf-thres 0.8</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>命令解析</strong></p>
<ul>
<li><p><code>detect.py</code>:  python运行的py文件名称</p>
</li>
<li><p><code>--weights</code>： 需要推理的模型文件路径</p>
</li>
<li><p><code>--source</code>： 推理所需要的输入图片路径</p>
</li>
<li><p><code>--conf-thres:</code> 置信度阈值，建议初始设置为0.8</p>
</li>
<li><p><code>--class_dir</code>： 模型推理后输出文件路径<strong>（新增参数）</strong></p>
</li>
</ul>
</li>
</ol>
<h3 id="二、detect-py-训练参数解析"><a href="#二、detect-py-训练参数解析" class="headerlink" title="二、detect.py 训练参数解析"></a>二、detect.py 训练参数解析</h3><ol>
<li><p><strong>控制台常用输入参数解析</strong>：</p>
<ul>
<li><code>weights:</code>  模型文件（best.pt）</li>
<li><code>source:</code>  模型输入的数据，类型支持图片、视频与摄像头（摄像头：0）以及是rtsp等视频流,。</li>
<li><code>imgsz:</code> 网络输入图片大小, 默认的大小是640</li>
<li><code>conf-thres:</code> 置信度阈值， 默认为0.25</li>
<li><code>max-det:</code> 保留的最大检测框数量, 每张图片中检测目标的个数最多为1000类、</li>
<li><code>device:</code> 设置设备CPU/CUDA, 可以不用设置</li>
<li><code>save-txt:</code> 是否将预测的框坐标以txt文件形式保存, 默认False, 使用—save-txt 在路径runs/detect/exp<em>/labels/</em>.txt下生成每张图片预测的txt文件</li>
<li><code>save-conf:</code> 是否将置信度conf也保存到txt中, 默认False</li>
<li><code>classes:</code> 设置只保留某一部分类别, 形如0或者0 2 3, 使用—classes = n, 则在路径runs/detect/exp*/下保存的图片为n所对应的类别, 此时需要设置data</li>
</ul>
</li>
<li><p><code>detect.py</code> <strong>所有参数说明</strong> </p>
<ul>
<li><p><code>weights:</code> 训练的权重路径,可以使用自己训练的权重,也可以使用官网提供的权重 默认官网的权重yolov5s.pt(yolov5n.pt/yolov5s.pt/yolov5m.pt/yolov5l.pt/yolov5x.pt/区别在于网络的宽度和深度以此增加)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">ython path/to/detect.py --weights yolov5s.pt                 # PyTorch</span><br><span class="line">                                   yolov5s.torchscript        # TorchScript</span><br><span class="line">                                   yolov5s.onnx               # ONNX Runtime or OpenCV DNN with --dnn</span><br><span class="line">                                   yolov5s.xml                # OpenVINO</span><br><span class="line">                                    yolov5s.engine             # TensorRT</span><br><span class="line">                                    yolov5s.mlmodel            # CoreML (MacOS-only)</span><br><span class="line">                                    yolov5s_saved_model        # TensorFlow SavedModel</span><br><span class="line">                                    yolov5s.pb                 # TensorFlow GraphDef</span><br><span class="line">                                    yolov5s.tflite             # TensorFlow Lite</span><br><span class="line">                                    yolov5s_edgetpu.tflite     # TensorFlow Edge TPU</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ol>
<ul>
<li><p><code>source:</code> 测试数据，可以是图片/视频路径，也可以是’0’(电脑自带摄像头),也可以是rtsp等视频流, 默认data/images</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">python path/to/detect.py --weights yolov5s.pt --source 0              # webcam # 直播软件/电脑摄像头</span><br><span class="line">                                                       img.jpg        # image</span><br><span class="line">                                                       vid.mp4        # video</span><br><span class="line">                                                        path/          # directory</span><br><span class="line">                                                       path/*.jpg     # glob</span><br><span class="line">                                                       &#x27;https://youtu.be/Zgi9g1ksQHc&#x27;  # YouTube</span><br><span class="line">                                                        &#x27;rtsp://example.com/media.mp4&#x27;  # RTSP, </span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li><p><code>data:</code> 配置数据文件路径, 包括image/label/classes等信息, 训练自己的文件, 需要作相应更改, 可以不用管</p>
<pre><code>如果设置了只显示个别类别即使用了--classes = 0 或二者1, 2, 3等, 则需要设置该文件，数字和类别相对应才能只检测某一个类
</code></pre></li>
<li><p><code>imgsz:</code> 网络输入图片大小, 默认的大小是640</p>
</li>
<li><p><code>conf-thres:</code> 置信度阈值， 默认为0.25</p>
</li>
<li><p><code>iou-thres:</code>  做nms的iou阈值, 默认为0.45</p>
</li>
<li><p><code>max-det:</code> 保留的最大检测框数量, 每张图片中检测目标的个数最多为1000类</p>
</li>
<li><p><code>device:</code> 设置设备CPU/CUDA, 可以不用设置</p>
</li>
<li><p><code>view-img:</code> 是否展示预测之后的图片/视频, 默认False, —view-img 电脑界面出现图片或者视频检测结果</p>
</li>
<li><p><code>save-txt:</code> 是否将预测的框坐标以txt文件形式保存, 默认False, 使用—save-txt 在路径runs/detect/exp<em>/labels/</em>.txt下生成每张图片预测的txt文件</p>
</li>
<li><p><code>save-conf:</code> 是否将置信度conf也保存到txt中, 默认False</p>
</li>
<li><p><code>save-crop:</code> 是否保存裁剪预测框图片, 默认为False, 使用—save-crop 在runs/detect/exp*/crop/剪切类别文件夹/ 路径下会保存每个接下来的目标</p>
</li>
<li><p><code>nosave:</code> 不保存图片、视频, 要保存图片，不设置—nosave 在runs/detect/exp*/会出现预测的结果</p>
</li>
<li><p><code>classes:</code> 设置只保留某一部分类别, 形如0或者0 2 3, 使用—classes = n, 则在路径runs/detect/exp*/下保存的图片为n所对应的类别, 此时需要设置data</p>
</li>
<li><p><code>agnostic-nms:</code> 进行NMS去除不同类别之间的框, 默认False</p>
</li>
<li><p><code>augment:</code> TTA测试时增强/多尺度预测</p>
</li>
<li><p><code>visualize:</code> 是否可视化网络层输出特征</p>
</li>
<li><p><code>update:</code> 如果为True,则对所有模型进行strip_optimizer操作,去除pt文件中的优化器等信息,默认为False</p>
</li>
<li><p><code>project:</code>保存测试日志的文件夹路径</p>
</li>
<li><p><code>name:</code>保存测试日志文件夹的名字, 所以最终是保存在project/name中</p>
</li>
<li><p><code>exist_ok:</code> 是否重新创建日志文件, False时重新创建文件</p>
</li>
<li><p><code>line-thickness:</code> 画框的线条粗细</p>
</li>
<li><p><code>hide-labels:</code> 可视化时隐藏预测类别</p>
</li>
<li><p><code>hide-conf:</code> 可视化时隐藏置信度</p>
</li>
<li><p><code>half:</code> 是否使用F16精度推理, 半进度提高检测速度</p>
</li>
<li><p><code>dnn:</code> 用OpenCV DNN预测</p>
</li>
<li><p><code>vid-stride:</code>  设置视频帧率  <strong>（新版本参数）</strong></p>
</li>
</ul>
<h3 id="三、detect-py-源码函数解析"><a href="#三、detect-py-源码函数解析" class="headerlink" title="三、detect.py 源码函数解析"></a>三、detect.py 源码函数解析</h3><ol>
<li><p>detect.py 代码解析<a target="_blank" rel="noopener" href="https://github.com/ultralytics/yolov5/blob/master/detect.py">github项目地址</a>，参考<a target="_blank" rel="noopener" href="https://blog.csdn.net/CharmsLUO/article/details/123422822?spm=1001.2014.3001.5506">代码注释参考</a> <a target="_blank" rel="noopener" href="https://blog.csdn.net/CharmsLUO">Charms@</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># YOLOv5 🚀 by Ultralytics, GPL-3.0 license</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;Run inference on images, videos, directories, streams, etc.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.backends.cudnn <span class="keyword">as</span> cudnn</span><br><span class="line"></span><br><span class="line">FILE = Path(__file__).resolve()</span><br><span class="line">ROOT = FILE.parents[<span class="number">0</span>]  <span class="comment"># YOLOv5 root directory</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">str</span>(ROOT) <span class="keyword">not</span> <span class="keyword">in</span> sys.path:</span><br><span class="line">    sys.path.append(<span class="built_in">str</span>(ROOT))  <span class="comment"># add ROOT to PATH</span></span><br><span class="line">ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  <span class="comment"># relative</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> models.common <span class="keyword">import</span> DetectMultiBackend</span><br><span class="line"><span class="keyword">from</span> utils.datasets <span class="keyword">import</span> IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams</span><br><span class="line"><span class="keyword">from</span> utils.general <span class="keyword">import</span> (LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr,</span><br><span class="line">                           increment_path, non_max_suppression, print_args, scale_coords, strip_optimizer, xyxy2xywh)</span><br><span class="line"><span class="keyword">from</span> utils.plots <span class="keyword">import</span> Annotator, colors, save_one_box</span><br><span class="line"><span class="keyword">from</span> utils.torch_utils <span class="keyword">import</span> select_device, time_sync</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测不更新梯度</span></span><br><span class="line"><span class="meta">@torch.no_grad()</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">weights=ROOT / <span class="string">&#x27;yolov5s.pt&#x27;</span>,  <span class="comment"># model.pt path(s) # 权重文件地址 默认 weights/可以是自己的路径</span></span></span><br><span class="line"><span class="params">        source=ROOT / <span class="string">&#x27;data/images&#x27;</span>,  <span class="comment"># file/dir/URL/glob, 0 for webcam 0 自带电脑摄像头， 默认data/images/</span></span></span><br><span class="line"><span class="params">        data=ROOT / <span class="string">&#x27;data/coco128.yaml&#x27;</span>,  <span class="comment"># dataset.yaml path, data文件路径，包括类别/图片/标签等信息</span></span></span><br><span class="line"><span class="params">        imgsz=(<span class="params"><span class="number">640</span>, <span class="number">640</span></span>),  <span class="comment"># inference size (height, width) 输入图片的大小 默认640*640</span></span></span><br><span class="line"><span class="params">        conf_thres=<span class="number">0.25</span>,  <span class="comment"># confidence threshold # object置信度阈值 默认0.25  用在nms中</span></span></span><br><span class="line"><span class="params">        iou_thres=<span class="number">0.45</span>,  <span class="comment"># NMS IOU threshold # 做nms的iou阈值 默认0.45   用在nms中</span></span></span><br><span class="line"><span class="params">        max_det=<span class="number">1000</span>,  <span class="comment"># maximum detections per image 每张图片最多的目标数量  用在nms中 </span></span></span><br><span class="line"><span class="params">        device=<span class="string">&#x27;&#x27;</span>,  <span class="comment"># cuda device, i.e. 0 or 0,1,2,3 or cpu 设置代码执行的设备 cuda device, i.e. 0 or 0,1,2,3 or cpu</span></span></span><br><span class="line"><span class="params">        view_img=<span class="literal">False</span>,  <span class="comment"># show results 是否展示预测之后的图片或视频 默认False </span></span></span><br><span class="line"><span class="params">        save_txt=<span class="literal">False</span>,  <span class="comment"># save results to *.txt 是否将预测的框坐标以txt文件形式保存, 默认False, 使用--save-txt 在路径runs/detect/exp*/labels/*.txt下生成每张图片预测的txt文件</span></span></span><br><span class="line"><span class="params">        save_conf=<span class="literal">False</span>,  <span class="comment"># save confidences in --save-txt labels 是否将置信度conf也保存到txt中, 默认False</span></span></span><br><span class="line"><span class="params">        save_crop=<span class="literal">False</span>,  <span class="comment"># save cropped prediction boxes 是否保存裁剪预测框图片, 默认为False, 使用--save-crop 在runs/detect/exp*/crop/剪切类别文件夹/ 路径下会保存每个接下来的目标</span></span></span><br><span class="line"><span class="params">        nosave=<span class="literal">False</span>,  <span class="comment"># do not save images/videos 不保存图片、视频, 要保存图片，不设置--nosave 在runs/detect/exp*/会出现预测的结果</span></span></span><br><span class="line"><span class="params">        classes=<span class="literal">None</span>,  <span class="comment"># filter by class: --class 0, or --class 0 2 3 设置只保留某一部分类别, 形如0或者0 2 3, 使用--classes = n, 则在路径runs/detect/exp*/下保存的图片为n所对应的类别, 此时需要设置data</span></span></span><br><span class="line"><span class="params">        agnostic_nms=<span class="literal">False</span>,  <span class="comment"># class-agnostic NMS 进行NMS去除不同类别之间的框, 默认False</span></span></span><br><span class="line"><span class="params">        augment=<span class="literal">False</span>,  <span class="comment"># augmented inference TTA测试时增强/多尺度预测，可以提分</span></span></span><br><span class="line"><span class="params">        visualize=<span class="literal">False</span>,  <span class="comment"># visualize features 是否可视化网络层输出特征</span></span></span><br><span class="line"><span class="params">        update=<span class="literal">False</span>,  <span class="comment"># update all models 如果为True,则对所有模型进行strip_optimizer操作,去除pt文件中的优化器等信息,默认为False</span></span></span><br><span class="line"><span class="params">        project=ROOT / <span class="string">&#x27;runs/detect&#x27;</span>,  <span class="comment"># save results to project/name 保存测试日志的文件夹路径</span></span></span><br><span class="line"><span class="params">        name=<span class="string">&#x27;exp&#x27;</span>,  <span class="comment"># save results to project/name 每次实验的名称</span></span></span><br><span class="line"><span class="params">        exist_ok=<span class="literal">False</span>,  <span class="comment"># existing project/name ok, do not increment 是否重新创建日志文件, False时重新创建文件</span></span></span><br><span class="line"><span class="params">        line_thickness=<span class="number">3</span>,  <span class="comment"># bounding box thickness (pixels) 画框的线条粗细</span></span></span><br><span class="line"><span class="params">        hide_labels=<span class="literal">False</span>,  <span class="comment"># hide labels 可视化时隐藏预测类别</span></span></span><br><span class="line"><span class="params">        hide_conf=<span class="literal">False</span>,  <span class="comment"># hide confidences 可视化时隐藏置信度</span></span></span><br><span class="line"><span class="params">        half=<span class="literal">False</span>,  <span class="comment"># use FP16 half-precision inference 是否使用F16精度推理, 半进度提高检测速度</span></span></span><br><span class="line"><span class="params">        dnn=<span class="literal">False</span>,  <span class="comment"># use OpenCV DNN for ONNX inference 用OpenCV DNN预测</span></span></span><br><span class="line"><span class="params">        </span>):</span><br><span class="line">    <span class="comment">################################################# 1. 初始化配置 #####################################################</span></span><br><span class="line">    <span class="comment"># 输入的路径变为字符串</span></span><br><span class="line">    source = <span class="built_in">str</span>(source)</span><br><span class="line">    <span class="comment"># 是否保存图片和txt文件</span></span><br><span class="line">    save_img = <span class="keyword">not</span> nosave <span class="keyword">and</span> <span class="keyword">not</span> source.endswith(<span class="string">&#x27;.txt&#x27;</span>)  <span class="comment"># save inference images</span></span><br><span class="line">    <span class="comment"># 判断文件是否是视频流</span></span><br><span class="line">    <span class="comment"># Path()提取文件名 例如：Path(&quot;./data/test_images/bus.jpg&quot;) Path.name-&gt;bus.jpg Path.parent-&gt;./data/test_images Path.suffix-&gt;.jpg</span></span><br><span class="line">    is_file = Path(source).suffix[<span class="number">1</span>:] <span class="keyword">in</span> (IMG_FORMATS + VID_FORMATS) <span class="comment"># 提取文件后缀名是否符合要求的文件，例如：是否格式是jpg, png, asf, avi等</span></span><br><span class="line">    <span class="comment"># .lower()转化成小写 .upper()转化成大写 .title()首字符转化成大写，其余为小写, .startswith(&#x27;http://&#x27;)返回True or Flase</span></span><br><span class="line">    is_url = source.lower().startswith((<span class="string">&#x27;rtsp://&#x27;</span>, <span class="string">&#x27;rtmp://&#x27;</span>, <span class="string">&#x27;http://&#x27;</span>, <span class="string">&#x27;https://&#x27;</span>))</span><br><span class="line">    <span class="comment"># .isnumeric()是否是由数字组成，返回True or False</span></span><br><span class="line">    webcam = source.isnumeric() <span class="keyword">or</span> source.endswith(<span class="string">&#x27;.txt&#x27;</span>) <span class="keyword">or</span> (is_url <span class="keyword">and</span> <span class="keyword">not</span> is_file)</span><br><span class="line">    <span class="keyword">if</span> is_url <span class="keyword">and</span> is_file:</span><br><span class="line">        <span class="comment"># 返回文件</span></span><br><span class="line">        source = check_file(source)  <span class="comment"># download</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Directories</span></span><br><span class="line">    <span class="comment"># 预测路径是否存在，不存在新建，按照实验文件以此递增新建</span></span><br><span class="line">    save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)  <span class="comment"># increment run</span></span><br><span class="line">    (save_dir / <span class="string">&#x27;labels&#x27;</span> <span class="keyword">if</span> save_txt <span class="keyword">else</span> save_dir).mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)  <span class="comment"># make dir</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Load model</span></span><br><span class="line">    <span class="comment"># 获取设备 CPU/CUDA</span></span><br><span class="line">    device = select_device(device)</span><br><span class="line">    <span class="comment"># 检测编译框架PYTORCH/TENSORFLOW/TENSORRT</span></span><br><span class="line">    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data)</span><br><span class="line">    stride, names, pt, jit, onnx, engine = model.stride, model.names, model.pt, model.jit, model.onnx, model.engine</span><br><span class="line">    <span class="comment"># 确保输入图片的尺寸imgsz能整除stride=32 如果不能则调整为能被整除并返回</span></span><br><span class="line">    imgsz = check_img_size(imgsz, s=stride)  <span class="comment"># check image size</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Half</span></span><br><span class="line">    <span class="comment"># 如果不是CPU，使用半进度(图片半精度/模型半精度)</span></span><br><span class="line">    half &amp;= (pt <span class="keyword">or</span> jit <span class="keyword">or</span> onnx <span class="keyword">or</span> engine) <span class="keyword">and</span> device.<span class="built_in">type</span> != <span class="string">&#x27;cpu&#x27;</span>  <span class="comment"># FP16 supported on limited backends with CUDA</span></span><br><span class="line">    <span class="keyword">if</span> pt <span class="keyword">or</span> jit:</span><br><span class="line">        model.model.half() <span class="keyword">if</span> half <span class="keyword">else</span> model.model.<span class="built_in">float</span>()</span><br><span class="line">    <span class="comment"># TENSORRT加速</span></span><br><span class="line">    <span class="keyword">elif</span> engine <span class="keyword">and</span> model.trt_fp16_input != half:</span><br><span class="line">        LOGGER.info(<span class="string">&#x27;model &#x27;</span> + (</span><br><span class="line">            <span class="string">&#x27;requires&#x27;</span> <span class="keyword">if</span> model.trt_fp16_input <span class="keyword">else</span> <span class="string">&#x27;incompatible with&#x27;</span>) + <span class="string">&#x27; --half. Adjusting automatically.&#x27;</span>)</span><br><span class="line">        half = model.trt_fp16_input</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    <span class="comment">################################################# 2. 加载数据 #####################################################</span></span><br><span class="line">    <span class="comment"># Dataloader 加载数据</span></span><br><span class="line">    <span class="comment"># 使用视频流或者页面</span></span><br><span class="line">    <span class="keyword">if</span> webcam:</span><br><span class="line">        view_img = check_imshow()</span><br><span class="line">        cudnn.benchmark = <span class="literal">True</span>  <span class="comment"># set True to speed up constant image size inference</span></span><br><span class="line">        dataset = LoadStreams(source, img_size=imgsz, stride=stride, auto=pt)</span><br><span class="line">        bs = <span class="built_in">len</span>(dataset)  <span class="comment"># batch_size</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 直接从source文件下读取图片</span></span><br><span class="line">        dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt)</span><br><span class="line">        bs = <span class="number">1</span>  <span class="comment"># batch_size</span></span><br><span class="line">    <span class="comment"># 保存的路径</span></span><br><span class="line">    vid_path, vid_writer = [<span class="literal">None</span>] * bs, [<span class="literal">None</span>] * bs</span><br><span class="line"></span><br><span class="line">    <span class="comment">################################################# 3. 网络预测 #####################################################</span></span><br><span class="line">    <span class="comment"># Run inference</span></span><br><span class="line">    <span class="comment"># warmup 热身</span></span><br><span class="line">    model.warmup(imgsz=(<span class="number">1</span> <span class="keyword">if</span> pt <span class="keyword">else</span> bs, <span class="number">3</span>, *imgsz), half=half)  <span class="comment"># warmup</span></span><br><span class="line">    dt, seen = [<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>], <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> path, im, im0s, vid_cap, s <span class="keyword">in</span> dataset:</span><br><span class="line">        t1 = time_sync()</span><br><span class="line">        <span class="comment"># 转化到GPU上</span></span><br><span class="line">        im = torch.from_numpy(im).to(device)</span><br><span class="line">        <span class="comment"># 是否使用半精度</span></span><br><span class="line">        im = im.half() <span class="keyword">if</span> half <span class="keyword">else</span> im.<span class="built_in">float</span>()  <span class="comment"># uint8 to fp16/32</span></span><br><span class="line">        im /= <span class="number">255</span>  <span class="comment"># 0 - 255 to 0.0 - 1.0</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(im.shape) == <span class="number">3</span>:</span><br><span class="line">            <span class="comment"># 增加一个维度</span></span><br><span class="line">            im = im[<span class="literal">None</span>]  <span class="comment"># expand for batch dim</span></span><br><span class="line">        t2 = time_sync()</span><br><span class="line">        dt[<span class="number">0</span>] += t2 - t1</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Inference</span></span><br><span class="line">        <span class="comment"># 可是化文件路径</span></span><br><span class="line">        visualize = increment_path(save_dir / Path(path).stem, mkdir=<span class="literal">True</span>) <span class="keyword">if</span> visualize <span class="keyword">else</span> <span class="literal">False</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        pred.shape=(1, num_boxes, 5+num_class)</span></span><br><span class="line"><span class="string">        h,w为传入网络图片的长和宽,注意dataset在检测时使用了矩形推理,所以这里h不一定等于w</span></span><br><span class="line"><span class="string">        num_boxes = h/32 * w/32 + h/16 * w/16 + h/8 * w/8</span></span><br><span class="line"><span class="string">        pred[..., 0:4]为预测框坐标=预测框坐标为xywh(中心点+宽长)格式</span></span><br><span class="line"><span class="string">        pred[..., 4]为objectness置信度</span></span><br><span class="line"><span class="string">        pred[..., 5:-1]为分类结果</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        pred = model(im, augment=augment, visualize=visualize)</span><br><span class="line">        t3 = time_sync()</span><br><span class="line">        <span class="comment"># 预测的时间</span></span><br><span class="line">        dt[<span class="number">1</span>] += t3 - t2</span><br><span class="line"></span><br><span class="line">        <span class="comment"># NMS</span></span><br><span class="line">        <span class="comment"># 非极大值抑制</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        pred: 网络的输出结果</span></span><br><span class="line"><span class="string">        conf_thres:置信度阈值</span></span><br><span class="line"><span class="string">        ou_thres:iou阈值</span></span><br><span class="line"><span class="string">        classes: 是否只保留特定的类别</span></span><br><span class="line"><span class="string">        agnostic_nms: 进行nms是否也去除不同类别之间的框</span></span><br><span class="line"><span class="string">        max-det: 保留的最大检测框数量</span></span><br><span class="line"><span class="string">        ---NMS, 预测框格式: xywh(中心点+长宽)--&gt;xyxy(左上角右下角)</span></span><br><span class="line"><span class="string">        pred是一个列表list[torch.tensor], 长度为batch_size</span></span><br><span class="line"><span class="string">        每一个torch.tensor的shape为(num_boxes, 6), 内容为box + conf + cls</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)</span><br><span class="line">        <span class="comment"># 预测+NMS的时间</span></span><br><span class="line">        dt[<span class="number">2</span>] += time_sync() - t3</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Second-stage classifier (optional)</span></span><br><span class="line">        <span class="comment"># pred = utils.general.apply_classifier(pred, classifier_model, im, im0s)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Process predictions</span></span><br><span class="line">        <span class="comment"># 对每张图片做处理</span></span><br><span class="line">        <span class="keyword">for</span> i, det <span class="keyword">in</span> <span class="built_in">enumerate</span>(pred):  <span class="comment"># per image</span></span><br><span class="line">            seen += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> webcam:  <span class="comment"># batch_size &gt;= 1</span></span><br><span class="line">                <span class="comment"># 如果输入源是webcam则batch_size&gt;=1 取出dataset中的一张图片</span></span><br><span class="line">                p, im0, frame = path[i], im0s[i].copy(), dataset.count</span><br><span class="line">                s += <span class="string">f&#x27;<span class="subst">&#123;i&#125;</span>: &#x27;</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 但是大部分我们一般都是从LoadImages流读取本都文件中的照片或者视频 所以batch_size=1</span></span><br><span class="line">                <span class="comment"># p: 当前图片/视频的绝对路径 如 F:\yolo_v5\yolov5-U\data\images\bus.jpg</span></span><br><span class="line">                <span class="comment"># s: 输出信息 初始为 &#x27;&#x27;</span></span><br><span class="line">                <span class="comment"># im0: 原始图片 letterbox + pad 之前的图片</span></span><br><span class="line">                <span class="comment"># frame: 视频流</span></span><br><span class="line">                p, im0, frame = path, im0s.copy(), <span class="built_in">getattr</span>(dataset, <span class="string">&#x27;frame&#x27;</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 当前路径yolov5/data/images/</span></span><br><span class="line">            p = Path(p)  <span class="comment"># to Path</span></span><br><span class="line">            <span class="comment"># 图片/视频的保存路径save_path 如 runs\\detect\\exp8\\bus.jpg</span></span><br><span class="line">            save_path = <span class="built_in">str</span>(save_dir / p.name)  <span class="comment"># im.jpg</span></span><br><span class="line">            <span class="comment"># 设置保存框坐标的txt文件路径，每张图片对应一个框坐标信息</span></span><br><span class="line">            txt_path = <span class="built_in">str</span>(save_dir / <span class="string">&#x27;labels&#x27;</span> / p.stem) + (<span class="string">&#x27;&#x27;</span> <span class="keyword">if</span> dataset.mode == <span class="string">&#x27;image&#x27;</span> <span class="keyword">else</span> <span class="string">f&#x27;_<span class="subst">&#123;frame&#125;</span>&#x27;</span>)  <span class="comment"># im.txt</span></span><br><span class="line">            <span class="comment"># 设置打印图片的信息</span></span><br><span class="line">            s += <span class="string">&#x27;%gx%g &#x27;</span> % im.shape[<span class="number">2</span>:]  <span class="comment"># print string</span></span><br><span class="line">            gn = torch.tensor(im0.shape)[[<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]]  <span class="comment"># normalization gain whwh</span></span><br><span class="line">            <span class="comment"># 保存截图</span></span><br><span class="line">            imc = im0.copy() <span class="keyword">if</span> save_crop <span class="keyword">else</span> im0  <span class="comment"># for save_crop</span></span><br><span class="line">            annotator = Annotator(im0, line_width=line_thickness, example=<span class="built_in">str</span>(names))</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(det):</span><br><span class="line">                <span class="comment"># Rescale boxes from img_size to im0 size</span></span><br><span class="line">                <span class="comment"># 将预测信息映射到原图</span></span><br><span class="line">                det[:, :<span class="number">4</span>] = scale_coords(im.shape[<span class="number">2</span>:], det[:, :<span class="number">4</span>], im0.shape).<span class="built_in">round</span>()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Print results</span></span><br><span class="line">                <span class="comment"># 打印检测到的类别数量</span></span><br><span class="line">                <span class="keyword">for</span> c <span class="keyword">in</span> det[:, -<span class="number">1</span>].unique():</span><br><span class="line">                    n = (det[:, -<span class="number">1</span>] == c).<span class="built_in">sum</span>()  <span class="comment"># detections per class</span></span><br><span class="line">                    s += <span class="string">f&quot;<span class="subst">&#123;n&#125;</span> <span class="subst">&#123;names[<span class="built_in">int</span>(c)]&#125;</span><span class="subst">&#123;<span class="string">&#x27;s&#x27;</span> * (n &gt; <span class="number">1</span>)&#125;</span>, &quot;</span>  <span class="comment"># add to string</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># Write results</span></span><br><span class="line">                <span class="comment"># 保存结果： txt/图片画框/crop-image</span></span><br><span class="line">                <span class="keyword">for</span> *xyxy, conf, cls <span class="keyword">in</span> <span class="built_in">reversed</span>(det):</span><br><span class="line">                    <span class="comment"># 将每个图片的预测信息分别存入save_dir/labels下的xxx.txt中 每行: class_id + score + xywh</span></span><br><span class="line">                    <span class="keyword">if</span> save_txt:  <span class="comment"># Write to file</span></span><br><span class="line">                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(<span class="number">1</span>, <span class="number">4</span>)) / gn).view(-<span class="number">1</span>).tolist()  <span class="comment"># normalized xywh</span></span><br><span class="line">                        line = (cls, *xywh, conf) <span class="keyword">if</span> save_conf <span class="keyword">else</span> (cls, *xywh)  <span class="comment"># label format</span></span><br><span class="line">                        <span class="keyword">with</span> <span class="built_in">open</span>(txt_path + <span class="string">&#x27;.txt&#x27;</span>, <span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                            f.write((<span class="string">&#x27;%g &#x27;</span> * <span class="built_in">len</span>(line)).rstrip() % line + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">                    <span class="comment"># # 在原图上画框 + 将预测到的目标剪切出来 保存成图片 保存在save_dir/crops下 在原图像画图或者保存结果</span></span><br><span class="line">                    <span class="keyword">if</span> save_img <span class="keyword">or</span> save_crop <span class="keyword">or</span> view_img:  <span class="comment"># Add bbox to image</span></span><br><span class="line">                        c = <span class="built_in">int</span>(cls)  <span class="comment"># integer class</span></span><br><span class="line">                        label = <span class="literal">None</span> <span class="keyword">if</span> hide_labels <span class="keyword">else</span> (names[c] <span class="keyword">if</span> hide_conf <span class="keyword">else</span> <span class="string">f&#x27;<span class="subst">&#123;names[c]&#125;</span> <span class="subst">&#123;conf:<span class="number">.2</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">                        annotator.box_label(xyxy, label, color=colors(c, <span class="literal">True</span>))</span><br><span class="line">                        <span class="keyword">if</span> save_crop:</span><br><span class="line">                            <span class="comment"># 在原图上画框 + 将预测到的目标剪切出来 保存成图片 保存在save_dir/crops下</span></span><br><span class="line">                            save_one_box(xyxy, imc, file=save_dir / <span class="string">&#x27;crops&#x27;</span> / names[c] / <span class="string">f&#x27;<span class="subst">&#123;p.stem&#125;</span>.jpg&#x27;</span>, BGR=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Stream results</span></span><br><span class="line">            im0 = annotator.result()</span><br><span class="line">            <span class="comment"># 显示图片</span></span><br><span class="line">            <span class="keyword">if</span> view_img:</span><br><span class="line">                cv2.imshow(<span class="built_in">str</span>(p), im0)</span><br><span class="line">                cv2.waitKey(<span class="number">1</span>)  <span class="comment"># 1 millisecond</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Save results (image with detections)</span></span><br><span class="line">            <span class="comment"># 保存图片</span></span><br><span class="line">            <span class="keyword">if</span> save_img:</span><br><span class="line">                <span class="keyword">if</span> dataset.mode == <span class="string">&#x27;image&#x27;</span>:</span><br><span class="line">                    cv2.imwrite(save_path, im0)</span><br><span class="line">                <span class="keyword">else</span>:  <span class="comment"># &#x27;video&#x27; or &#x27;stream&#x27;</span></span><br><span class="line">                    <span class="keyword">if</span> vid_path[i] != save_path:  <span class="comment"># new video</span></span><br><span class="line">                        vid_path[i] = save_path</span><br><span class="line">                        <span class="keyword">if</span> <span class="built_in">isinstance</span>(vid_writer[i], cv2.VideoWriter):</span><br><span class="line">                            vid_writer[i].release()  <span class="comment"># release previous video writer</span></span><br><span class="line">                        <span class="keyword">if</span> vid_cap:  <span class="comment"># video</span></span><br><span class="line">                            fps = vid_cap.get(cv2.CAP_PROP_FPS)</span><br><span class="line">                            w = <span class="built_in">int</span>(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))</span><br><span class="line">                            h = <span class="built_in">int</span>(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))</span><br><span class="line">                        <span class="keyword">else</span>:  <span class="comment"># stream</span></span><br><span class="line">                            fps, w, h = <span class="number">30</span>, im0.shape[<span class="number">1</span>], im0.shape[<span class="number">0</span>]</span><br><span class="line">                        save_path = <span class="built_in">str</span>(Path(save_path).with_suffix(<span class="string">&#x27;.mp4&#x27;</span>))  <span class="comment"># force *.mp4 suffix on results videos</span></span><br><span class="line">                        vid_writer[i] = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*<span class="string">&#x27;mp4v&#x27;</span>), fps, (w, h))</span><br><span class="line">                    vid_writer[i].write(im0)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Print time (inference-only)</span></span><br><span class="line">        LOGGER.info(<span class="string">f&#x27;<span class="subst">&#123;s&#125;</span>Done. (<span class="subst">&#123;t3 - t2:<span class="number">.3</span>f&#125;</span>s)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Print results</span></span><br><span class="line">    <span class="comment"># 打印每张图片的速度</span></span><br><span class="line">    t = <span class="built_in">tuple</span>(x / seen * <span class="number">1E3</span> <span class="keyword">for</span> x <span class="keyword">in</span> dt)  <span class="comment"># speeds per image</span></span><br><span class="line">    LOGGER.info(<span class="string">f&#x27;Speed: %.1fms pre-process, %.1fms inference, %.1fms NMS per image at shape <span class="subst">&#123;(<span class="number">1</span>, <span class="number">3</span>, *imgsz)&#125;</span>&#x27;</span> % t)</span><br><span class="line">    <span class="comment"># 保存图片或者txt</span></span><br><span class="line">    <span class="keyword">if</span> save_txt <span class="keyword">or</span> save_img:</span><br><span class="line">        s = <span class="string">f&quot;\n<span class="subst">&#123;<span class="built_in">len</span>(<span class="built_in">list</span>(save_dir.glob(<span class="string">&#x27;labels/*.txt&#x27;</span>)))&#125;</span> labels saved to <span class="subst">&#123;save_dir / <span class="string">&#x27;labels&#x27;</span>&#125;</span>&quot;</span> <span class="keyword">if</span> save_txt <span class="keyword">else</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line">        LOGGER.info(<span class="string">f&quot;Results saved to <span class="subst">&#123;colorstr(<span class="string">&#x27;bold&#x27;</span>, save_dir)&#125;</span><span class="subst">&#123;s&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> update:</span><br><span class="line">        strip_optimizer(weights)  <span class="comment"># update model (to fix SourceChangeWarning)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_opt</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    weights: 训练的权重路径,可以使用自己训练的权重,也可以使用官网提供的权重</span></span><br><span class="line"><span class="string">    默认官网的权重yolov5s.pt(yolov5n.pt/yolov5s.pt/yolov5m.pt/yolov5l.pt/yolov5x.pt/区别在于网络的宽度和深度以此增加)</span></span><br><span class="line"><span class="string">    source: 测试数据，可以是图片/视频路径，也可以是&#x27;0&#x27;(电脑自带摄像头),也可以是rtsp等视频流, 默认data/images</span></span><br><span class="line"><span class="string">    data: 配置数据文件路径, 包括image/label/classes等信息, 训练自己的文件, 需要作相应更改, 可以不用管</span></span><br><span class="line"><span class="string">    如果设置了只显示个别类别即使用了--classes = 0 或二者1, 2, 3等, 则需要设置该文件，数字和类别相对应才能只检测某一个类</span></span><br><span class="line"><span class="string">    imgsz: 网络输入图片大小, 默认的大小是640</span></span><br><span class="line"><span class="string">    conf-thres: 置信度阈值， 默认为0.25</span></span><br><span class="line"><span class="string">    iou-thres:  做nms的iou阈值, 默认为0.45</span></span><br><span class="line"><span class="string">    max-det: 保留的最大检测框数量, 每张图片中检测目标的个数最多为1000类</span></span><br><span class="line"><span class="string">    device: 设置设备CPU/CUDA, 可以不用设置</span></span><br><span class="line"><span class="string">    view-img: 是否展示预测之后的图片/视频, 默认False, --view-img 电脑界面出现图片或者视频检测结果</span></span><br><span class="line"><span class="string">    save-txt: 是否将预测的框坐标以txt文件形式保存, 默认False, 使用--save-txt 在路径runs/detect/exp*/labels/*.txt下生成每张图片预测的txt文件</span></span><br><span class="line"><span class="string">    save-conf: 是否将置信度conf也保存到txt中, 默认False</span></span><br><span class="line"><span class="string">    save-crop: 是否保存裁剪预测框图片, 默认为False, 使用--save-crop 在runs/detect/exp*/crop/剪切类别文件夹/ 路径下会保存每个接下来的目标</span></span><br><span class="line"><span class="string">    nosave: 不保存图片、视频, 要保存图片，不设置--nosave 在runs/detect/exp*/会出现预测的结果</span></span><br><span class="line"><span class="string">    classes: 设置只保留某一部分类别, 形如0或者0 2 3, 使用--classes = n, 则在路径runs/detect/exp*/下保存的图片为n所对应的类别, 此时需要设置data</span></span><br><span class="line"><span class="string">    agnostic-nms: 进行NMS去除不同类别之间的框, 默认False</span></span><br><span class="line"><span class="string">    augment: TTA测试时增强/多尺度预测, 可以提分</span></span><br><span class="line"><span class="string">    visualize: 是否可视化网络层输出特征</span></span><br><span class="line"><span class="string">    update: 如果为True,则对所有模型进行strip_optimizer操作,去除pt文件中的优化器等信息,默认为False</span></span><br><span class="line"><span class="string">    project: 保存测试日志的文件夹路径</span></span><br><span class="line"><span class="string">    name: 保存测试日志文件夹的名字, 所以最终是保存在project/name中</span></span><br><span class="line"><span class="string">    exist_ok: 是否重新创建日志文件, False时重新创建文件</span></span><br><span class="line"><span class="string">    line-thickness: 画框的线条粗细</span></span><br><span class="line"><span class="string">    hide-labels: 可视化时隐藏预测类别</span></span><br><span class="line"><span class="string">    hide-conf: 可视化时隐藏置信度</span></span><br><span class="line"><span class="string">    half: 是否使用F16精度推理, 半进度提高检测速度</span></span><br><span class="line"><span class="string">    dnn: 用OpenCV DNN预测</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--weights&#x27;</span>, nargs=<span class="string">&#x27;+&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=ROOT / <span class="string">&#x27;yolov5s.pt&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;model path(s)&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--source&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=ROOT / <span class="string">&#x27;data/images&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;file/dir/URL/glob, 0 for webcam&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--data&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=ROOT / <span class="string">&#x27;data/coco128.yaml&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;(optional) dataset.yaml path&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--imgsz&#x27;</span>, <span class="string">&#x27;--img&#x27;</span>, <span class="string">&#x27;--img-size&#x27;</span>, nargs=<span class="string">&#x27;+&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=[<span class="number">640</span>], <span class="built_in">help</span>=<span class="string">&#x27;inference size h,w&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--conf-thres&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.25</span>, <span class="built_in">help</span>=<span class="string">&#x27;confidence threshold&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--iou-thres&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.45</span>, <span class="built_in">help</span>=<span class="string">&#x27;NMS IoU threshold&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--max-det&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">1000</span>, <span class="built_in">help</span>=<span class="string">&#x27;maximum detections per image&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--device&#x27;</span>, default=<span class="string">&#x27;&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;cuda device, i.e. 0 or 0,1,2,3 or cpu&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--view-img&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;show results&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--save-txt&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;save results to *.txt&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--save-conf&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;save confidences in --save-txt labels&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--save-crop&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;save cropped prediction boxes&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--nosave&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;do not save images/videos&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--classes&#x27;</span>, nargs=<span class="string">&#x27;+&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;filter by class: --classes 0, or --classes 0 2 3&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--agnostic-nms&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;class-agnostic NMS&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--augment&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;augmented inference&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--visualize&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;visualize features&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--update&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;update all models&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--project&#x27;</span>, default=ROOT / <span class="string">&#x27;runs/detect&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;save results to project/name&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--name&#x27;</span>, default=<span class="string">&#x27;exp&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;save results to project/name&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--exist-ok&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;existing project/name ok, do not increment&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--line-thickness&#x27;</span>, default=<span class="number">3</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;bounding box thickness (pixels)&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--hide-labels&#x27;</span>, default=<span class="literal">False</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;hide labels&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--hide-conf&#x27;</span>, default=<span class="literal">False</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;hide confidences&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--half&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;use FP16 half-precision inference&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--dnn&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;use OpenCV DNN for ONNX inference&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    opt = parser.parse_args()</span><br><span class="line">    <span class="comment"># 扩充维度, 如果是一位就扩充一位</span></span><br><span class="line">    opt.imgsz *= <span class="number">2</span> <span class="keyword">if</span> <span class="built_in">len</span>(opt.imgsz) == <span class="number">1</span> <span class="keyword">else</span> <span class="number">1</span>  <span class="comment"># expand</span></span><br><span class="line">    <span class="comment"># 输出所有参数</span></span><br><span class="line">    print_args(FILE.stem, opt)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> opt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">opt</span>):</span><br><span class="line">    <span class="comment"># 检查环境/打印参数,主要是requrement.txt的包是否安装，用彩色显示设置的参数</span></span><br><span class="line">    check_requirements(exclude=(<span class="string">&#x27;tensorboard&#x27;</span>, <span class="string">&#x27;thop&#x27;</span>))</span><br><span class="line">    <span class="comment"># 执行run()函数</span></span><br><span class="line">    run(**<span class="built_in">vars</span>(opt))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    opt = parse_opt()</span><br><span class="line">    main(opt)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>parse_opt（）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">parse_opt</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    weights: 训练的权重路径,可以使用自己训练的权重,也可以使用官网提供的权重</span></span><br><span class="line"><span class="string">    默认官网的权重yolov5s.pt(yolov5n.pt/yolov5s.pt/yolov5m.pt/yolov5l.pt/yolov5x.pt/区别在于网络的宽度和深度以此增加)</span></span><br><span class="line"><span class="string">    source: 测试数据，可以是图片/视频路径，也可以是&#x27;0&#x27;(电脑自带摄像头),也可以是rtsp等视频流, 默认data/images</span></span><br><span class="line"><span class="string">    data: 配置数据文件路径, 包括image/label/classes等信息, 训练自己的文件, 需要作相应更改, 可以不用管</span></span><br><span class="line"><span class="string">    如果设置了只显示个别类别即使用了--classes = 0 或二者1, 2, 3等, 则需要设置该文件，数字和类别相对应才能只检测某一个类</span></span><br><span class="line"><span class="string">    imgsz: 网络输入图片大小, 默认的大小是640</span></span><br><span class="line"><span class="string">    conf-thres: 置信度阈值， 默认为0.25</span></span><br><span class="line"><span class="string">    iou-thres:  做nms的iou阈值, 默认为0.45</span></span><br><span class="line"><span class="string">    max-det: 保留的最大检测框数量, 每张图片中检测目标的个数最多为1000类</span></span><br><span class="line"><span class="string">    device: 设置设备CPU/CUDA, 可以不用设置</span></span><br><span class="line"><span class="string">    view-img: 是否展示预测之后的图片/视频, 默认False, --view-img 电脑界面出现图片或者视频检测结果</span></span><br><span class="line"><span class="string">    save-txt: 是否将预测的框坐标以txt文件形式保存, 默认False, 使用--save-txt 在路径runs/detect/exp*/labels/*.txt下生成每张图片预测的txt文件</span></span><br><span class="line"><span class="string">    save-conf: 是否将置信度conf也保存到txt中, 默认False</span></span><br><span class="line"><span class="string">    save-crop: 是否保存裁剪预测框图片, 默认为False, 使用--save-crop 在runs/detect/exp*/crop/剪切类别文件夹/ 路径下会保存每个接下来的目标</span></span><br><span class="line"><span class="string">    nosave: 不保存图片、视频, 要保存图片，不设置--nosave 在runs/detect/exp*/会出现预测的结果</span></span><br><span class="line"><span class="string">    classes: 设置只保留某一部分类别, 形如0或者0 2 3, 使用--classes = n, 则在路径runs/detect/exp*/下保存的图片为n所对应的类别, 此时需要设置data</span></span><br><span class="line"><span class="string">    agnostic-nms: 进行NMS去除不同类别之间的框, 默认False</span></span><br><span class="line"><span class="string">    augment: TTA测试时增强/多尺度预测</span></span><br><span class="line"><span class="string">    visualize: 是否可视化网络层输出特征</span></span><br><span class="line"><span class="string">    update: 如果为True,则对所有模型进行strip_optimizer操作,去除pt文件中的优化器等信息,默认为False</span></span><br><span class="line"><span class="string">    project:保存测试日志的文件夹路径</span></span><br><span class="line"><span class="string">    name:保存测试日志文件夹的名字, 所以最终是保存在project/name中</span></span><br><span class="line"><span class="string">    exist_ok: 是否重新创建日志文件, False时重新创建文件</span></span><br><span class="line"><span class="string">    line-thickness: 画框的线条粗细</span></span><br><span class="line"><span class="string">    hide-labels: 可视化时隐藏预测类别</span></span><br><span class="line"><span class="string">    hide-conf: 可视化时隐藏置信度</span></span><br><span class="line"><span class="string">    half: 是否使用F16精度推理, 半进度提高检测速度</span></span><br><span class="line"><span class="string">    dnn: 用OpenCV DNN预测</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--weights&#x27;</span>, nargs=<span class="string">&#x27;+&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=ROOT / <span class="string">&#x27;yolov5s.pt&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;model path(s)&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--source&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=ROOT / <span class="string">&#x27;data/images&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;file/dir/URL/glob, 0 for webcam&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--data&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=ROOT / <span class="string">&#x27;data/coco128.yaml&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;(optional) dataset.yaml path&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--imgsz&#x27;</span>, <span class="string">&#x27;--img&#x27;</span>, <span class="string">&#x27;--img-size&#x27;</span>, nargs=<span class="string">&#x27;+&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=[<span class="number">640</span>], <span class="built_in">help</span>=<span class="string">&#x27;inference size h,w&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--conf-thres&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.25</span>, <span class="built_in">help</span>=<span class="string">&#x27;confidence threshold&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--iou-thres&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.45</span>, <span class="built_in">help</span>=<span class="string">&#x27;NMS IoU threshold&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--max-det&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">1000</span>, <span class="built_in">help</span>=<span class="string">&#x27;maximum detections per image&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--device&#x27;</span>, default=<span class="string">&#x27;&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;cuda device, i.e. 0 or 0,1,2,3 or cpu&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--view-img&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;show results&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--save-txt&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;save results to *.txt&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--save-conf&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;save confidences in --save-txt labels&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--save-crop&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;save cropped prediction boxes&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--nosave&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;do not save images/videos&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--classes&#x27;</span>, nargs=<span class="string">&#x27;+&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;filter by class: --classes 0, or --classes 0 2 3&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--agnostic-nms&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;class-agnostic NMS&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--augment&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;augmented inference&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--visualize&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;visualize features&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--update&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;update all models&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--project&#x27;</span>, default=ROOT / <span class="string">&#x27;runs/detect&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;save results to project/name&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--name&#x27;</span>, default=<span class="string">&#x27;exp&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;save results to project/name&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--exist-ok&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;existing project/name ok, do not increment&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--line-thickness&#x27;</span>, default=<span class="number">3</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;bounding box thickness (pixels)&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--hide-labels&#x27;</span>, default=<span class="literal">False</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;hide labels&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--hide-conf&#x27;</span>, default=<span class="literal">False</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;hide confidences&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--half&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;use FP16 half-precision inference&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--dnn&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;use OpenCV DNN for ONNX inference&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    opt = parser.parse_args()</span><br><span class="line">    <span class="comment"># 扩充维度, 如果是一位就扩充一位</span></span><br><span class="line">    opt.imgsz *= <span class="number">2</span> <span class="keyword">if</span> <span class="built_in">len</span>(opt.imgsz) == <span class="number">1</span> <span class="keyword">else</span> <span class="number">1</span>  <span class="comment"># expand</span></span><br><span class="line">    <span class="comment"># 输出所有参数</span></span><br><span class="line">    print_args(FILE.stem, opt)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> opt</span><br></pre></td></tr></table></figure>
</li>
<li><p>main()</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">opt</span>):</span><br><span class="line">    <span class="comment"># 检查环境/打印参数,主要是requrement.txt的包是否安装，用彩色显示设置的参数</span></span><br><span class="line">    check_requirements(exclude=(<span class="string">&#x27;tensorboard&#x27;</span>, <span class="string">&#x27;thop&#x27;</span>))</span><br><span class="line">    <span class="comment"># 执行run()函数</span></span><br><span class="line">    run(**<span class="built_in">vars</span>(opt))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>run()</p>
<ul>
<li><p>传入参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">weights=ROOT / <span class="string">&#x27;yolov5s.pt&#x27;</span>,  <span class="comment"># model.pt path(s) # 权重文件地址 默认 weights/可以是自己的路径</span></span></span><br><span class="line"><span class="params">        source=ROOT / <span class="string">&#x27;data/images&#x27;</span>,  <span class="comment"># file/dir/URL/glob, 0 for webcam 0 自带电脑摄像头， 默认data/images/</span></span></span><br><span class="line"><span class="params">        data=ROOT / <span class="string">&#x27;data/coco128.yaml&#x27;</span>,  <span class="comment"># dataset.yaml path, data文件路径，包括类别/图片/标签等信息</span></span></span><br><span class="line"><span class="params">        imgsz=(<span class="params"><span class="number">640</span>, <span class="number">640</span></span>),  <span class="comment"># inference size (height, width) 输入图片的大小 默认640*640</span></span></span><br><span class="line"><span class="params">        conf_thres=<span class="number">0.25</span>,  <span class="comment"># confidence threshold # object置信度阈值 默认0.25  用在nms中</span></span></span><br><span class="line"><span class="params">        iou_thres=<span class="number">0.45</span>,  <span class="comment"># NMS IOU threshold # 做nms的iou阈值 默认0.45   用在nms中</span></span></span><br><span class="line"><span class="params">        max_det=<span class="number">1000</span>,  <span class="comment"># maximum detections per image 每张图片最多的目标数量  用在nms中 </span></span></span><br><span class="line"><span class="params">        device=<span class="string">&#x27;&#x27;</span>,  <span class="comment"># cuda device, i.e. 0 or 0,1,2,3 or cpu 设置代码执行的设备 cuda device, i.e. 0 or 0,1,2,3 or cpu</span></span></span><br><span class="line"><span class="params">        view_img=<span class="literal">False</span>,  <span class="comment"># show results 是否展示预测之后的图片或视频 默认False </span></span></span><br><span class="line"><span class="params">        save_txt=<span class="literal">False</span>,  <span class="comment"># save results to *.txt 是否将预测的框坐标以txt文件形式保存, 默认False, 使用--save-txt 在路径runs/detect/exp*/labels/*.txt下生成每张图片预测的txt文件</span></span></span><br><span class="line"><span class="params">        save_conf=<span class="literal">False</span>,  <span class="comment"># save confidences in --save-txt labels 是否将置信度conf也保存到txt中, 默认False</span></span></span><br><span class="line"><span class="params">        save_crop=<span class="literal">False</span>,  <span class="comment"># save cropped prediction boxes 是否保存裁剪预测框图片, 默认为False, 使用--save-crop 在runs/detect/exp*/crop/剪切类别文件夹/ 路径下会保存每个接下来的目标</span></span></span><br><span class="line"><span class="params">        nosave=<span class="literal">False</span>,  <span class="comment"># do not save images/videos 不保存图片、视频, 要保存图片，不设置--nosave 在runs/detect/exp*/会出现预测的结果</span></span></span><br><span class="line"><span class="params">        classes=<span class="literal">None</span>,  <span class="comment"># filter by class: --class 0, or --class 0 2 3 设置只保留某一部分类别, 形如0或者0 2 3, 使用--classes = n, 则在路径runs/detect/exp*/下保存的图片为n所对应的类别, 此时需要设置data</span></span></span><br><span class="line"><span class="params">        agnostic_nms=<span class="literal">False</span>,  <span class="comment"># class-agnostic NMS 进行NMS去除不同类别之间的框, 默认False</span></span></span><br><span class="line"><span class="params">        augment=<span class="literal">False</span>,  <span class="comment"># augmented inference TTA测试时增强/多尺度预测，可以提分</span></span></span><br><span class="line"><span class="params">        visualize=<span class="literal">False</span>,  <span class="comment"># visualize features 是否可视化网络层输出特征</span></span></span><br><span class="line"><span class="params">        update=<span class="literal">False</span>,  <span class="comment"># update all models 如果为True,则对所有模型进行strip_optimizer操作,去除pt文件中的优化器等信息,默认为False</span></span></span><br><span class="line"><span class="params">        project=ROOT / <span class="string">&#x27;runs/detect&#x27;</span>,  <span class="comment"># save results to project/name 保存测试日志的文件夹路径</span></span></span><br><span class="line"><span class="params">        name=<span class="string">&#x27;exp&#x27;</span>,  <span class="comment"># save results to project/name 每次实验的名称</span></span></span><br><span class="line"><span class="params">        exist_ok=<span class="literal">False</span>,  <span class="comment"># existing project/name ok, do not increment 是否重新创建日志文件, False时重新创建文件</span></span></span><br><span class="line"><span class="params">        line_thickness=<span class="number">3</span>,  <span class="comment"># bounding box thickness (pixels) 画框的线条粗细</span></span></span><br><span class="line"><span class="params">        hide_labels=<span class="literal">False</span>,  <span class="comment"># hide labels 可视化时隐藏预测类别</span></span></span><br><span class="line"><span class="params">        hide_conf=<span class="literal">False</span>,  <span class="comment"># hide confidences 可视化时隐藏置信度</span></span></span><br><span class="line"><span class="params">        half=<span class="literal">False</span>,  <span class="comment"># use FP16 half-precision inference 是否使用F16精度推理, 半进度提高检测速度</span></span></span><br><span class="line"><span class="params">        dnn=<span class="literal">False</span>,  <span class="comment"># use OpenCV DNN for ONNX inference 用OpenCV DNN预测</span></span></span><br><span class="line"><span class="params">        </span>):</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>初始化配置</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">################################################# 1. 初始化配置 #####################################################</span></span><br><span class="line">    <span class="comment"># 输入的路径变为字符串</span></span><br><span class="line">    source = <span class="built_in">str</span>(source)</span><br><span class="line">    <span class="comment"># 是否保存图片和txt文件</span></span><br><span class="line">    save_img = <span class="keyword">not</span> nosave <span class="keyword">and</span> <span class="keyword">not</span> source.endswith(<span class="string">&#x27;.txt&#x27;</span>)  <span class="comment"># save inference images</span></span><br><span class="line">    <span class="comment"># 判断文件是否是视频流</span></span><br><span class="line">    <span class="comment"># Path()提取文件名 例如：Path(&quot;./data/test_images/bus.jpg&quot;) Path.name-&gt;bus.jpg Path.parent-&gt;./data/test_images Path.suffix-&gt;.jpg</span></span><br><span class="line">    is_file = Path(source).suffix[<span class="number">1</span>:] <span class="keyword">in</span> (IMG_FORMATS + VID_FORMATS) <span class="comment"># 提取文件后缀名是否符合要求的文件，例如：是否格式是jpg, png, asf, avi等</span></span><br><span class="line">    <span class="comment"># .lower()转化成小写 .upper()转化成大写 .title()首字符转化成大写，其余为小写, .startswith(&#x27;http://&#x27;)返回True or Flase</span></span><br><span class="line">    is_url = source.lower().startswith((<span class="string">&#x27;rtsp://&#x27;</span>, <span class="string">&#x27;rtmp://&#x27;</span>, <span class="string">&#x27;http://&#x27;</span>, <span class="string">&#x27;https://&#x27;</span>))</span><br><span class="line">    <span class="comment"># .isnumeric()是否是由数字组成，返回True or False</span></span><br><span class="line">    webcam = source.isnumeric() <span class="keyword">or</span> source.endswith(<span class="string">&#x27;.txt&#x27;</span>) <span class="keyword">or</span> (is_url <span class="keyword">and</span> <span class="keyword">not</span> is_file)</span><br><span class="line">    <span class="keyword">if</span> is_url <span class="keyword">and</span> is_file:</span><br><span class="line">        <span class="comment"># 返回文件</span></span><br><span class="line">        source = check_file(source)  <span class="comment"># download</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Directories</span></span><br><span class="line">    <span class="comment"># 预测路径是否存在，不存在新建，按照实验文件以此递增新建</span></span><br><span class="line">    save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)  <span class="comment"># increment run</span></span><br><span class="line">    (save_dir / <span class="string">&#x27;labels&#x27;</span> <span class="keyword">if</span> save_txt <span class="keyword">else</span> save_dir).mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)  <span class="comment"># make dir</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Load model</span></span><br><span class="line">    <span class="comment"># 获取设备 CPU/CUDA</span></span><br><span class="line">    device = select_device(device)</span><br><span class="line">    <span class="comment"># 检测编译框架PYTORCH/TENSORFLOW/TENSORRT</span></span><br><span class="line">    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data)</span><br><span class="line">    stride, names, pt, jit, onnx, engine = model.stride, model.names, model.pt, model.jit, model.onnx, model.engine</span><br><span class="line">    <span class="comment"># 确保输入图片的尺寸imgsz能整除stride=32 如果不能则调整为能被整除并返回</span></span><br><span class="line">    imgsz = check_img_size(imgsz, s=stride)  <span class="comment"># check image size</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Half</span></span><br><span class="line">    <span class="comment"># 如果不是CPU，使用半进度(图片半精度/模型半精度)</span></span><br><span class="line">    half &amp;= (pt <span class="keyword">or</span> jit <span class="keyword">or</span> onnx <span class="keyword">or</span> engine) <span class="keyword">and</span> device.<span class="built_in">type</span> != <span class="string">&#x27;cpu&#x27;</span>  <span class="comment"># FP16 supported on limited backends with CUDA</span></span><br><span class="line">    <span class="keyword">if</span> pt <span class="keyword">or</span> jit:</span><br><span class="line">        model.model.half() <span class="keyword">if</span> half <span class="keyword">else</span> model.model.<span class="built_in">float</span>()</span><br><span class="line">    <span class="comment"># TENSORRT加速</span></span><br><span class="line">    <span class="keyword">elif</span> engine <span class="keyword">and</span> model.trt_fp16_input != half:</span><br><span class="line">        LOGGER.info(<span class="string">&#x27;model &#x27;</span> + (</span><br><span class="line">            <span class="string">&#x27;requires&#x27;</span> <span class="keyword">if</span> model.trt_fp16_input <span class="keyword">else</span> <span class="string">&#x27;incompatible with&#x27;</span>) + <span class="string">&#x27; --half. Adjusting automatically.&#x27;</span>)</span><br><span class="line">        half = model.trt_fp16_input</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>加载数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">################################################# 2. 加载数据 #####################################################</span></span><br><span class="line">    <span class="comment"># Dataloader 加载数据</span></span><br><span class="line">    <span class="comment"># 使用视频流或者页面</span></span><br><span class="line">    <span class="keyword">if</span> webcam:</span><br><span class="line">        view_img = check_imshow()</span><br><span class="line">        cudnn.benchmark = <span class="literal">True</span>  <span class="comment"># set True to speed up constant image size inference</span></span><br><span class="line">        dataset = LoadStreams(source, img_size=imgsz, stride=stride, auto=pt)</span><br><span class="line">        bs = <span class="built_in">len</span>(dataset)  <span class="comment"># batch_size</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 直接从source文件下读取图片</span></span><br><span class="line">        dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt)</span><br><span class="line">        bs = <span class="number">1</span>  <span class="comment"># batch_size</span></span><br><span class="line">    <span class="comment"># 保存的路径</span></span><br><span class="line">    vid_path, vid_writer = [<span class="literal">None</span>] * bs, [<span class="literal">None</span>] * bs</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>输入预测</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">model.warmup(imgsz=(<span class="number">1</span> <span class="keyword">if</span> pt <span class="keyword">else</span> bs, <span class="number">3</span>, *imgsz), half=half)  <span class="comment"># warmup</span></span><br><span class="line">   dt, seen = [<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>], <span class="number">0</span></span><br><span class="line">   <span class="keyword">for</span> path, im, im0s, vid_cap, s <span class="keyword">in</span> dataset:</span><br><span class="line">       t1 = time_sync()</span><br><span class="line">       <span class="comment"># 转化到GPU上</span></span><br><span class="line">       im = torch.from_numpy(im).to(device)</span><br><span class="line">       <span class="comment"># 是否使用半精度</span></span><br><span class="line">       im = im.half() <span class="keyword">if</span> half <span class="keyword">else</span> im.<span class="built_in">float</span>()  <span class="comment"># uint8 to fp16/32</span></span><br><span class="line">       im /= <span class="number">255</span>  <span class="comment"># 0 - 255 to 0.0 - 1.0</span></span><br><span class="line">       <span class="keyword">if</span> <span class="built_in">len</span>(im.shape) == <span class="number">3</span>:</span><br><span class="line">           <span class="comment"># 增加一个维度</span></span><br><span class="line">           im = im[<span class="literal">None</span>]  <span class="comment"># expand for batch dim</span></span><br><span class="line">       t2 = time_sync()</span><br><span class="line">       dt[<span class="number">0</span>] += t2 - t1</span><br><span class="line">     </span><br><span class="line">       <span class="comment"># Inference</span></span><br><span class="line">       <span class="comment"># 可是化文件路径</span></span><br><span class="line">       visualize = increment_path(save_dir / Path(path).stem, mkdir=<span class="literal">True</span>) <span class="keyword">if</span> visualize <span class="keyword">else</span> <span class="literal">False</span></span><br><span class="line">       <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">       pred.shape=(1, num_boxes, 5+num_class)</span></span><br><span class="line"><span class="string">       h,w为传入网络图片的长和宽,注意dataset在检测时使用了矩形推理,所以这里h不一定等于w</span></span><br><span class="line"><span class="string">       num_boxes = h/32 * w/32 + h/16 * w/16 + h/8 * w/8</span></span><br><span class="line"><span class="string">       pred[..., 0:4]为预测框坐标=预测框坐标为xywh(中心点+宽长)格式</span></span><br><span class="line"><span class="string">       pred[..., 4]为objectness置信度</span></span><br><span class="line"><span class="string">       pred[..., 5:-1]为分类结果</span></span><br><span class="line"><span class="string">       &quot;&quot;&quot;</span></span><br><span class="line">       pred = model(im, augment=augment, visualize=visualize)</span><br><span class="line">       t3 = time_sync()</span><br><span class="line">       <span class="comment"># 预测的时间</span></span><br><span class="line">       dt[<span class="number">1</span>] += t3 - t2</span><br><span class="line">     </span><br></pre></td></tr></table></figure>
</li>
<li><p>NMS</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># NMS</span></span><br><span class="line">      <span class="comment"># 非极大值抑制</span></span><br><span class="line">      <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">      pred: 网络的输出结果</span></span><br><span class="line"><span class="string">      conf_thres:置信度阈值</span></span><br><span class="line"><span class="string">      ou_thres:iou阈值</span></span><br><span class="line"><span class="string">      classes: 是否只保留特定的类别</span></span><br><span class="line"><span class="string">      agnostic_nms: 进行nms是否也去除不同类别之间的框</span></span><br><span class="line"><span class="string">      max-det: 保留的最大检测框数量</span></span><br><span class="line"><span class="string">      ---NMS, 预测框格式: xywh(中心点+长宽)--&gt;xyxy(左上角右下角)</span></span><br><span class="line"><span class="string">      pred是一个列表list[torch.tensor], 长度为batch_size</span></span><br><span class="line"><span class="string">      每一个torch.tensor的shape为(num_boxes, 6), 内容为box + conf + cls</span></span><br><span class="line"><span class="string">      &quot;&quot;&quot;</span></span><br><span class="line">      pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)</span><br><span class="line">      <span class="comment"># 预测+NMS的时间</span></span><br><span class="line">      dt[<span class="number">2</span>] += time_sync() - t3</span><br><span class="line">     </span><br></pre></td></tr></table></figure>
</li>
<li><p>保存打印</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Process predictions</span></span><br><span class="line">        <span class="comment"># 对每张图片做处理</span></span><br><span class="line">        <span class="keyword">for</span> i, det <span class="keyword">in</span> <span class="built_in">enumerate</span>(pred):  <span class="comment"># per image</span></span><br><span class="line">            seen += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> webcam:  <span class="comment"># batch_size &gt;= 1</span></span><br><span class="line">                <span class="comment"># 如果输入源是webcam则batch_size&gt;=1 取出dataset中的一张图片</span></span><br><span class="line">                p, im0, frame = path[i], im0s[i].copy(), dataset.count</span><br><span class="line">                s += <span class="string">f&#x27;<span class="subst">&#123;i&#125;</span>: &#x27;</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 但是大部分我们一般都是从LoadImages流读取本都文件中的照片或者视频 所以batch_size=1</span></span><br><span class="line">                <span class="comment"># p: 当前图片/视频的绝对路径 如 F:\yolo_v5\yolov5-U\data\images\bus.jpg</span></span><br><span class="line">                <span class="comment"># s: 输出信息 初始为 &#x27;&#x27;</span></span><br><span class="line">                <span class="comment"># im0: 原始图片 letterbox + pad 之前的图片</span></span><br><span class="line">                <span class="comment"># frame: 视频流</span></span><br><span class="line">                p, im0, frame = path, im0s.copy(), <span class="built_in">getattr</span>(dataset, <span class="string">&#x27;frame&#x27;</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 当前路径yolov5/data/images/</span></span><br><span class="line">            p = Path(p)  <span class="comment"># to Path</span></span><br><span class="line">            <span class="comment"># 图片/视频的保存路径save_path 如 runs\\detect\\exp8\\bus.jpg</span></span><br><span class="line">            save_path = <span class="built_in">str</span>(save_dir / p.name)  <span class="comment"># im.jpg</span></span><br><span class="line">            <span class="comment"># 设置保存框坐标的txt文件路径，每张图片对应一个框坐标信息</span></span><br><span class="line">            txt_path = <span class="built_in">str</span>(save_dir / <span class="string">&#x27;labels&#x27;</span> / p.stem) + (<span class="string">&#x27;&#x27;</span> <span class="keyword">if</span> dataset.mode == <span class="string">&#x27;image&#x27;</span> <span class="keyword">else</span> <span class="string">f&#x27;_<span class="subst">&#123;frame&#125;</span>&#x27;</span>)  <span class="comment"># im.txt</span></span><br><span class="line">            <span class="comment"># 设置打印图片的信息</span></span><br><span class="line">            s += <span class="string">&#x27;%gx%g &#x27;</span> % im.shape[<span class="number">2</span>:]  <span class="comment"># print string</span></span><br><span class="line">            gn = torch.tensor(im0.shape)[[<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]]  <span class="comment"># normalization gain whwh</span></span><br><span class="line">            <span class="comment"># 保存截图</span></span><br><span class="line">            imc = im0.copy() <span class="keyword">if</span> save_crop <span class="keyword">else</span> im0  <span class="comment"># for save_crop</span></span><br><span class="line">            annotator = Annotator(im0, line_width=line_thickness, example=<span class="built_in">str</span>(names))</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(det):</span><br><span class="line">                <span class="comment"># Rescale boxes from img_size to im0 size</span></span><br><span class="line">                <span class="comment"># 将预测信息映射到原图</span></span><br><span class="line">                det[:, :<span class="number">4</span>] = scale_coords(im.shape[<span class="number">2</span>:], det[:, :<span class="number">4</span>], im0.shape).<span class="built_in">round</span>()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Print results</span></span><br><span class="line">                <span class="comment"># 打印检测到的类别数量</span></span><br><span class="line">                <span class="keyword">for</span> c <span class="keyword">in</span> det[:, -<span class="number">1</span>].unique():</span><br><span class="line">                    n = (det[:, -<span class="number">1</span>] == c).<span class="built_in">sum</span>()  <span class="comment"># detections per class</span></span><br><span class="line">                    s += <span class="string">f&quot;<span class="subst">&#123;n&#125;</span> <span class="subst">&#123;names[<span class="built_in">int</span>(c)]&#125;</span><span class="subst">&#123;<span class="string">&#x27;s&#x27;</span> * (n &gt; <span class="number">1</span>)&#125;</span>, &quot;</span>  <span class="comment"># add to string</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># Write results</span></span><br><span class="line">                <span class="comment"># 保存结果： txt/图片画框/crop-image</span></span><br><span class="line">                <span class="keyword">for</span> *xyxy, conf, cls <span class="keyword">in</span> <span class="built_in">reversed</span>(det):</span><br><span class="line">                    <span class="comment"># 将每个图片的预测信息分别存入save_dir/labels下的xxx.txt中 每行: class_id + score + xywh</span></span><br><span class="line">                    <span class="keyword">if</span> save_txt:  <span class="comment"># Write to file</span></span><br><span class="line">                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(<span class="number">1</span>, <span class="number">4</span>)) / gn).view(-<span class="number">1</span>).tolist()  <span class="comment"># normalized xywh</span></span><br><span class="line">                        line = (cls, *xywh, conf) <span class="keyword">if</span> save_conf <span class="keyword">else</span> (cls, *xywh)  <span class="comment"># label format</span></span><br><span class="line">                        <span class="keyword">with</span> <span class="built_in">open</span>(txt_path + <span class="string">&#x27;.txt&#x27;</span>, <span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                            f.write((<span class="string">&#x27;%g &#x27;</span> * <span class="built_in">len</span>(line)).rstrip() % line + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">                    <span class="comment"># # 在原图上画框 + 将预测到的目标剪切出来 保存成图片 保存在save_dir/crops下 在原图像画图或者保存结果</span></span><br><span class="line">                    <span class="keyword">if</span> save_img <span class="keyword">or</span> save_crop <span class="keyword">or</span> view_img:  <span class="comment"># Add bbox to image</span></span><br><span class="line">                        c = <span class="built_in">int</span>(cls)  <span class="comment"># integer class</span></span><br><span class="line">                        label = <span class="literal">None</span> <span class="keyword">if</span> hide_labels <span class="keyword">else</span> (names[c] <span class="keyword">if</span> hide_conf <span class="keyword">else</span> <span class="string">f&#x27;<span class="subst">&#123;names[c]&#125;</span> <span class="subst">&#123;conf:<span class="number">.2</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">                        annotator.box_label(xyxy, label, color=colors(c, <span class="literal">True</span>))</span><br><span class="line">                        <span class="keyword">if</span> save_crop:</span><br><span class="line">                            <span class="comment"># 在原图上画框 + 将预测到的目标剪切出来 保存成图片 保存在save_dir/crops下</span></span><br><span class="line">                            save_one_box(xyxy, imc, file=save_dir / <span class="string">&#x27;crops&#x27;</span> / names[c] / <span class="string">f&#x27;<span class="subst">&#123;p.stem&#125;</span>.jpg&#x27;</span>, BGR=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Stream results</span></span><br><span class="line">            im0 = annotator.result()</span><br><span class="line">            <span class="comment"># 显示图片</span></span><br><span class="line">            <span class="keyword">if</span> view_img:</span><br><span class="line">                cv2.imshow(<span class="built_in">str</span>(p), im0)</span><br><span class="line">                cv2.waitKey(<span class="number">1</span>)  <span class="comment"># 1 millisecond</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Save results (image with detections)</span></span><br><span class="line">            <span class="comment"># 保存图片</span></span><br><span class="line">            <span class="keyword">if</span> save_img:</span><br><span class="line">                <span class="keyword">if</span> dataset.mode == <span class="string">&#x27;image&#x27;</span>:</span><br><span class="line">                    cv2.imwrite(save_path, im0)</span><br><span class="line">                <span class="keyword">else</span>:  <span class="comment"># &#x27;video&#x27; or &#x27;stream&#x27;</span></span><br><span class="line">                    <span class="keyword">if</span> vid_path[i] != save_path:  <span class="comment"># new video</span></span><br><span class="line">                        vid_path[i] = save_path</span><br><span class="line">                        <span class="keyword">if</span> <span class="built_in">isinstance</span>(vid_writer[i], cv2.VideoWriter):</span><br><span class="line">                            vid_writer[i].release()  <span class="comment"># release previous video writer</span></span><br><span class="line">                        <span class="keyword">if</span> vid_cap:  <span class="comment"># video</span></span><br><span class="line">                            fps = vid_cap.get(cv2.CAP_PROP_FPS)</span><br><span class="line">                            w = <span class="built_in">int</span>(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))</span><br><span class="line">                            h = <span class="built_in">int</span>(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))</span><br><span class="line">                        <span class="keyword">else</span>:  <span class="comment"># stream</span></span><br><span class="line">                            fps, w, h = <span class="number">30</span>, im0.shape[<span class="number">1</span>], im0.shape[<span class="number">0</span>]</span><br><span class="line">                        save_path = <span class="built_in">str</span>(Path(save_path).with_suffix(<span class="string">&#x27;.mp4&#x27;</span>))  <span class="comment"># force *.mp4 suffix on results videos</span></span><br><span class="line">                        vid_writer[i] = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*<span class="string">&#x27;mp4v&#x27;</span>), fps, (w, h))</span><br><span class="line">                    vid_writer[i].write(im0)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Print time (inference-only)</span></span><br><span class="line">        LOGGER.info(<span class="string">f&#x27;<span class="subst">&#123;s&#125;</span>Done. (<span class="subst">&#123;t3 - t2:<span class="number">.3</span>f&#125;</span>s)&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ol>
<h3 id="四、扩展使用方法"><a href="#四、扩展使用方法" class="headerlink" title="四、扩展使用方法"></a>四、扩展使用方法</h3><ol>
<li><strong>在</strong><code>python</code><strong>文件中运行</strong></li>
<li><strong>加入项目使用</strong></li>
</ol>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://acgnLiu.github.io">刘星宇</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://acgnliu.github.io/posts/9b5de9ab.html">https://acgnliu.github.io/posts/9b5de9ab.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://acgnLiu.github.io" target="_blank">Kahoku丶懒`Blong</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://images2.alphacoders.com/691/691077.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/posts/a58ad574.html"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://images8.alphacoders.com/831/831874.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">git:gitignore文件</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">刘星宇</div><div class="author-info__description">博客， 刘星宇，一个有趣的博客</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">7</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#YOLO-%E4%BD%BF%E7%94%A8detect-py-%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.</span> <span class="toc-text">YOLO: 使用detect.py 推理模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4"><span class="toc-number">1.0.1.</span> <span class="toc-text">一、模型推理基本命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E3%80%81detect-py-%E8%AE%AD%E7%BB%83%E5%8F%82%E6%95%B0%E8%A7%A3%E6%9E%90"><span class="toc-number">1.0.2.</span> <span class="toc-text">二、detect.py 训练参数解析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89%E3%80%81detect-py-%E6%BA%90%E7%A0%81%E5%87%BD%E6%95%B0%E8%A7%A3%E6%9E%90"><span class="toc-number">1.0.3.</span> <span class="toc-text">三、detect.py 源码函数解析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E6%89%A9%E5%B1%95%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95"><span class="toc-number">1.0.4.</span> <span class="toc-text">四、扩展使用方法</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/9b5de9ab.html" title="yolov5:模型推理与使用"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://images2.alphacoders.com/691/691077.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="yolov5:模型推理与使用"/></a><div class="content"><a class="title" href="/posts/9b5de9ab.html" title="yolov5:模型推理与使用">yolov5:模型推理与使用</a><time datetime="2023-03-16T13:21:29.000Z" title="发表于 2023-03-16 21:21:29">2023-03-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/a58ad574.html" title="git:gitignore文件"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://images8.alphacoders.com/831/831874.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="git:gitignore文件"/></a><div class="content"><a class="title" href="/posts/a58ad574.html" title="git:gitignore文件">git:gitignore文件</a><time datetime="2023-03-16T13:18:34.000Z" title="发表于 2023-03-16 21:18:34">2023-03-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/2e7109a8.html" title="yolov5环境搭建"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="hhttps://images8.alphacoders.com/130/1304675.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="yolov5环境搭建"/></a><div class="content"><a class="title" href="/posts/2e7109a8.html" title="yolov5环境搭建">yolov5环境搭建</a><time datetime="2023-03-16T13:16:07.000Z" title="发表于 2023-03-16 21:16:07">2023-03-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/2f57a694.html" title="正则表达式"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="正则表达式"/></a><div class="content"><a class="title" href="/posts/2f57a694.html" title="正则表达式">正则表达式</a><time datetime="2022-11-15T14:29:20.000Z" title="发表于 2022-11-15 22:29:20">2022-11-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/518e617c.html" title="git"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="git"/></a><div class="content"><a class="title" href="/posts/518e617c.html" title="git">git</a><time datetime="2022-11-14T15:57:00.000Z" title="发表于 2022-11-14 23:57:00">2022-11-14</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By 刘星宇</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"></div><script defer src="/live2d-widget/autoload.js"></script><div class="aplayer no-destroy" data-id="97819683" data-server="netease" data-type="playlist"   data-order="list" data-fixed="true" data-preload="auto" data-autoplay="false" data-mutex="true" ></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script>
    // 全局变量声明区域
    var fdata = {
      apiurl: 'https://hexo-friendcircle-api-ai9d4hwad-anzhiyu-c.vercel.app/api',
      initnumber: 20, //【可选】页面初始化展示文章数量
      stepnumber: 10, //【可选】每次加载增加的篇数
      error_img: 'https://npm.elemecdn.com/akilar-candyassets/image/404.gif' //【可选，头像图片加载失败时的默认头像】
    }
    //存入本地存储
    localStorage.setItem("fdatalist",JSON.stringify(fdata))
    </script>
    <script defer src="https://npm.elemecdn.com/hexo-filter-fcircle/assets/js/fetch.min.js"></script><script data-pjax>
  function butterfly_clock_anzhiyu_injector_config(){
    var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
    var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img class="entered loading" id="card-clock-loading" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu@1.0.6/lib/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading"/></div></div></div></div></div>';
    console.log('已挂载butterfly_clock_anzhiyu')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var qweather_key = 'ceef7ce646ed45bea5e477c13418cc97';
  var gaud_map_key = 'bd89fcc76ebb00e5832cdccdae513895';
  var baidu_ak_key = 'undefined';
  var flag = 0;
  var clock_rectangle = '112.6534116,27.96920845';
  var clock_default_rectangle_enable = 'false';

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_clock_anzhiyu_injector_config();
  }
  else if (epage === cpage){
    butterfly_clock_anzhiyu_injector_config();
  }
  </script><script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script><script data-pjax src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu@1.0.6/lib/clock.min.js"></script><script data-pjax>
  function butterfly_footer_beautify_injector_config(){
    var parent_div_git = document.getElementById('footer-wrap');
    var item_html = '<div id="workboard"></div><p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" data-title="博客框架为Hexo_v5.4.0" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&amp;logo=hexo" alt=""/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px" data-title="主题版本Butterfly_v4.2.2" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&amp;logo=bitdefender" alt=""/></a><a class="github-badge" target="_blank" href="https://www.jsdelivr.com/" style="margin-inline:5px" data-title="本站使用JsDelivr为静态资源提供CDN加速" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&amp;logo=jsDelivr" alt=""/></a><a class="github-badge" target="_blank" href="https://beian.miit.gov.cn/#/Integrated/index" style="margin-inline:5px" data-title="本站已在湘进行备案" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/湘ICP备-2022004213号-e1d492?style=flat&amp;logo=data:image/png;base64,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" alt=""/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" data-title="本站项目由Github托管" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&amp;logo=GitHub" alt=""/></a><a class="github-badge" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" style="margin-inline:5px" data-title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&amp;logo=Claris" alt=""/></a></p>';
    console.log('已挂载butterfly_footer_beautify')
    parent_div_git.insertAdjacentHTML("beforeend",item_html)
    }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_footer_beautify_injector_config();
  }
  else if (epage === cpage){
    butterfly_footer_beautify_injector_config();
  }
  </script><script async src="/js/runtime/runtime.min.js"></script><div class="js-pjax"><script async="async">var arr = document.getElementsByClassName('recent-post-item');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '1s');
    arr[i].setAttribute('data-wow-delay', '200ms');
    arr[i].setAttribute('data-wow-offset', '30');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('card-widget');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '');
    arr[i].setAttribute('data-wow-delay', '200ms');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script><script async="async">var arr = document.getElementsByClassName('flink-list-card');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__flipInY');
    arr[i].setAttribute('data-wow-duration', '3s');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script><script async="async">var arr = document.getElementsByClassName('flink-list-card');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__animated');
    arr[i].setAttribute('data-wow-duration', '3s');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script><script async="async">var arr = document.getElementsByClassName('article-sort-item');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__slideInRight');
    arr[i].setAttribute('data-wow-duration', '1.5s');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script><script async="async">var arr = document.getElementsByClassName('site-card');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__flipInY');
    arr[i].setAttribute('data-wow-duration', '3s');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script><script async="async">var arr = document.getElementsByClassName('site-card');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__animated');
    arr[i].setAttribute('data-wow-duration', '3s');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script></div><script defer src="https://cdn.cbd.int/hexo-butterfly-wowjs/lib/wow.min.js"></script><script defer src="https://cdn.cbd.int/hexo-butterfly-wowjs/lib/wow_init.js"></script><script async src="/js/ali_font.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/haruto.model.json"},"display":{"position":"left","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/"});</script></body></html>