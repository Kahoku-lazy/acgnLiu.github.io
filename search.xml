<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>yolov5:模型推理与使用</title>
      <link href="/posts/9b5de9ab.html"/>
      <url>/posts/9b5de9ab.html</url>
      
        <content type="html"><![CDATA[<h1 id="YOLO-使用detect-py-推理模型"><a href="#YOLO-使用detect-py-推理模型" class="headerlink" title="YOLO: 使用detect.py 推理模型"></a>YOLO: 使用detect.py 推理模型</h1><h3 id="一、模型推理基本命令"><a href="#一、模型推理基本命令" class="headerlink" title="一、模型推理基本命令"></a>一、模型推理基本命令</h3><ol><li><p><code>bash</code><strong>命令</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 控制台指令</span></span><br><span class="line">python detect.py  --weights <span class="string">&quot;模型文件&quot;</span> --<span class="built_in">source</span> <span class="string">&quot;输入文件&quot;</span> --class_dir <span class="string">&quot;输出文件&quot;</span> --conf-thres 0.8</span><br></pre></td></tr></table></figure></li><li><p><strong>命令解析</strong></p><ul><li><p><code>detect.py</code>:  python运行的py文件名称</p></li><li><p><code>--weights</code>： 需要推理的模型文件路径</p></li><li><p><code>--source</code>： 推理所需要的输入图片路径</p></li><li><p><code>--conf-thres:</code> 置信度阈值，建议初始设置为0.8</p></li><li><p><code>--class_dir</code>： 模型推理后输出文件路径<strong>（新增参数）</strong></p></li></ul></li></ol><h3 id="二、detect-py-训练参数解析"><a href="#二、detect-py-训练参数解析" class="headerlink" title="二、detect.py 训练参数解析"></a>二、detect.py 训练参数解析</h3><ol><li><p><strong>控制台常用输入参数解析</strong>：</p><ul><li><code>weights:</code>  模型文件（best.pt）</li><li><code>source:</code>  模型输入的数据，类型支持图片、视频与摄像头（摄像头：0）以及是rtsp等视频流,。</li><li><code>imgsz:</code> 网络输入图片大小, 默认的大小是640</li><li><code>conf-thres:</code> 置信度阈值， 默认为0.25</li><li><code>max-det:</code> 保留的最大检测框数量, 每张图片中检测目标的个数最多为1000类、</li><li><code>device:</code> 设置设备CPU/CUDA, 可以不用设置</li><li><code>save-txt:</code> 是否将预测的框坐标以txt文件形式保存, 默认False, 使用—save-txt 在路径runs/detect/exp<em>/labels/</em>.txt下生成每张图片预测的txt文件</li><li><code>save-conf:</code> 是否将置信度conf也保存到txt中, 默认False</li><li><code>classes:</code> 设置只保留某一部分类别, 形如0或者0 2 3, 使用—classes = n, 则在路径runs/detect/exp*/下保存的图片为n所对应的类别, 此时需要设置data</li></ul></li><li><p><code>detect.py</code> <strong>所有参数说明</strong> </p><ul><li><p><code>weights:</code> 训练的权重路径,可以使用自己训练的权重,也可以使用官网提供的权重 默认官网的权重yolov5s.pt(yolov5n.pt/yolov5s.pt/yolov5m.pt/yolov5l.pt/yolov5x.pt/区别在于网络的宽度和深度以此增加)</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">ython path/to/detect.py --weights yolov5s.pt                 # PyTorch</span><br><span class="line">                                   yolov5s.torchscript        # TorchScript</span><br><span class="line">                                   yolov5s.onnx               # ONNX Runtime or OpenCV DNN with --dnn</span><br><span class="line">                                   yolov5s.xml                # OpenVINO</span><br><span class="line">                                    yolov5s.engine             # TensorRT</span><br><span class="line">                                    yolov5s.mlmodel            # CoreML (MacOS-only)</span><br><span class="line">                                    yolov5s_saved_model        # TensorFlow SavedModel</span><br><span class="line">                                    yolov5s.pb                 # TensorFlow GraphDef</span><br><span class="line">                                    yolov5s.tflite             # TensorFlow Lite</span><br><span class="line">                                    yolov5s_edgetpu.tflite     # TensorFlow Edge TPU</span><br></pre></td></tr></table></figure></li></ul></li></ol><ul><li><p><code>source:</code> 测试数据，可以是图片/视频路径，也可以是’0’(电脑自带摄像头),也可以是rtsp等视频流, 默认data/images</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">python path/to/detect.py --weights yolov5s.pt --source 0              # webcam # 直播软件/电脑摄像头</span><br><span class="line">                                                       img.jpg        # image</span><br><span class="line">                                                       vid.mp4        # video</span><br><span class="line">                                                        path/          # directory</span><br><span class="line">                                                       path/*.jpg     # glob</span><br><span class="line">                                                       &#x27;https://youtu.be/Zgi9g1ksQHc&#x27;  # YouTube</span><br><span class="line">                                                        &#x27;rtsp://example.com/media.mp4&#x27;  # RTSP, </span><br></pre></td></tr></table></figure></li></ul><ul><li><p><code>data:</code> 配置数据文件路径, 包括image/label/classes等信息, 训练自己的文件, 需要作相应更改, 可以不用管</p><pre><code>如果设置了只显示个别类别即使用了--classes = 0 或二者1, 2, 3等, 则需要设置该文件，数字和类别相对应才能只检测某一个类</code></pre></li><li><p><code>imgsz:</code> 网络输入图片大小, 默认的大小是640</p></li><li><p><code>conf-thres:</code> 置信度阈值， 默认为0.25</p></li><li><p><code>iou-thres:</code>  做nms的iou阈值, 默认为0.45</p></li><li><p><code>max-det:</code> 保留的最大检测框数量, 每张图片中检测目标的个数最多为1000类</p></li><li><p><code>device:</code> 设置设备CPU/CUDA, 可以不用设置</p></li><li><p><code>view-img:</code> 是否展示预测之后的图片/视频, 默认False, —view-img 电脑界面出现图片或者视频检测结果</p></li><li><p><code>save-txt:</code> 是否将预测的框坐标以txt文件形式保存, 默认False, 使用—save-txt 在路径runs/detect/exp<em>/labels/</em>.txt下生成每张图片预测的txt文件</p></li><li><p><code>save-conf:</code> 是否将置信度conf也保存到txt中, 默认False</p></li><li><p><code>save-crop:</code> 是否保存裁剪预测框图片, 默认为False, 使用—save-crop 在runs/detect/exp*/crop/剪切类别文件夹/ 路径下会保存每个接下来的目标</p></li><li><p><code>nosave:</code> 不保存图片、视频, 要保存图片，不设置—nosave 在runs/detect/exp*/会出现预测的结果</p></li><li><p><code>classes:</code> 设置只保留某一部分类别, 形如0或者0 2 3, 使用—classes = n, 则在路径runs/detect/exp*/下保存的图片为n所对应的类别, 此时需要设置data</p></li><li><p><code>agnostic-nms:</code> 进行NMS去除不同类别之间的框, 默认False</p></li><li><p><code>augment:</code> TTA测试时增强/多尺度预测</p></li><li><p><code>visualize:</code> 是否可视化网络层输出特征</p></li><li><p><code>update:</code> 如果为True,则对所有模型进行strip_optimizer操作,去除pt文件中的优化器等信息,默认为False</p></li><li><p><code>project:</code>保存测试日志的文件夹路径</p></li><li><p><code>name:</code>保存测试日志文件夹的名字, 所以最终是保存在project/name中</p></li><li><p><code>exist_ok:</code> 是否重新创建日志文件, False时重新创建文件</p></li><li><p><code>line-thickness:</code> 画框的线条粗细</p></li><li><p><code>hide-labels:</code> 可视化时隐藏预测类别</p></li><li><p><code>hide-conf:</code> 可视化时隐藏置信度</p></li><li><p><code>half:</code> 是否使用F16精度推理, 半进度提高检测速度</p></li><li><p><code>dnn:</code> 用OpenCV DNN预测</p></li><li><p><code>vid-stride:</code>  设置视频帧率  <strong>（新版本参数）</strong></p></li></ul><h3 id="三、detect-py-源码函数解析"><a href="#三、detect-py-源码函数解析" class="headerlink" title="三、detect.py 源码函数解析"></a>三、detect.py 源码函数解析</h3><ol><li><p>detect.py 代码解析<a href="https://github.com/ultralytics/yolov5/blob/master/detect.py">github项目地址</a>，参考<a href="https://blog.csdn.net/CharmsLUO/article/details/123422822?spm=1001.2014.3001.5506">代码注释参考</a> <a href="https://blog.csdn.net/CharmsLUO">Charms@</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># YOLOv5 🚀 by Ultralytics, GPL-3.0 license</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;Run inference on images, videos, directories, streams, etc.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.backends.cudnn <span class="keyword">as</span> cudnn</span><br><span class="line"></span><br><span class="line">FILE = Path(__file__).resolve()</span><br><span class="line">ROOT = FILE.parents[<span class="number">0</span>]  <span class="comment"># YOLOv5 root directory</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">str</span>(ROOT) <span class="keyword">not</span> <span class="keyword">in</span> sys.path:</span><br><span class="line">    sys.path.append(<span class="built_in">str</span>(ROOT))  <span class="comment"># add ROOT to PATH</span></span><br><span class="line">ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  <span class="comment"># relative</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> models.common <span class="keyword">import</span> DetectMultiBackend</span><br><span class="line"><span class="keyword">from</span> utils.datasets <span class="keyword">import</span> IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams</span><br><span class="line"><span class="keyword">from</span> utils.general <span class="keyword">import</span> (LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr,</span><br><span class="line">                           increment_path, non_max_suppression, print_args, scale_coords, strip_optimizer, xyxy2xywh)</span><br><span class="line"><span class="keyword">from</span> utils.plots <span class="keyword">import</span> Annotator, colors, save_one_box</span><br><span class="line"><span class="keyword">from</span> utils.torch_utils <span class="keyword">import</span> select_device, time_sync</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测不更新梯度</span></span><br><span class="line"><span class="meta">@torch.no_grad()</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">weights=ROOT / <span class="string">&#x27;yolov5s.pt&#x27;</span>,  <span class="comment"># model.pt path(s) # 权重文件地址 默认 weights/可以是自己的路径</span></span></span><br><span class="line"><span class="params">        source=ROOT / <span class="string">&#x27;data/images&#x27;</span>,  <span class="comment"># file/dir/URL/glob, 0 for webcam 0 自带电脑摄像头， 默认data/images/</span></span></span><br><span class="line"><span class="params">        data=ROOT / <span class="string">&#x27;data/coco128.yaml&#x27;</span>,  <span class="comment"># dataset.yaml path, data文件路径，包括类别/图片/标签等信息</span></span></span><br><span class="line"><span class="params">        imgsz=(<span class="params"><span class="number">640</span>, <span class="number">640</span></span>),  <span class="comment"># inference size (height, width) 输入图片的大小 默认640*640</span></span></span><br><span class="line"><span class="params">        conf_thres=<span class="number">0.25</span>,  <span class="comment"># confidence threshold # object置信度阈值 默认0.25  用在nms中</span></span></span><br><span class="line"><span class="params">        iou_thres=<span class="number">0.45</span>,  <span class="comment"># NMS IOU threshold # 做nms的iou阈值 默认0.45   用在nms中</span></span></span><br><span class="line"><span class="params">        max_det=<span class="number">1000</span>,  <span class="comment"># maximum detections per image 每张图片最多的目标数量  用在nms中 </span></span></span><br><span class="line"><span class="params">        device=<span class="string">&#x27;&#x27;</span>,  <span class="comment"># cuda device, i.e. 0 or 0,1,2,3 or cpu 设置代码执行的设备 cuda device, i.e. 0 or 0,1,2,3 or cpu</span></span></span><br><span class="line"><span class="params">        view_img=<span class="literal">False</span>,  <span class="comment"># show results 是否展示预测之后的图片或视频 默认False </span></span></span><br><span class="line"><span class="params">        save_txt=<span class="literal">False</span>,  <span class="comment"># save results to *.txt 是否将预测的框坐标以txt文件形式保存, 默认False, 使用--save-txt 在路径runs/detect/exp*/labels/*.txt下生成每张图片预测的txt文件</span></span></span><br><span class="line"><span class="params">        save_conf=<span class="literal">False</span>,  <span class="comment"># save confidences in --save-txt labels 是否将置信度conf也保存到txt中, 默认False</span></span></span><br><span class="line"><span class="params">        save_crop=<span class="literal">False</span>,  <span class="comment"># save cropped prediction boxes 是否保存裁剪预测框图片, 默认为False, 使用--save-crop 在runs/detect/exp*/crop/剪切类别文件夹/ 路径下会保存每个接下来的目标</span></span></span><br><span class="line"><span class="params">        nosave=<span class="literal">False</span>,  <span class="comment"># do not save images/videos 不保存图片、视频, 要保存图片，不设置--nosave 在runs/detect/exp*/会出现预测的结果</span></span></span><br><span class="line"><span class="params">        classes=<span class="literal">None</span>,  <span class="comment"># filter by class: --class 0, or --class 0 2 3 设置只保留某一部分类别, 形如0或者0 2 3, 使用--classes = n, 则在路径runs/detect/exp*/下保存的图片为n所对应的类别, 此时需要设置data</span></span></span><br><span class="line"><span class="params">        agnostic_nms=<span class="literal">False</span>,  <span class="comment"># class-agnostic NMS 进行NMS去除不同类别之间的框, 默认False</span></span></span><br><span class="line"><span class="params">        augment=<span class="literal">False</span>,  <span class="comment"># augmented inference TTA测试时增强/多尺度预测，可以提分</span></span></span><br><span class="line"><span class="params">        visualize=<span class="literal">False</span>,  <span class="comment"># visualize features 是否可视化网络层输出特征</span></span></span><br><span class="line"><span class="params">        update=<span class="literal">False</span>,  <span class="comment"># update all models 如果为True,则对所有模型进行strip_optimizer操作,去除pt文件中的优化器等信息,默认为False</span></span></span><br><span class="line"><span class="params">        project=ROOT / <span class="string">&#x27;runs/detect&#x27;</span>,  <span class="comment"># save results to project/name 保存测试日志的文件夹路径</span></span></span><br><span class="line"><span class="params">        name=<span class="string">&#x27;exp&#x27;</span>,  <span class="comment"># save results to project/name 每次实验的名称</span></span></span><br><span class="line"><span class="params">        exist_ok=<span class="literal">False</span>,  <span class="comment"># existing project/name ok, do not increment 是否重新创建日志文件, False时重新创建文件</span></span></span><br><span class="line"><span class="params">        line_thickness=<span class="number">3</span>,  <span class="comment"># bounding box thickness (pixels) 画框的线条粗细</span></span></span><br><span class="line"><span class="params">        hide_labels=<span class="literal">False</span>,  <span class="comment"># hide labels 可视化时隐藏预测类别</span></span></span><br><span class="line"><span class="params">        hide_conf=<span class="literal">False</span>,  <span class="comment"># hide confidences 可视化时隐藏置信度</span></span></span><br><span class="line"><span class="params">        half=<span class="literal">False</span>,  <span class="comment"># use FP16 half-precision inference 是否使用F16精度推理, 半进度提高检测速度</span></span></span><br><span class="line"><span class="params">        dnn=<span class="literal">False</span>,  <span class="comment"># use OpenCV DNN for ONNX inference 用OpenCV DNN预测</span></span></span><br><span class="line"><span class="params">        </span>):</span><br><span class="line">    <span class="comment">################################################# 1. 初始化配置 #####################################################</span></span><br><span class="line">    <span class="comment"># 输入的路径变为字符串</span></span><br><span class="line">    source = <span class="built_in">str</span>(source)</span><br><span class="line">    <span class="comment"># 是否保存图片和txt文件</span></span><br><span class="line">    save_img = <span class="keyword">not</span> nosave <span class="keyword">and</span> <span class="keyword">not</span> source.endswith(<span class="string">&#x27;.txt&#x27;</span>)  <span class="comment"># save inference images</span></span><br><span class="line">    <span class="comment"># 判断文件是否是视频流</span></span><br><span class="line">    <span class="comment"># Path()提取文件名 例如：Path(&quot;./data/test_images/bus.jpg&quot;) Path.name-&gt;bus.jpg Path.parent-&gt;./data/test_images Path.suffix-&gt;.jpg</span></span><br><span class="line">    is_file = Path(source).suffix[<span class="number">1</span>:] <span class="keyword">in</span> (IMG_FORMATS + VID_FORMATS) <span class="comment"># 提取文件后缀名是否符合要求的文件，例如：是否格式是jpg, png, asf, avi等</span></span><br><span class="line">    <span class="comment"># .lower()转化成小写 .upper()转化成大写 .title()首字符转化成大写，其余为小写, .startswith(&#x27;http://&#x27;)返回True or Flase</span></span><br><span class="line">    is_url = source.lower().startswith((<span class="string">&#x27;rtsp://&#x27;</span>, <span class="string">&#x27;rtmp://&#x27;</span>, <span class="string">&#x27;http://&#x27;</span>, <span class="string">&#x27;https://&#x27;</span>))</span><br><span class="line">    <span class="comment"># .isnumeric()是否是由数字组成，返回True or False</span></span><br><span class="line">    webcam = source.isnumeric() <span class="keyword">or</span> source.endswith(<span class="string">&#x27;.txt&#x27;</span>) <span class="keyword">or</span> (is_url <span class="keyword">and</span> <span class="keyword">not</span> is_file)</span><br><span class="line">    <span class="keyword">if</span> is_url <span class="keyword">and</span> is_file:</span><br><span class="line">        <span class="comment"># 返回文件</span></span><br><span class="line">        source = check_file(source)  <span class="comment"># download</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Directories</span></span><br><span class="line">    <span class="comment"># 预测路径是否存在，不存在新建，按照实验文件以此递增新建</span></span><br><span class="line">    save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)  <span class="comment"># increment run</span></span><br><span class="line">    (save_dir / <span class="string">&#x27;labels&#x27;</span> <span class="keyword">if</span> save_txt <span class="keyword">else</span> save_dir).mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)  <span class="comment"># make dir</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Load model</span></span><br><span class="line">    <span class="comment"># 获取设备 CPU/CUDA</span></span><br><span class="line">    device = select_device(device)</span><br><span class="line">    <span class="comment"># 检测编译框架PYTORCH/TENSORFLOW/TENSORRT</span></span><br><span class="line">    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data)</span><br><span class="line">    stride, names, pt, jit, onnx, engine = model.stride, model.names, model.pt, model.jit, model.onnx, model.engine</span><br><span class="line">    <span class="comment"># 确保输入图片的尺寸imgsz能整除stride=32 如果不能则调整为能被整除并返回</span></span><br><span class="line">    imgsz = check_img_size(imgsz, s=stride)  <span class="comment"># check image size</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Half</span></span><br><span class="line">    <span class="comment"># 如果不是CPU，使用半进度(图片半精度/模型半精度)</span></span><br><span class="line">    half &amp;= (pt <span class="keyword">or</span> jit <span class="keyword">or</span> onnx <span class="keyword">or</span> engine) <span class="keyword">and</span> device.<span class="built_in">type</span> != <span class="string">&#x27;cpu&#x27;</span>  <span class="comment"># FP16 supported on limited backends with CUDA</span></span><br><span class="line">    <span class="keyword">if</span> pt <span class="keyword">or</span> jit:</span><br><span class="line">        model.model.half() <span class="keyword">if</span> half <span class="keyword">else</span> model.model.<span class="built_in">float</span>()</span><br><span class="line">    <span class="comment"># TENSORRT加速</span></span><br><span class="line">    <span class="keyword">elif</span> engine <span class="keyword">and</span> model.trt_fp16_input != half:</span><br><span class="line">        LOGGER.info(<span class="string">&#x27;model &#x27;</span> + (</span><br><span class="line">            <span class="string">&#x27;requires&#x27;</span> <span class="keyword">if</span> model.trt_fp16_input <span class="keyword">else</span> <span class="string">&#x27;incompatible with&#x27;</span>) + <span class="string">&#x27; --half. Adjusting automatically.&#x27;</span>)</span><br><span class="line">        half = model.trt_fp16_input</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    <span class="comment">################################################# 2. 加载数据 #####################################################</span></span><br><span class="line">    <span class="comment"># Dataloader 加载数据</span></span><br><span class="line">    <span class="comment"># 使用视频流或者页面</span></span><br><span class="line">    <span class="keyword">if</span> webcam:</span><br><span class="line">        view_img = check_imshow()</span><br><span class="line">        cudnn.benchmark = <span class="literal">True</span>  <span class="comment"># set True to speed up constant image size inference</span></span><br><span class="line">        dataset = LoadStreams(source, img_size=imgsz, stride=stride, auto=pt)</span><br><span class="line">        bs = <span class="built_in">len</span>(dataset)  <span class="comment"># batch_size</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 直接从source文件下读取图片</span></span><br><span class="line">        dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt)</span><br><span class="line">        bs = <span class="number">1</span>  <span class="comment"># batch_size</span></span><br><span class="line">    <span class="comment"># 保存的路径</span></span><br><span class="line">    vid_path, vid_writer = [<span class="literal">None</span>] * bs, [<span class="literal">None</span>] * bs</span><br><span class="line"></span><br><span class="line">    <span class="comment">################################################# 3. 网络预测 #####################################################</span></span><br><span class="line">    <span class="comment"># Run inference</span></span><br><span class="line">    <span class="comment"># warmup 热身</span></span><br><span class="line">    model.warmup(imgsz=(<span class="number">1</span> <span class="keyword">if</span> pt <span class="keyword">else</span> bs, <span class="number">3</span>, *imgsz), half=half)  <span class="comment"># warmup</span></span><br><span class="line">    dt, seen = [<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>], <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> path, im, im0s, vid_cap, s <span class="keyword">in</span> dataset:</span><br><span class="line">        t1 = time_sync()</span><br><span class="line">        <span class="comment"># 转化到GPU上</span></span><br><span class="line">        im = torch.from_numpy(im).to(device)</span><br><span class="line">        <span class="comment"># 是否使用半精度</span></span><br><span class="line">        im = im.half() <span class="keyword">if</span> half <span class="keyword">else</span> im.<span class="built_in">float</span>()  <span class="comment"># uint8 to fp16/32</span></span><br><span class="line">        im /= <span class="number">255</span>  <span class="comment"># 0 - 255 to 0.0 - 1.0</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(im.shape) == <span class="number">3</span>:</span><br><span class="line">            <span class="comment"># 增加一个维度</span></span><br><span class="line">            im = im[<span class="literal">None</span>]  <span class="comment"># expand for batch dim</span></span><br><span class="line">        t2 = time_sync()</span><br><span class="line">        dt[<span class="number">0</span>] += t2 - t1</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Inference</span></span><br><span class="line">        <span class="comment"># 可是化文件路径</span></span><br><span class="line">        visualize = increment_path(save_dir / Path(path).stem, mkdir=<span class="literal">True</span>) <span class="keyword">if</span> visualize <span class="keyword">else</span> <span class="literal">False</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        pred.shape=(1, num_boxes, 5+num_class)</span></span><br><span class="line"><span class="string">        h,w为传入网络图片的长和宽,注意dataset在检测时使用了矩形推理,所以这里h不一定等于w</span></span><br><span class="line"><span class="string">        num_boxes = h/32 * w/32 + h/16 * w/16 + h/8 * w/8</span></span><br><span class="line"><span class="string">        pred[..., 0:4]为预测框坐标=预测框坐标为xywh(中心点+宽长)格式</span></span><br><span class="line"><span class="string">        pred[..., 4]为objectness置信度</span></span><br><span class="line"><span class="string">        pred[..., 5:-1]为分类结果</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        pred = model(im, augment=augment, visualize=visualize)</span><br><span class="line">        t3 = time_sync()</span><br><span class="line">        <span class="comment"># 预测的时间</span></span><br><span class="line">        dt[<span class="number">1</span>] += t3 - t2</span><br><span class="line"></span><br><span class="line">        <span class="comment"># NMS</span></span><br><span class="line">        <span class="comment"># 非极大值抑制</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        pred: 网络的输出结果</span></span><br><span class="line"><span class="string">        conf_thres:置信度阈值</span></span><br><span class="line"><span class="string">        ou_thres:iou阈值</span></span><br><span class="line"><span class="string">        classes: 是否只保留特定的类别</span></span><br><span class="line"><span class="string">        agnostic_nms: 进行nms是否也去除不同类别之间的框</span></span><br><span class="line"><span class="string">        max-det: 保留的最大检测框数量</span></span><br><span class="line"><span class="string">        ---NMS, 预测框格式: xywh(中心点+长宽)--&gt;xyxy(左上角右下角)</span></span><br><span class="line"><span class="string">        pred是一个列表list[torch.tensor], 长度为batch_size</span></span><br><span class="line"><span class="string">        每一个torch.tensor的shape为(num_boxes, 6), 内容为box + conf + cls</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)</span><br><span class="line">        <span class="comment"># 预测+NMS的时间</span></span><br><span class="line">        dt[<span class="number">2</span>] += time_sync() - t3</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Second-stage classifier (optional)</span></span><br><span class="line">        <span class="comment"># pred = utils.general.apply_classifier(pred, classifier_model, im, im0s)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Process predictions</span></span><br><span class="line">        <span class="comment"># 对每张图片做处理</span></span><br><span class="line">        <span class="keyword">for</span> i, det <span class="keyword">in</span> <span class="built_in">enumerate</span>(pred):  <span class="comment"># per image</span></span><br><span class="line">            seen += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> webcam:  <span class="comment"># batch_size &gt;= 1</span></span><br><span class="line">                <span class="comment"># 如果输入源是webcam则batch_size&gt;=1 取出dataset中的一张图片</span></span><br><span class="line">                p, im0, frame = path[i], im0s[i].copy(), dataset.count</span><br><span class="line">                s += <span class="string">f&#x27;<span class="subst">&#123;i&#125;</span>: &#x27;</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 但是大部分我们一般都是从LoadImages流读取本都文件中的照片或者视频 所以batch_size=1</span></span><br><span class="line">                <span class="comment"># p: 当前图片/视频的绝对路径 如 F:\yolo_v5\yolov5-U\data\images\bus.jpg</span></span><br><span class="line">                <span class="comment"># s: 输出信息 初始为 &#x27;&#x27;</span></span><br><span class="line">                <span class="comment"># im0: 原始图片 letterbox + pad 之前的图片</span></span><br><span class="line">                <span class="comment"># frame: 视频流</span></span><br><span class="line">                p, im0, frame = path, im0s.copy(), <span class="built_in">getattr</span>(dataset, <span class="string">&#x27;frame&#x27;</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 当前路径yolov5/data/images/</span></span><br><span class="line">            p = Path(p)  <span class="comment"># to Path</span></span><br><span class="line">            <span class="comment"># 图片/视频的保存路径save_path 如 runs\\detect\\exp8\\bus.jpg</span></span><br><span class="line">            save_path = <span class="built_in">str</span>(save_dir / p.name)  <span class="comment"># im.jpg</span></span><br><span class="line">            <span class="comment"># 设置保存框坐标的txt文件路径，每张图片对应一个框坐标信息</span></span><br><span class="line">            txt_path = <span class="built_in">str</span>(save_dir / <span class="string">&#x27;labels&#x27;</span> / p.stem) + (<span class="string">&#x27;&#x27;</span> <span class="keyword">if</span> dataset.mode == <span class="string">&#x27;image&#x27;</span> <span class="keyword">else</span> <span class="string">f&#x27;_<span class="subst">&#123;frame&#125;</span>&#x27;</span>)  <span class="comment"># im.txt</span></span><br><span class="line">            <span class="comment"># 设置打印图片的信息</span></span><br><span class="line">            s += <span class="string">&#x27;%gx%g &#x27;</span> % im.shape[<span class="number">2</span>:]  <span class="comment"># print string</span></span><br><span class="line">            gn = torch.tensor(im0.shape)[[<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]]  <span class="comment"># normalization gain whwh</span></span><br><span class="line">            <span class="comment"># 保存截图</span></span><br><span class="line">            imc = im0.copy() <span class="keyword">if</span> save_crop <span class="keyword">else</span> im0  <span class="comment"># for save_crop</span></span><br><span class="line">            annotator = Annotator(im0, line_width=line_thickness, example=<span class="built_in">str</span>(names))</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(det):</span><br><span class="line">                <span class="comment"># Rescale boxes from img_size to im0 size</span></span><br><span class="line">                <span class="comment"># 将预测信息映射到原图</span></span><br><span class="line">                det[:, :<span class="number">4</span>] = scale_coords(im.shape[<span class="number">2</span>:], det[:, :<span class="number">4</span>], im0.shape).<span class="built_in">round</span>()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Print results</span></span><br><span class="line">                <span class="comment"># 打印检测到的类别数量</span></span><br><span class="line">                <span class="keyword">for</span> c <span class="keyword">in</span> det[:, -<span class="number">1</span>].unique():</span><br><span class="line">                    n = (det[:, -<span class="number">1</span>] == c).<span class="built_in">sum</span>()  <span class="comment"># detections per class</span></span><br><span class="line">                    s += <span class="string">f&quot;<span class="subst">&#123;n&#125;</span> <span class="subst">&#123;names[<span class="built_in">int</span>(c)]&#125;</span><span class="subst">&#123;<span class="string">&#x27;s&#x27;</span> * (n &gt; <span class="number">1</span>)&#125;</span>, &quot;</span>  <span class="comment"># add to string</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># Write results</span></span><br><span class="line">                <span class="comment"># 保存结果： txt/图片画框/crop-image</span></span><br><span class="line">                <span class="keyword">for</span> *xyxy, conf, cls <span class="keyword">in</span> <span class="built_in">reversed</span>(det):</span><br><span class="line">                    <span class="comment"># 将每个图片的预测信息分别存入save_dir/labels下的xxx.txt中 每行: class_id + score + xywh</span></span><br><span class="line">                    <span class="keyword">if</span> save_txt:  <span class="comment"># Write to file</span></span><br><span class="line">                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(<span class="number">1</span>, <span class="number">4</span>)) / gn).view(-<span class="number">1</span>).tolist()  <span class="comment"># normalized xywh</span></span><br><span class="line">                        line = (cls, *xywh, conf) <span class="keyword">if</span> save_conf <span class="keyword">else</span> (cls, *xywh)  <span class="comment"># label format</span></span><br><span class="line">                        <span class="keyword">with</span> <span class="built_in">open</span>(txt_path + <span class="string">&#x27;.txt&#x27;</span>, <span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                            f.write((<span class="string">&#x27;%g &#x27;</span> * <span class="built_in">len</span>(line)).rstrip() % line + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">                    <span class="comment"># # 在原图上画框 + 将预测到的目标剪切出来 保存成图片 保存在save_dir/crops下 在原图像画图或者保存结果</span></span><br><span class="line">                    <span class="keyword">if</span> save_img <span class="keyword">or</span> save_crop <span class="keyword">or</span> view_img:  <span class="comment"># Add bbox to image</span></span><br><span class="line">                        c = <span class="built_in">int</span>(cls)  <span class="comment"># integer class</span></span><br><span class="line">                        label = <span class="literal">None</span> <span class="keyword">if</span> hide_labels <span class="keyword">else</span> (names[c] <span class="keyword">if</span> hide_conf <span class="keyword">else</span> <span class="string">f&#x27;<span class="subst">&#123;names[c]&#125;</span> <span class="subst">&#123;conf:<span class="number">.2</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">                        annotator.box_label(xyxy, label, color=colors(c, <span class="literal">True</span>))</span><br><span class="line">                        <span class="keyword">if</span> save_crop:</span><br><span class="line">                            <span class="comment"># 在原图上画框 + 将预测到的目标剪切出来 保存成图片 保存在save_dir/crops下</span></span><br><span class="line">                            save_one_box(xyxy, imc, file=save_dir / <span class="string">&#x27;crops&#x27;</span> / names[c] / <span class="string">f&#x27;<span class="subst">&#123;p.stem&#125;</span>.jpg&#x27;</span>, BGR=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Stream results</span></span><br><span class="line">            im0 = annotator.result()</span><br><span class="line">            <span class="comment"># 显示图片</span></span><br><span class="line">            <span class="keyword">if</span> view_img:</span><br><span class="line">                cv2.imshow(<span class="built_in">str</span>(p), im0)</span><br><span class="line">                cv2.waitKey(<span class="number">1</span>)  <span class="comment"># 1 millisecond</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Save results (image with detections)</span></span><br><span class="line">            <span class="comment"># 保存图片</span></span><br><span class="line">            <span class="keyword">if</span> save_img:</span><br><span class="line">                <span class="keyword">if</span> dataset.mode == <span class="string">&#x27;image&#x27;</span>:</span><br><span class="line">                    cv2.imwrite(save_path, im0)</span><br><span class="line">                <span class="keyword">else</span>:  <span class="comment"># &#x27;video&#x27; or &#x27;stream&#x27;</span></span><br><span class="line">                    <span class="keyword">if</span> vid_path[i] != save_path:  <span class="comment"># new video</span></span><br><span class="line">                        vid_path[i] = save_path</span><br><span class="line">                        <span class="keyword">if</span> <span class="built_in">isinstance</span>(vid_writer[i], cv2.VideoWriter):</span><br><span class="line">                            vid_writer[i].release()  <span class="comment"># release previous video writer</span></span><br><span class="line">                        <span class="keyword">if</span> vid_cap:  <span class="comment"># video</span></span><br><span class="line">                            fps = vid_cap.get(cv2.CAP_PROP_FPS)</span><br><span class="line">                            w = <span class="built_in">int</span>(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))</span><br><span class="line">                            h = <span class="built_in">int</span>(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))</span><br><span class="line">                        <span class="keyword">else</span>:  <span class="comment"># stream</span></span><br><span class="line">                            fps, w, h = <span class="number">30</span>, im0.shape[<span class="number">1</span>], im0.shape[<span class="number">0</span>]</span><br><span class="line">                        save_path = <span class="built_in">str</span>(Path(save_path).with_suffix(<span class="string">&#x27;.mp4&#x27;</span>))  <span class="comment"># force *.mp4 suffix on results videos</span></span><br><span class="line">                        vid_writer[i] = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*<span class="string">&#x27;mp4v&#x27;</span>), fps, (w, h))</span><br><span class="line">                    vid_writer[i].write(im0)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Print time (inference-only)</span></span><br><span class="line">        LOGGER.info(<span class="string">f&#x27;<span class="subst">&#123;s&#125;</span>Done. (<span class="subst">&#123;t3 - t2:<span class="number">.3</span>f&#125;</span>s)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Print results</span></span><br><span class="line">    <span class="comment"># 打印每张图片的速度</span></span><br><span class="line">    t = <span class="built_in">tuple</span>(x / seen * <span class="number">1E3</span> <span class="keyword">for</span> x <span class="keyword">in</span> dt)  <span class="comment"># speeds per image</span></span><br><span class="line">    LOGGER.info(<span class="string">f&#x27;Speed: %.1fms pre-process, %.1fms inference, %.1fms NMS per image at shape <span class="subst">&#123;(<span class="number">1</span>, <span class="number">3</span>, *imgsz)&#125;</span>&#x27;</span> % t)</span><br><span class="line">    <span class="comment"># 保存图片或者txt</span></span><br><span class="line">    <span class="keyword">if</span> save_txt <span class="keyword">or</span> save_img:</span><br><span class="line">        s = <span class="string">f&quot;\n<span class="subst">&#123;<span class="built_in">len</span>(<span class="built_in">list</span>(save_dir.glob(<span class="string">&#x27;labels/*.txt&#x27;</span>)))&#125;</span> labels saved to <span class="subst">&#123;save_dir / <span class="string">&#x27;labels&#x27;</span>&#125;</span>&quot;</span> <span class="keyword">if</span> save_txt <span class="keyword">else</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line">        LOGGER.info(<span class="string">f&quot;Results saved to <span class="subst">&#123;colorstr(<span class="string">&#x27;bold&#x27;</span>, save_dir)&#125;</span><span class="subst">&#123;s&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> update:</span><br><span class="line">        strip_optimizer(weights)  <span class="comment"># update model (to fix SourceChangeWarning)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_opt</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    weights: 训练的权重路径,可以使用自己训练的权重,也可以使用官网提供的权重</span></span><br><span class="line"><span class="string">    默认官网的权重yolov5s.pt(yolov5n.pt/yolov5s.pt/yolov5m.pt/yolov5l.pt/yolov5x.pt/区别在于网络的宽度和深度以此增加)</span></span><br><span class="line"><span class="string">    source: 测试数据，可以是图片/视频路径，也可以是&#x27;0&#x27;(电脑自带摄像头),也可以是rtsp等视频流, 默认data/images</span></span><br><span class="line"><span class="string">    data: 配置数据文件路径, 包括image/label/classes等信息, 训练自己的文件, 需要作相应更改, 可以不用管</span></span><br><span class="line"><span class="string">    如果设置了只显示个别类别即使用了--classes = 0 或二者1, 2, 3等, 则需要设置该文件，数字和类别相对应才能只检测某一个类</span></span><br><span class="line"><span class="string">    imgsz: 网络输入图片大小, 默认的大小是640</span></span><br><span class="line"><span class="string">    conf-thres: 置信度阈值， 默认为0.25</span></span><br><span class="line"><span class="string">    iou-thres:  做nms的iou阈值, 默认为0.45</span></span><br><span class="line"><span class="string">    max-det: 保留的最大检测框数量, 每张图片中检测目标的个数最多为1000类</span></span><br><span class="line"><span class="string">    device: 设置设备CPU/CUDA, 可以不用设置</span></span><br><span class="line"><span class="string">    view-img: 是否展示预测之后的图片/视频, 默认False, --view-img 电脑界面出现图片或者视频检测结果</span></span><br><span class="line"><span class="string">    save-txt: 是否将预测的框坐标以txt文件形式保存, 默认False, 使用--save-txt 在路径runs/detect/exp*/labels/*.txt下生成每张图片预测的txt文件</span></span><br><span class="line"><span class="string">    save-conf: 是否将置信度conf也保存到txt中, 默认False</span></span><br><span class="line"><span class="string">    save-crop: 是否保存裁剪预测框图片, 默认为False, 使用--save-crop 在runs/detect/exp*/crop/剪切类别文件夹/ 路径下会保存每个接下来的目标</span></span><br><span class="line"><span class="string">    nosave: 不保存图片、视频, 要保存图片，不设置--nosave 在runs/detect/exp*/会出现预测的结果</span></span><br><span class="line"><span class="string">    classes: 设置只保留某一部分类别, 形如0或者0 2 3, 使用--classes = n, 则在路径runs/detect/exp*/下保存的图片为n所对应的类别, 此时需要设置data</span></span><br><span class="line"><span class="string">    agnostic-nms: 进行NMS去除不同类别之间的框, 默认False</span></span><br><span class="line"><span class="string">    augment: TTA测试时增强/多尺度预测, 可以提分</span></span><br><span class="line"><span class="string">    visualize: 是否可视化网络层输出特征</span></span><br><span class="line"><span class="string">    update: 如果为True,则对所有模型进行strip_optimizer操作,去除pt文件中的优化器等信息,默认为False</span></span><br><span class="line"><span class="string">    project: 保存测试日志的文件夹路径</span></span><br><span class="line"><span class="string">    name: 保存测试日志文件夹的名字, 所以最终是保存在project/name中</span></span><br><span class="line"><span class="string">    exist_ok: 是否重新创建日志文件, False时重新创建文件</span></span><br><span class="line"><span class="string">    line-thickness: 画框的线条粗细</span></span><br><span class="line"><span class="string">    hide-labels: 可视化时隐藏预测类别</span></span><br><span class="line"><span class="string">    hide-conf: 可视化时隐藏置信度</span></span><br><span class="line"><span class="string">    half: 是否使用F16精度推理, 半进度提高检测速度</span></span><br><span class="line"><span class="string">    dnn: 用OpenCV DNN预测</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--weights&#x27;</span>, nargs=<span class="string">&#x27;+&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=ROOT / <span class="string">&#x27;yolov5s.pt&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;model path(s)&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--source&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=ROOT / <span class="string">&#x27;data/images&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;file/dir/URL/glob, 0 for webcam&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--data&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=ROOT / <span class="string">&#x27;data/coco128.yaml&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;(optional) dataset.yaml path&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--imgsz&#x27;</span>, <span class="string">&#x27;--img&#x27;</span>, <span class="string">&#x27;--img-size&#x27;</span>, nargs=<span class="string">&#x27;+&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=[<span class="number">640</span>], <span class="built_in">help</span>=<span class="string">&#x27;inference size h,w&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--conf-thres&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.25</span>, <span class="built_in">help</span>=<span class="string">&#x27;confidence threshold&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--iou-thres&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.45</span>, <span class="built_in">help</span>=<span class="string">&#x27;NMS IoU threshold&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--max-det&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">1000</span>, <span class="built_in">help</span>=<span class="string">&#x27;maximum detections per image&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--device&#x27;</span>, default=<span class="string">&#x27;&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;cuda device, i.e. 0 or 0,1,2,3 or cpu&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--view-img&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;show results&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--save-txt&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;save results to *.txt&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--save-conf&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;save confidences in --save-txt labels&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--save-crop&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;save cropped prediction boxes&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--nosave&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;do not save images/videos&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--classes&#x27;</span>, nargs=<span class="string">&#x27;+&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;filter by class: --classes 0, or --classes 0 2 3&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--agnostic-nms&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;class-agnostic NMS&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--augment&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;augmented inference&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--visualize&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;visualize features&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--update&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;update all models&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--project&#x27;</span>, default=ROOT / <span class="string">&#x27;runs/detect&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;save results to project/name&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--name&#x27;</span>, default=<span class="string">&#x27;exp&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;save results to project/name&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--exist-ok&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;existing project/name ok, do not increment&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--line-thickness&#x27;</span>, default=<span class="number">3</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;bounding box thickness (pixels)&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--hide-labels&#x27;</span>, default=<span class="literal">False</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;hide labels&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--hide-conf&#x27;</span>, default=<span class="literal">False</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;hide confidences&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--half&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;use FP16 half-precision inference&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--dnn&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;use OpenCV DNN for ONNX inference&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    opt = parser.parse_args()</span><br><span class="line">    <span class="comment"># 扩充维度, 如果是一位就扩充一位</span></span><br><span class="line">    opt.imgsz *= <span class="number">2</span> <span class="keyword">if</span> <span class="built_in">len</span>(opt.imgsz) == <span class="number">1</span> <span class="keyword">else</span> <span class="number">1</span>  <span class="comment"># expand</span></span><br><span class="line">    <span class="comment"># 输出所有参数</span></span><br><span class="line">    print_args(FILE.stem, opt)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> opt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">opt</span>):</span><br><span class="line">    <span class="comment"># 检查环境/打印参数,主要是requrement.txt的包是否安装，用彩色显示设置的参数</span></span><br><span class="line">    check_requirements(exclude=(<span class="string">&#x27;tensorboard&#x27;</span>, <span class="string">&#x27;thop&#x27;</span>))</span><br><span class="line">    <span class="comment"># 执行run()函数</span></span><br><span class="line">    run(**<span class="built_in">vars</span>(opt))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    opt = parse_opt()</span><br><span class="line">    main(opt)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>parse_opt（）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">parse_opt</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    weights: 训练的权重路径,可以使用自己训练的权重,也可以使用官网提供的权重</span></span><br><span class="line"><span class="string">    默认官网的权重yolov5s.pt(yolov5n.pt/yolov5s.pt/yolov5m.pt/yolov5l.pt/yolov5x.pt/区别在于网络的宽度和深度以此增加)</span></span><br><span class="line"><span class="string">    source: 测试数据，可以是图片/视频路径，也可以是&#x27;0&#x27;(电脑自带摄像头),也可以是rtsp等视频流, 默认data/images</span></span><br><span class="line"><span class="string">    data: 配置数据文件路径, 包括image/label/classes等信息, 训练自己的文件, 需要作相应更改, 可以不用管</span></span><br><span class="line"><span class="string">    如果设置了只显示个别类别即使用了--classes = 0 或二者1, 2, 3等, 则需要设置该文件，数字和类别相对应才能只检测某一个类</span></span><br><span class="line"><span class="string">    imgsz: 网络输入图片大小, 默认的大小是640</span></span><br><span class="line"><span class="string">    conf-thres: 置信度阈值， 默认为0.25</span></span><br><span class="line"><span class="string">    iou-thres:  做nms的iou阈值, 默认为0.45</span></span><br><span class="line"><span class="string">    max-det: 保留的最大检测框数量, 每张图片中检测目标的个数最多为1000类</span></span><br><span class="line"><span class="string">    device: 设置设备CPU/CUDA, 可以不用设置</span></span><br><span class="line"><span class="string">    view-img: 是否展示预测之后的图片/视频, 默认False, --view-img 电脑界面出现图片或者视频检测结果</span></span><br><span class="line"><span class="string">    save-txt: 是否将预测的框坐标以txt文件形式保存, 默认False, 使用--save-txt 在路径runs/detect/exp*/labels/*.txt下生成每张图片预测的txt文件</span></span><br><span class="line"><span class="string">    save-conf: 是否将置信度conf也保存到txt中, 默认False</span></span><br><span class="line"><span class="string">    save-crop: 是否保存裁剪预测框图片, 默认为False, 使用--save-crop 在runs/detect/exp*/crop/剪切类别文件夹/ 路径下会保存每个接下来的目标</span></span><br><span class="line"><span class="string">    nosave: 不保存图片、视频, 要保存图片，不设置--nosave 在runs/detect/exp*/会出现预测的结果</span></span><br><span class="line"><span class="string">    classes: 设置只保留某一部分类别, 形如0或者0 2 3, 使用--classes = n, 则在路径runs/detect/exp*/下保存的图片为n所对应的类别, 此时需要设置data</span></span><br><span class="line"><span class="string">    agnostic-nms: 进行NMS去除不同类别之间的框, 默认False</span></span><br><span class="line"><span class="string">    augment: TTA测试时增强/多尺度预测</span></span><br><span class="line"><span class="string">    visualize: 是否可视化网络层输出特征</span></span><br><span class="line"><span class="string">    update: 如果为True,则对所有模型进行strip_optimizer操作,去除pt文件中的优化器等信息,默认为False</span></span><br><span class="line"><span class="string">    project:保存测试日志的文件夹路径</span></span><br><span class="line"><span class="string">    name:保存测试日志文件夹的名字, 所以最终是保存在project/name中</span></span><br><span class="line"><span class="string">    exist_ok: 是否重新创建日志文件, False时重新创建文件</span></span><br><span class="line"><span class="string">    line-thickness: 画框的线条粗细</span></span><br><span class="line"><span class="string">    hide-labels: 可视化时隐藏预测类别</span></span><br><span class="line"><span class="string">    hide-conf: 可视化时隐藏置信度</span></span><br><span class="line"><span class="string">    half: 是否使用F16精度推理, 半进度提高检测速度</span></span><br><span class="line"><span class="string">    dnn: 用OpenCV DNN预测</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--weights&#x27;</span>, nargs=<span class="string">&#x27;+&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=ROOT / <span class="string">&#x27;yolov5s.pt&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;model path(s)&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--source&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=ROOT / <span class="string">&#x27;data/images&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;file/dir/URL/glob, 0 for webcam&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--data&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=ROOT / <span class="string">&#x27;data/coco128.yaml&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;(optional) dataset.yaml path&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--imgsz&#x27;</span>, <span class="string">&#x27;--img&#x27;</span>, <span class="string">&#x27;--img-size&#x27;</span>, nargs=<span class="string">&#x27;+&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=[<span class="number">640</span>], <span class="built_in">help</span>=<span class="string">&#x27;inference size h,w&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--conf-thres&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.25</span>, <span class="built_in">help</span>=<span class="string">&#x27;confidence threshold&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--iou-thres&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.45</span>, <span class="built_in">help</span>=<span class="string">&#x27;NMS IoU threshold&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--max-det&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">1000</span>, <span class="built_in">help</span>=<span class="string">&#x27;maximum detections per image&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--device&#x27;</span>, default=<span class="string">&#x27;&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;cuda device, i.e. 0 or 0,1,2,3 or cpu&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--view-img&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;show results&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--save-txt&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;save results to *.txt&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--save-conf&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;save confidences in --save-txt labels&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--save-crop&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;save cropped prediction boxes&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--nosave&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;do not save images/videos&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--classes&#x27;</span>, nargs=<span class="string">&#x27;+&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;filter by class: --classes 0, or --classes 0 2 3&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--agnostic-nms&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;class-agnostic NMS&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--augment&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;augmented inference&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--visualize&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;visualize features&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--update&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;update all models&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--project&#x27;</span>, default=ROOT / <span class="string">&#x27;runs/detect&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;save results to project/name&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--name&#x27;</span>, default=<span class="string">&#x27;exp&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;save results to project/name&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--exist-ok&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;existing project/name ok, do not increment&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--line-thickness&#x27;</span>, default=<span class="number">3</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;bounding box thickness (pixels)&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--hide-labels&#x27;</span>, default=<span class="literal">False</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;hide labels&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--hide-conf&#x27;</span>, default=<span class="literal">False</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;hide confidences&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--half&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;use FP16 half-precision inference&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--dnn&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;use OpenCV DNN for ONNX inference&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    opt = parser.parse_args()</span><br><span class="line">    <span class="comment"># 扩充维度, 如果是一位就扩充一位</span></span><br><span class="line">    opt.imgsz *= <span class="number">2</span> <span class="keyword">if</span> <span class="built_in">len</span>(opt.imgsz) == <span class="number">1</span> <span class="keyword">else</span> <span class="number">1</span>  <span class="comment"># expand</span></span><br><span class="line">    <span class="comment"># 输出所有参数</span></span><br><span class="line">    print_args(FILE.stem, opt)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> opt</span><br></pre></td></tr></table></figure></li><li><p>main()</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">opt</span>):</span><br><span class="line">    <span class="comment"># 检查环境/打印参数,主要是requrement.txt的包是否安装，用彩色显示设置的参数</span></span><br><span class="line">    check_requirements(exclude=(<span class="string">&#x27;tensorboard&#x27;</span>, <span class="string">&#x27;thop&#x27;</span>))</span><br><span class="line">    <span class="comment"># 执行run()函数</span></span><br><span class="line">    run(**<span class="built_in">vars</span>(opt))</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>run()</p><ul><li><p>传入参数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">weights=ROOT / <span class="string">&#x27;yolov5s.pt&#x27;</span>,  <span class="comment"># model.pt path(s) # 权重文件地址 默认 weights/可以是自己的路径</span></span></span><br><span class="line"><span class="params">        source=ROOT / <span class="string">&#x27;data/images&#x27;</span>,  <span class="comment"># file/dir/URL/glob, 0 for webcam 0 自带电脑摄像头， 默认data/images/</span></span></span><br><span class="line"><span class="params">        data=ROOT / <span class="string">&#x27;data/coco128.yaml&#x27;</span>,  <span class="comment"># dataset.yaml path, data文件路径，包括类别/图片/标签等信息</span></span></span><br><span class="line"><span class="params">        imgsz=(<span class="params"><span class="number">640</span>, <span class="number">640</span></span>),  <span class="comment"># inference size (height, width) 输入图片的大小 默认640*640</span></span></span><br><span class="line"><span class="params">        conf_thres=<span class="number">0.25</span>,  <span class="comment"># confidence threshold # object置信度阈值 默认0.25  用在nms中</span></span></span><br><span class="line"><span class="params">        iou_thres=<span class="number">0.45</span>,  <span class="comment"># NMS IOU threshold # 做nms的iou阈值 默认0.45   用在nms中</span></span></span><br><span class="line"><span class="params">        max_det=<span class="number">1000</span>,  <span class="comment"># maximum detections per image 每张图片最多的目标数量  用在nms中 </span></span></span><br><span class="line"><span class="params">        device=<span class="string">&#x27;&#x27;</span>,  <span class="comment"># cuda device, i.e. 0 or 0,1,2,3 or cpu 设置代码执行的设备 cuda device, i.e. 0 or 0,1,2,3 or cpu</span></span></span><br><span class="line"><span class="params">        view_img=<span class="literal">False</span>,  <span class="comment"># show results 是否展示预测之后的图片或视频 默认False </span></span></span><br><span class="line"><span class="params">        save_txt=<span class="literal">False</span>,  <span class="comment"># save results to *.txt 是否将预测的框坐标以txt文件形式保存, 默认False, 使用--save-txt 在路径runs/detect/exp*/labels/*.txt下生成每张图片预测的txt文件</span></span></span><br><span class="line"><span class="params">        save_conf=<span class="literal">False</span>,  <span class="comment"># save confidences in --save-txt labels 是否将置信度conf也保存到txt中, 默认False</span></span></span><br><span class="line"><span class="params">        save_crop=<span class="literal">False</span>,  <span class="comment"># save cropped prediction boxes 是否保存裁剪预测框图片, 默认为False, 使用--save-crop 在runs/detect/exp*/crop/剪切类别文件夹/ 路径下会保存每个接下来的目标</span></span></span><br><span class="line"><span class="params">        nosave=<span class="literal">False</span>,  <span class="comment"># do not save images/videos 不保存图片、视频, 要保存图片，不设置--nosave 在runs/detect/exp*/会出现预测的结果</span></span></span><br><span class="line"><span class="params">        classes=<span class="literal">None</span>,  <span class="comment"># filter by class: --class 0, or --class 0 2 3 设置只保留某一部分类别, 形如0或者0 2 3, 使用--classes = n, 则在路径runs/detect/exp*/下保存的图片为n所对应的类别, 此时需要设置data</span></span></span><br><span class="line"><span class="params">        agnostic_nms=<span class="literal">False</span>,  <span class="comment"># class-agnostic NMS 进行NMS去除不同类别之间的框, 默认False</span></span></span><br><span class="line"><span class="params">        augment=<span class="literal">False</span>,  <span class="comment"># augmented inference TTA测试时增强/多尺度预测，可以提分</span></span></span><br><span class="line"><span class="params">        visualize=<span class="literal">False</span>,  <span class="comment"># visualize features 是否可视化网络层输出特征</span></span></span><br><span class="line"><span class="params">        update=<span class="literal">False</span>,  <span class="comment"># update all models 如果为True,则对所有模型进行strip_optimizer操作,去除pt文件中的优化器等信息,默认为False</span></span></span><br><span class="line"><span class="params">        project=ROOT / <span class="string">&#x27;runs/detect&#x27;</span>,  <span class="comment"># save results to project/name 保存测试日志的文件夹路径</span></span></span><br><span class="line"><span class="params">        name=<span class="string">&#x27;exp&#x27;</span>,  <span class="comment"># save results to project/name 每次实验的名称</span></span></span><br><span class="line"><span class="params">        exist_ok=<span class="literal">False</span>,  <span class="comment"># existing project/name ok, do not increment 是否重新创建日志文件, False时重新创建文件</span></span></span><br><span class="line"><span class="params">        line_thickness=<span class="number">3</span>,  <span class="comment"># bounding box thickness (pixels) 画框的线条粗细</span></span></span><br><span class="line"><span class="params">        hide_labels=<span class="literal">False</span>,  <span class="comment"># hide labels 可视化时隐藏预测类别</span></span></span><br><span class="line"><span class="params">        hide_conf=<span class="literal">False</span>,  <span class="comment"># hide confidences 可视化时隐藏置信度</span></span></span><br><span class="line"><span class="params">        half=<span class="literal">False</span>,  <span class="comment"># use FP16 half-precision inference 是否使用F16精度推理, 半进度提高检测速度</span></span></span><br><span class="line"><span class="params">        dnn=<span class="literal">False</span>,  <span class="comment"># use OpenCV DNN for ONNX inference 用OpenCV DNN预测</span></span></span><br><span class="line"><span class="params">        </span>):</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>初始化配置</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">################################################# 1. 初始化配置 #####################################################</span></span><br><span class="line">    <span class="comment"># 输入的路径变为字符串</span></span><br><span class="line">    source = <span class="built_in">str</span>(source)</span><br><span class="line">    <span class="comment"># 是否保存图片和txt文件</span></span><br><span class="line">    save_img = <span class="keyword">not</span> nosave <span class="keyword">and</span> <span class="keyword">not</span> source.endswith(<span class="string">&#x27;.txt&#x27;</span>)  <span class="comment"># save inference images</span></span><br><span class="line">    <span class="comment"># 判断文件是否是视频流</span></span><br><span class="line">    <span class="comment"># Path()提取文件名 例如：Path(&quot;./data/test_images/bus.jpg&quot;) Path.name-&gt;bus.jpg Path.parent-&gt;./data/test_images Path.suffix-&gt;.jpg</span></span><br><span class="line">    is_file = Path(source).suffix[<span class="number">1</span>:] <span class="keyword">in</span> (IMG_FORMATS + VID_FORMATS) <span class="comment"># 提取文件后缀名是否符合要求的文件，例如：是否格式是jpg, png, asf, avi等</span></span><br><span class="line">    <span class="comment"># .lower()转化成小写 .upper()转化成大写 .title()首字符转化成大写，其余为小写, .startswith(&#x27;http://&#x27;)返回True or Flase</span></span><br><span class="line">    is_url = source.lower().startswith((<span class="string">&#x27;rtsp://&#x27;</span>, <span class="string">&#x27;rtmp://&#x27;</span>, <span class="string">&#x27;http://&#x27;</span>, <span class="string">&#x27;https://&#x27;</span>))</span><br><span class="line">    <span class="comment"># .isnumeric()是否是由数字组成，返回True or False</span></span><br><span class="line">    webcam = source.isnumeric() <span class="keyword">or</span> source.endswith(<span class="string">&#x27;.txt&#x27;</span>) <span class="keyword">or</span> (is_url <span class="keyword">and</span> <span class="keyword">not</span> is_file)</span><br><span class="line">    <span class="keyword">if</span> is_url <span class="keyword">and</span> is_file:</span><br><span class="line">        <span class="comment"># 返回文件</span></span><br><span class="line">        source = check_file(source)  <span class="comment"># download</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Directories</span></span><br><span class="line">    <span class="comment"># 预测路径是否存在，不存在新建，按照实验文件以此递增新建</span></span><br><span class="line">    save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)  <span class="comment"># increment run</span></span><br><span class="line">    (save_dir / <span class="string">&#x27;labels&#x27;</span> <span class="keyword">if</span> save_txt <span class="keyword">else</span> save_dir).mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)  <span class="comment"># make dir</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Load model</span></span><br><span class="line">    <span class="comment"># 获取设备 CPU/CUDA</span></span><br><span class="line">    device = select_device(device)</span><br><span class="line">    <span class="comment"># 检测编译框架PYTORCH/TENSORFLOW/TENSORRT</span></span><br><span class="line">    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data)</span><br><span class="line">    stride, names, pt, jit, onnx, engine = model.stride, model.names, model.pt, model.jit, model.onnx, model.engine</span><br><span class="line">    <span class="comment"># 确保输入图片的尺寸imgsz能整除stride=32 如果不能则调整为能被整除并返回</span></span><br><span class="line">    imgsz = check_img_size(imgsz, s=stride)  <span class="comment"># check image size</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Half</span></span><br><span class="line">    <span class="comment"># 如果不是CPU，使用半进度(图片半精度/模型半精度)</span></span><br><span class="line">    half &amp;= (pt <span class="keyword">or</span> jit <span class="keyword">or</span> onnx <span class="keyword">or</span> engine) <span class="keyword">and</span> device.<span class="built_in">type</span> != <span class="string">&#x27;cpu&#x27;</span>  <span class="comment"># FP16 supported on limited backends with CUDA</span></span><br><span class="line">    <span class="keyword">if</span> pt <span class="keyword">or</span> jit:</span><br><span class="line">        model.model.half() <span class="keyword">if</span> half <span class="keyword">else</span> model.model.<span class="built_in">float</span>()</span><br><span class="line">    <span class="comment"># TENSORRT加速</span></span><br><span class="line">    <span class="keyword">elif</span> engine <span class="keyword">and</span> model.trt_fp16_input != half:</span><br><span class="line">        LOGGER.info(<span class="string">&#x27;model &#x27;</span> + (</span><br><span class="line">            <span class="string">&#x27;requires&#x27;</span> <span class="keyword">if</span> model.trt_fp16_input <span class="keyword">else</span> <span class="string">&#x27;incompatible with&#x27;</span>) + <span class="string">&#x27; --half. Adjusting automatically.&#x27;</span>)</span><br><span class="line">        half = model.trt_fp16_input</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>加载数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">################################################# 2. 加载数据 #####################################################</span></span><br><span class="line">    <span class="comment"># Dataloader 加载数据</span></span><br><span class="line">    <span class="comment"># 使用视频流或者页面</span></span><br><span class="line">    <span class="keyword">if</span> webcam:</span><br><span class="line">        view_img = check_imshow()</span><br><span class="line">        cudnn.benchmark = <span class="literal">True</span>  <span class="comment"># set True to speed up constant image size inference</span></span><br><span class="line">        dataset = LoadStreams(source, img_size=imgsz, stride=stride, auto=pt)</span><br><span class="line">        bs = <span class="built_in">len</span>(dataset)  <span class="comment"># batch_size</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 直接从source文件下读取图片</span></span><br><span class="line">        dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt)</span><br><span class="line">        bs = <span class="number">1</span>  <span class="comment"># batch_size</span></span><br><span class="line">    <span class="comment"># 保存的路径</span></span><br><span class="line">    vid_path, vid_writer = [<span class="literal">None</span>] * bs, [<span class="literal">None</span>] * bs</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>输入预测</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">model.warmup(imgsz=(<span class="number">1</span> <span class="keyword">if</span> pt <span class="keyword">else</span> bs, <span class="number">3</span>, *imgsz), half=half)  <span class="comment"># warmup</span></span><br><span class="line">   dt, seen = [<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>], <span class="number">0</span></span><br><span class="line">   <span class="keyword">for</span> path, im, im0s, vid_cap, s <span class="keyword">in</span> dataset:</span><br><span class="line">       t1 = time_sync()</span><br><span class="line">       <span class="comment"># 转化到GPU上</span></span><br><span class="line">       im = torch.from_numpy(im).to(device)</span><br><span class="line">       <span class="comment"># 是否使用半精度</span></span><br><span class="line">       im = im.half() <span class="keyword">if</span> half <span class="keyword">else</span> im.<span class="built_in">float</span>()  <span class="comment"># uint8 to fp16/32</span></span><br><span class="line">       im /= <span class="number">255</span>  <span class="comment"># 0 - 255 to 0.0 - 1.0</span></span><br><span class="line">       <span class="keyword">if</span> <span class="built_in">len</span>(im.shape) == <span class="number">3</span>:</span><br><span class="line">           <span class="comment"># 增加一个维度</span></span><br><span class="line">           im = im[<span class="literal">None</span>]  <span class="comment"># expand for batch dim</span></span><br><span class="line">       t2 = time_sync()</span><br><span class="line">       dt[<span class="number">0</span>] += t2 - t1</span><br><span class="line">     </span><br><span class="line">       <span class="comment"># Inference</span></span><br><span class="line">       <span class="comment"># 可是化文件路径</span></span><br><span class="line">       visualize = increment_path(save_dir / Path(path).stem, mkdir=<span class="literal">True</span>) <span class="keyword">if</span> visualize <span class="keyword">else</span> <span class="literal">False</span></span><br><span class="line">       <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">       pred.shape=(1, num_boxes, 5+num_class)</span></span><br><span class="line"><span class="string">       h,w为传入网络图片的长和宽,注意dataset在检测时使用了矩形推理,所以这里h不一定等于w</span></span><br><span class="line"><span class="string">       num_boxes = h/32 * w/32 + h/16 * w/16 + h/8 * w/8</span></span><br><span class="line"><span class="string">       pred[..., 0:4]为预测框坐标=预测框坐标为xywh(中心点+宽长)格式</span></span><br><span class="line"><span class="string">       pred[..., 4]为objectness置信度</span></span><br><span class="line"><span class="string">       pred[..., 5:-1]为分类结果</span></span><br><span class="line"><span class="string">       &quot;&quot;&quot;</span></span><br><span class="line">       pred = model(im, augment=augment, visualize=visualize)</span><br><span class="line">       t3 = time_sync()</span><br><span class="line">       <span class="comment"># 预测的时间</span></span><br><span class="line">       dt[<span class="number">1</span>] += t3 - t2</span><br><span class="line">     </span><br></pre></td></tr></table></figure></li><li><p>NMS</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># NMS</span></span><br><span class="line">      <span class="comment"># 非极大值抑制</span></span><br><span class="line">      <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">      pred: 网络的输出结果</span></span><br><span class="line"><span class="string">      conf_thres:置信度阈值</span></span><br><span class="line"><span class="string">      ou_thres:iou阈值</span></span><br><span class="line"><span class="string">      classes: 是否只保留特定的类别</span></span><br><span class="line"><span class="string">      agnostic_nms: 进行nms是否也去除不同类别之间的框</span></span><br><span class="line"><span class="string">      max-det: 保留的最大检测框数量</span></span><br><span class="line"><span class="string">      ---NMS, 预测框格式: xywh(中心点+长宽)--&gt;xyxy(左上角右下角)</span></span><br><span class="line"><span class="string">      pred是一个列表list[torch.tensor], 长度为batch_size</span></span><br><span class="line"><span class="string">      每一个torch.tensor的shape为(num_boxes, 6), 内容为box + conf + cls</span></span><br><span class="line"><span class="string">      &quot;&quot;&quot;</span></span><br><span class="line">      pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)</span><br><span class="line">      <span class="comment"># 预测+NMS的时间</span></span><br><span class="line">      dt[<span class="number">2</span>] += time_sync() - t3</span><br><span class="line">     </span><br></pre></td></tr></table></figure></li><li><p>保存打印</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Process predictions</span></span><br><span class="line">        <span class="comment"># 对每张图片做处理</span></span><br><span class="line">        <span class="keyword">for</span> i, det <span class="keyword">in</span> <span class="built_in">enumerate</span>(pred):  <span class="comment"># per image</span></span><br><span class="line">            seen += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> webcam:  <span class="comment"># batch_size &gt;= 1</span></span><br><span class="line">                <span class="comment"># 如果输入源是webcam则batch_size&gt;=1 取出dataset中的一张图片</span></span><br><span class="line">                p, im0, frame = path[i], im0s[i].copy(), dataset.count</span><br><span class="line">                s += <span class="string">f&#x27;<span class="subst">&#123;i&#125;</span>: &#x27;</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 但是大部分我们一般都是从LoadImages流读取本都文件中的照片或者视频 所以batch_size=1</span></span><br><span class="line">                <span class="comment"># p: 当前图片/视频的绝对路径 如 F:\yolo_v5\yolov5-U\data\images\bus.jpg</span></span><br><span class="line">                <span class="comment"># s: 输出信息 初始为 &#x27;&#x27;</span></span><br><span class="line">                <span class="comment"># im0: 原始图片 letterbox + pad 之前的图片</span></span><br><span class="line">                <span class="comment"># frame: 视频流</span></span><br><span class="line">                p, im0, frame = path, im0s.copy(), <span class="built_in">getattr</span>(dataset, <span class="string">&#x27;frame&#x27;</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 当前路径yolov5/data/images/</span></span><br><span class="line">            p = Path(p)  <span class="comment"># to Path</span></span><br><span class="line">            <span class="comment"># 图片/视频的保存路径save_path 如 runs\\detect\\exp8\\bus.jpg</span></span><br><span class="line">            save_path = <span class="built_in">str</span>(save_dir / p.name)  <span class="comment"># im.jpg</span></span><br><span class="line">            <span class="comment"># 设置保存框坐标的txt文件路径，每张图片对应一个框坐标信息</span></span><br><span class="line">            txt_path = <span class="built_in">str</span>(save_dir / <span class="string">&#x27;labels&#x27;</span> / p.stem) + (<span class="string">&#x27;&#x27;</span> <span class="keyword">if</span> dataset.mode == <span class="string">&#x27;image&#x27;</span> <span class="keyword">else</span> <span class="string">f&#x27;_<span class="subst">&#123;frame&#125;</span>&#x27;</span>)  <span class="comment"># im.txt</span></span><br><span class="line">            <span class="comment"># 设置打印图片的信息</span></span><br><span class="line">            s += <span class="string">&#x27;%gx%g &#x27;</span> % im.shape[<span class="number">2</span>:]  <span class="comment"># print string</span></span><br><span class="line">            gn = torch.tensor(im0.shape)[[<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]]  <span class="comment"># normalization gain whwh</span></span><br><span class="line">            <span class="comment"># 保存截图</span></span><br><span class="line">            imc = im0.copy() <span class="keyword">if</span> save_crop <span class="keyword">else</span> im0  <span class="comment"># for save_crop</span></span><br><span class="line">            annotator = Annotator(im0, line_width=line_thickness, example=<span class="built_in">str</span>(names))</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(det):</span><br><span class="line">                <span class="comment"># Rescale boxes from img_size to im0 size</span></span><br><span class="line">                <span class="comment"># 将预测信息映射到原图</span></span><br><span class="line">                det[:, :<span class="number">4</span>] = scale_coords(im.shape[<span class="number">2</span>:], det[:, :<span class="number">4</span>], im0.shape).<span class="built_in">round</span>()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Print results</span></span><br><span class="line">                <span class="comment"># 打印检测到的类别数量</span></span><br><span class="line">                <span class="keyword">for</span> c <span class="keyword">in</span> det[:, -<span class="number">1</span>].unique():</span><br><span class="line">                    n = (det[:, -<span class="number">1</span>] == c).<span class="built_in">sum</span>()  <span class="comment"># detections per class</span></span><br><span class="line">                    s += <span class="string">f&quot;<span class="subst">&#123;n&#125;</span> <span class="subst">&#123;names[<span class="built_in">int</span>(c)]&#125;</span><span class="subst">&#123;<span class="string">&#x27;s&#x27;</span> * (n &gt; <span class="number">1</span>)&#125;</span>, &quot;</span>  <span class="comment"># add to string</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># Write results</span></span><br><span class="line">                <span class="comment"># 保存结果： txt/图片画框/crop-image</span></span><br><span class="line">                <span class="keyword">for</span> *xyxy, conf, cls <span class="keyword">in</span> <span class="built_in">reversed</span>(det):</span><br><span class="line">                    <span class="comment"># 将每个图片的预测信息分别存入save_dir/labels下的xxx.txt中 每行: class_id + score + xywh</span></span><br><span class="line">                    <span class="keyword">if</span> save_txt:  <span class="comment"># Write to file</span></span><br><span class="line">                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(<span class="number">1</span>, <span class="number">4</span>)) / gn).view(-<span class="number">1</span>).tolist()  <span class="comment"># normalized xywh</span></span><br><span class="line">                        line = (cls, *xywh, conf) <span class="keyword">if</span> save_conf <span class="keyword">else</span> (cls, *xywh)  <span class="comment"># label format</span></span><br><span class="line">                        <span class="keyword">with</span> <span class="built_in">open</span>(txt_path + <span class="string">&#x27;.txt&#x27;</span>, <span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                            f.write((<span class="string">&#x27;%g &#x27;</span> * <span class="built_in">len</span>(line)).rstrip() % line + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">                    <span class="comment"># # 在原图上画框 + 将预测到的目标剪切出来 保存成图片 保存在save_dir/crops下 在原图像画图或者保存结果</span></span><br><span class="line">                    <span class="keyword">if</span> save_img <span class="keyword">or</span> save_crop <span class="keyword">or</span> view_img:  <span class="comment"># Add bbox to image</span></span><br><span class="line">                        c = <span class="built_in">int</span>(cls)  <span class="comment"># integer class</span></span><br><span class="line">                        label = <span class="literal">None</span> <span class="keyword">if</span> hide_labels <span class="keyword">else</span> (names[c] <span class="keyword">if</span> hide_conf <span class="keyword">else</span> <span class="string">f&#x27;<span class="subst">&#123;names[c]&#125;</span> <span class="subst">&#123;conf:<span class="number">.2</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">                        annotator.box_label(xyxy, label, color=colors(c, <span class="literal">True</span>))</span><br><span class="line">                        <span class="keyword">if</span> save_crop:</span><br><span class="line">                            <span class="comment"># 在原图上画框 + 将预测到的目标剪切出来 保存成图片 保存在save_dir/crops下</span></span><br><span class="line">                            save_one_box(xyxy, imc, file=save_dir / <span class="string">&#x27;crops&#x27;</span> / names[c] / <span class="string">f&#x27;<span class="subst">&#123;p.stem&#125;</span>.jpg&#x27;</span>, BGR=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Stream results</span></span><br><span class="line">            im0 = annotator.result()</span><br><span class="line">            <span class="comment"># 显示图片</span></span><br><span class="line">            <span class="keyword">if</span> view_img:</span><br><span class="line">                cv2.imshow(<span class="built_in">str</span>(p), im0)</span><br><span class="line">                cv2.waitKey(<span class="number">1</span>)  <span class="comment"># 1 millisecond</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Save results (image with detections)</span></span><br><span class="line">            <span class="comment"># 保存图片</span></span><br><span class="line">            <span class="keyword">if</span> save_img:</span><br><span class="line">                <span class="keyword">if</span> dataset.mode == <span class="string">&#x27;image&#x27;</span>:</span><br><span class="line">                    cv2.imwrite(save_path, im0)</span><br><span class="line">                <span class="keyword">else</span>:  <span class="comment"># &#x27;video&#x27; or &#x27;stream&#x27;</span></span><br><span class="line">                    <span class="keyword">if</span> vid_path[i] != save_path:  <span class="comment"># new video</span></span><br><span class="line">                        vid_path[i] = save_path</span><br><span class="line">                        <span class="keyword">if</span> <span class="built_in">isinstance</span>(vid_writer[i], cv2.VideoWriter):</span><br><span class="line">                            vid_writer[i].release()  <span class="comment"># release previous video writer</span></span><br><span class="line">                        <span class="keyword">if</span> vid_cap:  <span class="comment"># video</span></span><br><span class="line">                            fps = vid_cap.get(cv2.CAP_PROP_FPS)</span><br><span class="line">                            w = <span class="built_in">int</span>(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))</span><br><span class="line">                            h = <span class="built_in">int</span>(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))</span><br><span class="line">                        <span class="keyword">else</span>:  <span class="comment"># stream</span></span><br><span class="line">                            fps, w, h = <span class="number">30</span>, im0.shape[<span class="number">1</span>], im0.shape[<span class="number">0</span>]</span><br><span class="line">                        save_path = <span class="built_in">str</span>(Path(save_path).with_suffix(<span class="string">&#x27;.mp4&#x27;</span>))  <span class="comment"># force *.mp4 suffix on results videos</span></span><br><span class="line">                        vid_writer[i] = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*<span class="string">&#x27;mp4v&#x27;</span>), fps, (w, h))</span><br><span class="line">                    vid_writer[i].write(im0)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Print time (inference-only)</span></span><br><span class="line">        LOGGER.info(<span class="string">f&#x27;<span class="subst">&#123;s&#125;</span>Done. (<span class="subst">&#123;t3 - t2:<span class="number">.3</span>f&#125;</span>s)&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ul></li></ol><h3 id="四、扩展使用方法"><a href="#四、扩展使用方法" class="headerlink" title="四、扩展使用方法"></a>四、扩展使用方法</h3><ol><li><strong>在</strong><code>python</code><strong>文件中运行</strong></li><li><strong>加入项目使用</strong></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>git:gitignore文件</title>
      <link href="/posts/a58ad574.html"/>
      <url>/posts/a58ad574.html</url>
      
        <content type="html"><![CDATA[<h1 id="Git-gitignore文件的配置使用"><a href="#Git-gitignore文件的配置使用" class="headerlink" title="[Git].gitignore文件的配置使用"></a><code>[Git].gitignore</code>文件的配置使用</h1><h4 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h4><ul><li><code>.gitignore</code>文件： 可以设置相应的忽略规则，在使用<code>git add .</code>的时候忽略这些文件的提交。</li><li><code>git add -f</code>可以强制添加被<code>.gitignore</code>设置了忽略规则的文件</li><li><code>可使用git config --global core.excludesfile ~/.gitignore</code>指令定义Git全局的 <code>.gitignore</code> 文件</li><li>也可以当前项目下的 <code>.git/info/exclude</code>文件，将需要忽略提交的文件写入其中，已实现相同功能</li></ul><h5 id="二、使用方法演示"><a href="#二、使用方法演示" class="headerlink" title="二、使用方法演示"></a>二、使用方法演示</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># dir 不需要提交的目录</span></span><br><span class="line">/node_modules</span><br><span class="line"></span><br><span class="line"><span class="comment"># file 不需要提交的文件</span></span><br><span class="line">config.ini</span><br><span class="line"></span><br><span class="line"><span class="comment"># log 不需要提交的任意包含后缀名为log的文件</span></span><br><span class="line">*.log</span><br><span class="line"></span><br><span class="line"><span class="comment"># Package Files 不需要提交的任意包含后缀名为jar的文件</span></span><br><span class="line">*.jar</span><br></pre></td></tr></table></figure><h5 id="三、使用方法详解"><a href="#三、使用方法详解" class="headerlink" title="三、使用方法详解"></a>三、使用方法详解</h5><ol><li></li><li></li><li><p><strong><code>.gitignore</code>语法</strong></p><ul><li><code>#</code>： 注释</li><li><code>*</code>： 匹配0个或多个任意字符</li><li><code>!</code>： 不忽略，例如：!1.txt,  表示不忽略1.txt文件，git add 可以正常添加此文件。</li><li><code>\</code>:  以<code>\</code>开头表示目录， 目录以<code>\</code>结尾只忽略目录下的文件，不忽略此目录</li></ul></li></ol><p><a href="https://juejin.cn/post/7155653345813168142">https://juejin.cn/post/7155653345813168142</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>yolov5环境搭建</title>
      <link href="/posts/2e7109a8.html"/>
      <url>/posts/2e7109a8.html</url>
      
        <content type="html"><![CDATA[<h1 id="YOLOv5模型：-环境部署"><a href="#YOLOv5模型：-环境部署" class="headerlink" title="YOLOv5模型： 环境部署"></a>YOLOv5模型： 环境部署</h1><h3 id="一、🏴总概述-教程原文链接"><a href="#一、🏴总概述-教程原文链接" class="headerlink" title="一、🏴总概述  教程原文链接"></a>一、🏴总概述  <a href="https://aitechtogether.com/article/32386.html">教程原文链接</a></h3><ol><li>✨GPU/CPU环境详解及安装</li><li>✨GPU/CPU环境详解及安装</li><li>🌟Labelimg数据标注及数据转化</li></ol><h3 id="二、✨GPU-CPU环境详解及安装"><a href="#二、✨GPU-CPU环境详解及安装" class="headerlink" title="二、✨GPU/CPU环境详解及安装"></a>二、✨GPU/CPU环境详解及安装</h3><ol><li><p>什么是CPU？什么GPU？</p><ul><li>CPU主要用于串行运算；而GPU则是大规模并行运算。由于<a href="https://aitechtogether.com/tag/深度学习">深度学习</a>中样本量巨大，参数量也很大，所以GPU的作用就是加速网络运算</li><li>CPU计算神经网络也是可以的，算出来的神经网络放到实际应用中效果也很好，只不过速度会很慢罢了。而目前GPU运算主要集中在矩阵乘法和卷积上，其他的逻辑运算速度并没有CPU快</li></ul></li><li><p>我该选择使用GPU还是CPU？</p><ul><li>GPU和CPU的选择一方面看自己的需求，另一方面取决于自己的PC性能（如果你拥有一块RTX3060，而你刚好对深度学习感兴趣，那你有什么利用不利用起来它呢）。</li></ul></li><li><p>怎么安装GPU环境</p><ol><li><p>安装GPU环境需要我们首先安装CUDA和CUDNN</p><ul><li>CUDA: ComputeUnified Device Architecture)，是显卡厂商NVIDIA推出的运算平台。 CUDA是一种由NVIDIA推出的通用并行计算架构，该架构使GPU能够解决复杂的计算问题。</li><li>CUDNN:NVIDIA cuDNN是用于深度神经网络的GPU加速库。它强调性能、易用性和低内存开销。</li></ul></li><li><p>​    查看本机显卡</p><ul><li>首先我们要确定本机是否有独立显卡，在<code>计算机管理-设备管理器-显示适配器</code>中，查看是否有独立显卡</li><li>如下图所示：可以看到本机有一个集成显卡和独立显卡<code>NVIDIA GetForce GTX 1050</code>。</li><li><img src="https://aitechtogether.com/wp-content/uploads/2022/05/954b992d-e5c0-4386-8586-9786586f4d55.webp" alt="img"></li></ul></li><li><p>​    查询是否支持CUDA安装</p><ol><li>进入：<a href="https://developer.nvidia.com/cuda-gpus">https://developer.nvidia.com/cuda-gpus</a> ：从下图中，从上图中，可以看到我本机的独立显卡是支持<code>CUDA</code>安装的，计算力是<code>6.1</code>。<ul><li><img src="https://aitechtogether.com/wp-content/uploads/2022/05/80169db8-01f8-4886-bcca-e123f0194ee1.webp" alt="img"></li><li><img src="https://aitechtogether.com/wp-content/uploads/2022/05/f9c3701f-d144-469c-9b84-0110479b5fd9.webp" alt="img"></li></ul></li></ol></li><li><p>CUDA下载</p><ol><li>进入<a href="https://developer.nvidia.com/cuda-toolkit-archive">https://developer.nvidia.com/cuda-toolkit-archive</a> ：在这里会有众多CUDA版本，关于如何选择，我不能给出详细说法，只能说说我的理解。（<code>CUDA的安装主要取决于个人使用要求和硬件性能，如你是RTX3060及以上的30系显卡我推荐你安装CUDA11.x，如果你像我一样是RTX1050这样不太高端显卡，选择CUDA9.x和CUDA10.x均可以,以我的习惯就是下载CUDA10.2</code>）<ul><li><img src="https://aitechtogether.com/wp-content/uploads/2022/05/69ec64d1-f18d-40cb-a818-733503df572a.webp" alt="img"></li><li><em>从上到下<em>*依次单击选择</em></em>：<code>Operating System</code>、<code>Architecture</code>、<code>Version</code>、<code>Installer Type</code>、“Download`。等待下载，下载完成后你就会获得安装包。</li><li><img src="https://aitechtogether.com/wp-content/uploads/2022/05/5cb89445-c851-4542-8420-28719126c663.webp" alt="img"></li></ul></li></ol></li><li><p>CUDA安装</p><ol><li><p>双击打开，显示解压安装目录，<strong>不需要改变，默认即可</strong>。</p><p><img src="https://aitechtogether.com/wp-content/uploads/2022/05/39e65fd2-1e5e-4804-b70a-14f84173c8b1.webp" alt="img"></p></li><li><p>默认安装，保证后续过程不会出现太多其他不必要的问题！</p></li><li><p>接下来，进入<code>NVIDIA</code>安装过程，在这安装过程中，我一开始直接选择的精简安装，如果由于VS的原因，导致无法正常安装，可以换成自定义的安装方式，并将VS勾给去掉，便可以正常安装了，至于CUDA的安装目录，大家默认安装在C盘即可。</p></li><li><p><img src="https://aitechtogether.com/wp-content/uploads/2022/05/8663c9b2-e31a-4707-aa2e-bf564ffa3e41.webp" alt="img"></p></li></ol></li><li><p>CUDA环境变量设置</p><ol><li><p>安装完成之后，便是配置环境变量。方法为：<code>右键我的电脑</code>–<code>属性</code>–<code>高级系统设置</code>–<code>环境变量</code>–<code>系统变量</code>–<code>找到变量名为PATH</code>–<code>双击打开</code>，添加以下环境变量。</p><p><img src="https://aitechtogether.com/wp-content/uploads/2022/05/8104fb94-53b2-41e1-822a-0bd8bbef2c52.webp" alt="img"></p><ul><li><p>新增变量</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.2</span><br><span class="line">C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.2\lib\x64</span><br><span class="line">C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.2\lib</span><br><span class="line">C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.2\libnvvp</span><br></pre></td></tr></table></figure></li><li><p>测试安装, 有以下输出即为安装正确！</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ nvcc -V</span><br><span class="line">nvcc: NVIDIA (R) Cuda compiler driver</span><br><span class="line">Copyright (c) 2005-2019 NVIDIA Corporation</span><br><span class="line">Built on Wed_Oct_23_19:32:27_Pacific_Daylight_Time_2019</span><br><span class="line">Cuda compilation tools, release 10.2, V10.2.89</span><br></pre></td></tr></table></figure></li></ul></li></ol></li><li><p>CUDNN下载</p><ol><li><p>进入<a href="https://developer.nvidia.com/zh-cn/cudnn">https://developer.nvidia.com/zh-cn/cudnn</a> ，点击<code>下载cuDNN</code>会出现</p></li><li><p>这里写的很明白，就是必须你注册登录账户才有资格下载，因此你注册一个账户登录进去即可！</p><p><img src="https://aitechtogether.com/wp-content/uploads/2022/05/b99810f8-f1dc-47a8-aa4e-ab32b51fdcdd.webp" alt="img"></p></li><li><p>登录进去以后，点击选择相应的下载即可，但是要注意：<strong>CUDA的版本与CUDNN的版本要一致</strong></p><ul><li>在要下载的CUDNN的点击名称最后会有<code>CUDA 10.0</code>或者<code>CUDA 10.2</code>这样的后缀，这就是代表与相应CUDA对应版本的CUDNN。</li></ul></li></ol></li><li><p>CUDNN安装</p><ol><li>下载之后，你会得到一个zip的压缩包。解压缩，将CUDNN压缩包里面的<code>bin</code>、<code>include</code>、<code>lib</code>三整个文件夹直接复制到<code>CUDA的安装目录</code>下，<strong>覆盖掉原来CUDA的这三个文件夹</strong> 即可。</li></ol></li><li><p>GPU版本的Pytorch安装</p><ol><li><p>🟢在线安装</p><ol><li><p>有了本地的GPU环境，我们就可以安装<code>GPU版本的Pytorch了</code>。进入<a href="https://pytorch.org/">https://pytorch.org/</a> ，点击<code>INXTALL</code>：</p><p><img src="https://aitechtogether.com/wp-content/uploads/2022/05/d563d4be-abff-484f-b47e-88ffb8e25a6b.webp" alt="img"></p></li><li><p>根据自己的需求和安装的CUDA的版本对应安装Pytorch，复制输出的命令即可。如果下方<strong>Run this Command</strong>提醒<strong>CUDA-10.2 PyTorch builds are no longer available for Windows, please use CUDA-11.3 ，</strong> 可以访问：<a href="https://pytorch.org/get-started/previous-versions/">https://pytorch.org/get-started/previous-versions/</a> 查找之前的版本在线安装。</p></li></ol></li><li><p>🟡离线安装</p><ol><li><p>📌 方法一：进入官网下载地址，<a href="https://download.pytorch.org/whl/torch/">torch安装包列表</a> | <a href="https://download.pytorch.org/whl/torchvision/">torchvision安装包列表</a></p></li><li><p>📌 方法二：进入官网指定的CUDA版本下载地址：<a href="https://download.pytorch.org/whl/cu113/torch_stable.html">https://download.pytorch.org/whl/cu113/torch_stable.html</a> （以CUDA11.3为例）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 标*部分可以根据自己的CUDA型号进行搜索，比如CUDA 10.2对应为102，CUDA11.3对应为113</span><br><span class="line">https://download.pytorch.org/whl/cu***/torch_stable.html</span><br></pre></td></tr></table></figure></li><li><p>根据自己的实验环境，包括操作系统、CUDA类型、Python版本等，选择安装的<code>torch</code>和<code>torchvision</code>的安装包</p><p><img src="https://aitechtogether.com/wp-content/uploads/2022/05/fa5f2c6f-cd72-46b9-a489-90b1bf44af19.webp" alt="img"></p></li><li><p>```python<br>pip install ./torch-<strong><em>.whl # 先安装<br>pip install ./torchvision-</em></strong>.whl # 后安装</p><h1 id="注意：这里存在安装顺序，由于torch是torchvision的上级安装包，如果先安装torchvision，则会自动下载torch安装-包。因此先安装torch，再安装torchvision"><a href="#注意：这里存在安装顺序，由于torch是torchvision的上级安装包，如果先安装torchvision，则会自动下载torch安装-包。因此先安装torch，再安装torchvision" class="headerlink" title="注意：这里存在安装顺序，由于torch是torchvision的上级安装包，如果先安装torchvision，则会自动下载torch安装# 包。因此先安装torch，再安装torchvision"></a>注意：这里存在安装顺序，由于torch是torchvision的上级安装包，如果先安装torchvision，则会自动下载torch安装# 包。因此先安装torch，再安装torchvision</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">         5. 👉最后，给大家放一个Pytorch和torchvision对应的版本表：https://github.com/pytorch/pytorch/wiki/PyTorch-Versions</span><br><span class="line"></span><br><span class="line">            至此，所有比较麻烦的环境安装问题基本解决完成了，接下来我们就可以去找数据、标数据、训数据了。</span><br><span class="line"></span><br><span class="line">      </span><br><span class="line"></span><br><span class="line">## 三、🌟Labelimg数据标注及数据转化</span><br><span class="line"></span><br><span class="line">1. 初识Labelimg</span><br><span class="line"></span><br><span class="line">   - 用于深度网络训练的数据集做标注的方法和工具有好多，像Labelme、labelImg、yolo_mark、Vatic、Sloth等等，此处暂时只介绍其中的一种标注工具：labelImg。👁️‍🗨️[中文版本的labelImg下载](https://mianbaoduo.com/o/bread/mbd-YpqZm5lx)</span><br><span class="line"></span><br><span class="line">     ![img](https://aitechtogether.com/wp-content/uploads/2022/05/3f601c82-5884-485f-9096-5e4d761ef477.webp)</span><br><span class="line"></span><br><span class="line">   - [Labelimg](https://github.com/tzutalin/labelImg) 是一款开源的数据标注工具，可以标注三种格式：</span><br><span class="line"></span><br><span class="line">     1. PascalVOC标签格式，保存为xml文件</span><br><span class="line">     2. YOLO标签格式，保存为txt文件</span><br><span class="line">     3. CreateML标签格式，保存为json文件images</span><br><span class="line"></span><br><span class="line">2. Labelimg标注</span><br><span class="line"></span><br><span class="line">   1. 我们找一个新的位置，新建两个文件夹：存放图片：`images`，存放标签：`labels`，然后打开labelimg进行标注就可以了。</span><br><span class="line"></span><br><span class="line">      ```bash</span><br><span class="line">      .</span><br><span class="line">      │</span><br><span class="line">      ├─images</span><br><span class="line">      ├─ 1.jpg</span><br><span class="line">          ├─ 2.jpg</span><br><span class="line">          ├─ 3.jpg</span><br><span class="line">              ...</span><br><span class="line">      └─labels</span><br><span class="line">      ├─ 1.txt</span><br><span class="line">          ├─ 2.txt</span><br><span class="line">          ├─ 3.txt</span><br><span class="line">      </span><br><span class="line">      # 注意如果你发现你的图片的后缀不一致，最好是修改成一样的，避免后续的麻烦！！！（可以看到我这里JPEGImages文件夹下都是.jpg结尾的）</span><br><span class="line">      # bach脚本（这里的意思是将.jpg修改成.jpeg） </span><br><span class="line">      &gt;&gt;&gt;ren *.jpg *.jpeg </span><br><span class="line">        </span><br></pre></td></tr></table></figure></li></ol></li></ol></li><li><p>超级详细的标注过程看这里：<a href="https://blog.csdn.net/shuiyixin/article/details/82623613">YOLO数据集制作1（含LabelImg工具讲解）</a></p></li></ol></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>正则表达式</title>
      <link href="/posts/2f57a694.html"/>
      <url>/posts/2f57a694.html</url>
      
        <content type="html"><![CDATA[<p><h3> 一. 使用正则表达式查找文本模式<h3></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 字符串</span></span><br><span class="line">regex_str = <span class="string">&quot;1. wubba lubba dub dubs. 2. Hey, what are you in for? - Everyting. 3. Homework is stupid, the whole point is to get less of it.&quot;</span></span><br></pre></td></tr></table></figure><p><h4>1、正则操作步骤<h4></p><ul><li>基础流程如下<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">regex = re.<span class="built_in">compile</span>(<span class="string">&#x27;\d&#x27;</span>)        <span class="comment"># 正则表达式</span></span><br><span class="line">result = regex.search(regex_str)    <span class="comment"># 查找</span></span><br><span class="line"><span class="built_in">print</span>(result.group())   <span class="comment"># 返回结果</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行结果： 1</span></span><br></pre></td></tr></table></figure></li><li>流程解析 <br><ol><li>导入<code>re</code>模块</li><li>传入正则表达式，返回值为<code>regex</code>对象。</li><li>使用<code>regex</code>对象方法（<code>search</code>）查找匹配正则表达式， 返回<code>Match</code>对象</li><li>使用<code>Match</code>对象的方法（<code>group</code>）获取匹配的值。</li></ol></li><li><strong>知识点 01 字符替换</strong><ol><li><code>\d</code>: 表示一个数字 0~9</li><li><code>\w</code>: 表示一个下划线、数字、或字母</li><li><code>\s</code>: 表示一个空格、制表、换行</li></ol></li></ul><p><h4>2、分组 <h4></p><ul><li>代码演示<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">regex = re.<span class="built_in">compile</span>(<span class="string">&quot;(\d).*(\d).*(\d)&quot;</span>)  <span class="comment"># 分三组</span></span><br><span class="line">result = regex.search(regex_str)</span><br><span class="line"><span class="built_in">print</span>(result.group())</span><br><span class="line"><span class="comment"># 运行结果：1. wubba lubba dub dubs. Hey, 2. what are you in for? - Everyting. 3</span></span><br><span class="line"><span class="built_in">print</span>(result.group(<span class="number">1</span>))  <span class="comment"># 打印匹配到的第一组的值</span></span><br><span class="line"><span class="comment"># 运行结果： 1  </span></span><br><span class="line"><span class="built_in">print</span>(result.groups())  <span class="comment"># 打印匹配到的所有组的值</span></span><br><span class="line"><span class="comment"># 运行结果：(&#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;)</span></span><br></pre></td></tr></table></figure><strong>- 知识点 2 括号</strong></li></ul><ol><li>第一个括号内的表达式为第一组，可使用<code>group(1)</code>取值</li><li><code>groups()</code> 获取所有分组。</li></ol><p><h4>3、字符<h4></p><ul><li>代码演示<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">regex = re.<span class="built_in">compile</span>(<span class="string">&quot;(b)&#123;2&#125;&quot;</span>)  <span class="comment"># 分三组</span></span><br><span class="line">result = regex.search(regex_str)</span><br><span class="line"><span class="built_in">print</span>(result.group())</span><br><span class="line"><span class="comment"># 运行结果： bb</span></span><br><span class="line"><span class="built_in">print</span>(result.groups())</span><br><span class="line"><span class="comment"># 运行结果: (&#x27;b&#x27;,)</span></span><br></pre></td></tr></table></figure><strong>- 知识点 3 贪心匹配</strong></li></ul><ol><li><code>()&#123;N&#125;</code> 表示匹配括号内表达式 N次。</li><li><code>()&#123;1,3&#125;</code> 优先匹配3次</li><li><code>()&#123;1,&#125;</code> 优先配对最大值(<code>max</code>)</li><li><code>()&#123;,2&#125;</code> 优先配对2次，(<em>找不到值则返回为<code>None</code></em>)</li><li><code>()&#123;1,3&#125;?</code> 非贪心匹配</li></ol><p><h4>4、通配符<h4></p><ol><li><code>+</code>： 加号表示匹配一次或多次。</li><li><code>*</code>： 星号表示匹配零次或多次。</li><li><code>?</code>： 问号表示匹配零次或一次。</li><li><code>.</code>:  表示任意一个字符，非换行符之外的所有字符</li><li><code>^a</code>：表示以a开头的字符。</li><li><code>$a</code>: 表示以a结尾的字符。</li><li><code>&#123;N&#125;</code>: 表示匹配次数。</li><li><code>[auc]</code>: 表示单字符选择范围(<code>a u c</code>)</li><li><code>[^auc]</code>:表示单字符选择范围(除<code>a u c</code>外字符)</li></ol><p><h4>5、扩展<h4></p><ul><li><p>代码演示，<code>compile</code> 参数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">regex = re.<span class="built_in">compile</span>(<span class="string">&quot;.*&quot;</span>, re.DOTALL) <span class="comment"># 匹配所有字符，包括换行符</span></span><br><span class="line"></span><br><span class="line">regex = re.<span class="built_in">compile</span>(<span class="string">&quot;aAsA&quot;</span>, re.IGNORECASE)    <span class="comment"># 不区分大小写</span></span><br><span class="line"></span><br><span class="line">regex = re.<span class="built_in">compile</span>(<span class="string">&#x27;&#x27;&#x27;(wubba).*  # 注释</span></span><br><span class="line"><span class="string">(dub)  # 注释&#x27;&#x27;&#x27;</span>, re.VERBOSE)  </span><br><span class="line">result = regex.search(regex_str)</span><br><span class="line"><span class="comment">#运行结果: wubba lubbba dub dub</span></span><br><span class="line"><span class="built_in">print</span>(result.group())</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>代码演示， <code>re</code> 基础方法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">regex = re.<span class="built_in">compile</span>(<span class="string">&quot;(\d)(bb)&quot;</span>)</span><br><span class="line">regex.sub(<span class="string">&quot;www&quot;</span>, <span class="string">&quot;111bbbb, 111&quot;</span>) </span><br><span class="line"><span class="comment">#运行结果: 11wwwbb, 111</span></span><br><span class="line"></span><br><span class="line">regex.sub(<span class="string">&quot;\2***&quot;</span>, <span class="string">&quot;111bbbb, 111&quot;</span>)</span><br><span class="line"><span class="comment">#运行结果: 11***bb, 111</span></span><br><span class="line"></span><br><span class="line">result = re.<span class="keyword">match</span>(<span class="string">&quot;\w\d\w&quot;</span>, <span class="string">&quot;111 11111 111&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(result.group())</span><br><span class="line"><span class="comment">#运行结果: 111</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>git</title>
      <link href="/posts/518e617c.html"/>
      <url>/posts/518e617c.html</url>
      
        <content type="html"><![CDATA[<h3 id="Git-学习笔记"><a href="#Git-学习笔记" class="headerlink" title="Git 学习笔记"></a>Git 学习笔记</h3><ol><li><p><code>git</code> 基本介绍 <br></p><ul><li><p>是什么 <br></p><ol><li>一个代码管理的工具。</li><li>可以随时将本地仓库的代码提交至远程仓库</li><li><em>懒得打字</em></li></ol></li><li><p>流程</p><ol><li>下载安装并配置git</li><li>生成密钥对：<em>公钥</em> - <code>id_rsa.pub</code>  <em>私钥</em> - <code>id_rsa</code></li><li>创建远程仓库，上传公钥。</li><li>克隆代码到本地</li><li>提交代码.</li></ol></li></ul></li><li><code>git</code> 下载与安装。 <br><ul><li>指令</li><li><code>git version</code>: 查看版本号</li><li>注： <code>MAC 需要安装一下xcode: xcode-select --install</code></li></ul></li><li><code>git</code> 配置 <br><ul><li><code>git config --list</code>: 查看git当前的config配置</li><li><code>ssh-keygen -t rsa -C “your_email@youremail.com&quot;</code>: 生成密钥对。</li><li><code>git clone git@github.com:Yourcount/GitTest.ogt</code>: 克隆远程仓库。</li></ul></li><li><code>git</code> 日常使用命令。 <br><ul><li><code>git branch</code>: 查看本地分支</li><li><code>git baranch</code>: 查看所有分支。<br> <code>remotes/origin</code>为远程分支。</li><li><code>git branch -av</code>: 查看所有分支与最近的一条提交记录。</li><li><code>git branch -avv</code>: 查看分支，以及关联的仓库</li><li><code>git remote show otigin</code>: 查看远程分支直接的关系</li><li><code>git stauts</code>: 查看本地仓库状态</li><li><code>git diff</code>: 查看改动内容</li><li><code>git add .</code>: 添加</li><li><code>git reset .</code>: 撤销添加</li><li><code>git commit -m &quot;描述&quot;</code>: 提交本次改动</li><li><code>git commit -s</code></li><li><code>git log</code>: 查看提交日志</li><li><code>git push origin Head:main</code>: 提交至远程仓库</li><li><code>git pull - rebase</code>: 下拉仓库</li><li><code>git push</code>: 提交</li><li><code>git checkout -b V2</code>: 创建本地分支，并切换至此分支</li><li><code>git checkout V2</code>: 切换分支</li><li><code>git push origin V2:remote_branch_V2</code>:创建远程分支</li><li><code>git push origin :remote_branch_V2</code>:删除。push空就等于删除</li><li><code>git checkout -b v2 origin/main</code>: 拉取分支并建立关系</li><li><code>git config --global push.default upstream</code>: 设置push推送代码到本地分支关联的远程分支</li></ul></li><li>撤销操作<br><ul><li><code>git checkout</code> . // 代码改动后，撤销所有改动</li><li><code>git reset a</code> // git add a 后，撤销对a的add</li><li><code>git reset .</code> // git add . 后，撤销add所有</li><li><code>git reset HEAD~1</code> // 已经commit，在当前分支回退1条commit，当然2就是2条;回退后修改内容还在本地</li><li><code>git revert HEAD~1</code> //已经push，回滚这条记录，需要注意的是执行完后需要继续执行以下三行才可以，因为远端会保留revert记录<ol><li><code>git add .</code></li><li><code>git commit -a</code></li><li><code>git push</code></li></ol></li></ul></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Markdown基本语法.md</title>
      <link href="/posts/116d0b7e.html"/>
      <url>/posts/116d0b7e.html</url>
      
        <content type="html"><![CDATA[<h1 id="Markdown-标题语法"><a href="#Markdown-标题语法" class="headerlink" title="Markdown 标题语法"></a>Markdown 标题语法</h1><p>1、创建标题：在内容最前面添加“#”好就可以创建标题，“#”的数量代表这标题的级别。如下演示,注意书写 # 写这最前面，空一行再添加内容，不需要加双引号。</p><h2 id="“-”二级标题"><a href="#“-”二级标题" class="headerlink" title="“##”二级标题"></a>“##”二级标题</h2><h3 id="“-”三级标题"><a href="#“-”三级标题" class="headerlink" title="“###”三级标题"></a>“###”三级标题</h3><h4 id="“-”四级标题"><a href="#“-”四级标题" class="headerlink" title="“####”四级标题"></a>“####”四级标题</h4><h5 id="“-”五级标题"><a href="#“-”五级标题" class="headerlink" title="“#####”五级标题"></a>“#####”五级标题</h5><p>2、也可以使用“==”创建一级标题，“—”创建二级标题。  </p><h1 id="例如，这是一级标题"><a href="#例如，这是一级标题" class="headerlink" title="例如，这是一级标题"></a>例如，这是一级标题</h1><h2 id="这是二级标题"><a href="#这是二级标题" class="headerlink" title="这是二级标题"></a>这是二级标题</h2><p>3、段落一： 需要敲两次回车，推荐不要使用空格和制表符缩进段落，最后使用空白行隔开。</p><p>段落二：</p><p>4、换行，在一行的末尾添加两个或多个空格，然后按回车键。<br>也可以使用br来换行。例如：<br><br></p><h1 id="Markdown-强调语法"><a href="#Markdown-强调语法" class="headerlink" title="Markdown 强调语法"></a>Markdown 强调语法</h1><p>0、<em>斜体：</em>在单词前后各添加一个星号“<em>”<br><br>1、<strong>粗体（Bold）：</strong> 在单词前后各添加两个星号“<strong>”就可以讲星号中的内容变为粗体。<br><br>2、</strong></em>斜粗体(ltalic)：<strong><em> 在单词前后各添加加三个星号“</em></strong>”或者三个下划线”<strong><em>“,例如：</em></strong>斜粗体<em>_</em> .<br><br></p><h1 id="Markdown-引用语法"><a href="#Markdown-引用语法" class="headerlink" title="Markdown 引用语法"></a>Markdown 引用语法</h1><p>0、创建块引用，需要在段落前添加一个 <strong>&gt;</strong> <br></p><blockquote><ul><li>这是一个块引用 <br></li><li>第二行不需要添加 <em>&gt;</em><blockquote><p>嵌套的块引用，在段落前添加两个即可 <strong>&gt;&gt;</strong> <br><br>第二行也不需要添加  </p></blockquote></li></ul></blockquote><p>退出按两下回车即可。<br></p><h1 id="Markdown-列表语法"><a href="#Markdown-列表语法" class="headerlink" title="Markdown 列表语法"></a>Markdown 列表语法</h1><p>1、<strong>有序列表</strong>：每段前加上“1.”就可以了，每个列表项前添加数字并紧跟着一个英文句点。数字不用连续但必须以 1 开头。</p><ol><li>有序列表 1</li><li>有序列表 2</li><li>有序列表 3</li></ol><p>2、<strong>无序列表</strong>：在每个列表前添加破折号“-”，星号“*”，加号“+”。缩进一个或多个列表项可创建嵌套列表。</p><ul><li>无序列表 1</li><li>无序列表 2<ul><li>无序列表嵌套 1</li><li>无序列表嵌套 2<br>非无序列表</li></ul></li><li>无序列表 3<br>  非无序列表</li></ul><p>3、<strong>代码块</strong>： 通常采用四个空格或者一个制表符，当结合列表使用时需要八个列表块或两个制表符。</p><pre><code>如这是一个代码块 换行直接回车就可以。</code></pre><p>两下回车退出代码块。</p><ul><li><p>在列表中嵌套代码块</p><pre><code>  例子,同缩进插入图片失败（滑稽）</code></pre><p>  <img src="https://images.alphacoders.com/846/84631.jpg" alt="images"></p></li></ul><h1 id="Markdown-代码语法"><a href="#Markdown-代码语法" class="headerlink" title="Markdown 代码语法"></a>Markdown 代码语法</h1><p>1、转义反引号：可以将单词或者短语包含进去，例如（<code>Hello,Markdown</code>）</p><p>2、代码块： 首尾各三个转义反引号，例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Hello python&quot;</span>)</span><br></pre></td></tr></table></figure><h1 id="Markdown-链接语法："><a href="#Markdown-链接语法：" class="headerlink" title="Markdown 链接语法："></a>Markdown 链接语法：</h1><p>1、这是一个链接 <a href="https://markdown.com.cn">Markdown语法</a></p><p>2、给链接增加 Title, 鼠标悬停在链接上会显示文字。</p><p>这是一个链接 <a href="https://coding.net/help/docs/ci/lint/markdown-code-lang.html" title="Markdown 代码块编程语言清单">Markdown语法</a></p><p>3、网址和Email地址，使用尖括号可以很方便地把URL或者email地址变成可点击的链接</p><p>博客地址： <a href="https://liuixngyuvs.top">https://liuixngyuvs.top</a></p><p>邮箱： <a href="&#x6d;&#x61;&#105;&#x6c;&#116;&#111;&#x3a;&#x66;&#97;&#x6b;&#101;&#x40;&#101;&#120;&#97;&#109;&#112;&#x6c;&#101;&#46;&#x63;&#x6f;&#x6d;">&#x66;&#97;&#x6b;&#101;&#x40;&#101;&#120;&#97;&#109;&#112;&#x6c;&#101;&#46;&#x63;&#x6f;&#x6d;</a></p><p>4、带格式化的链接：强调链接，在链接语法前后增加星号。将链接表示为代码，在方括号中添加反引号。</p><p>I love supporting the <strong><a href="https://eff.org">EFF</a></strong></p><p>This is the <em><a href="https://www.markdownguide.org">Markdown Guide</a></em></p><p>See the section on <a href="#code"><code>code</code></a></p><p>5、引用类型链接：一种特殊的链接，使URL在Markdown中更容易显示与阅读，有两种格式。</p><ol><li>链接的第一部分格式：使用两组括号进行格式设置，第一组括号显示为链接的文本，第二组括号显示为一个标签。此标签用于指向存储在文件中的其他位置的链接。<ul><li>[hobbit-hole][1]</li><li>[hobbit-hole] [1]</li></ul></li><li>链接的第二部分格式：放在括号中的标签，其后紧跟着一个冒号和至少一个空格 例如<code>[label: ]</code>;链接的URL可选择将其括在双引号之中；链接的可选标题，可以将其括在双引号中、单引号或者括号中。<ul><li>[1]: htpps://en.wikipedia.org/wiki/Hobbit#Lifestyle</li><li>[1]: htpps://en.wikipedia.org/wiki/Hobbit#Lifestyle “Hobbit lifestyles”</li><li>[1]: htpps://en.wikipedia.org/wiki/Hobbit#Lifestyle ‘Hobbit lifestyles’</li><li>[1]: htpps://en.wikipedia.org/wiki/Hobbit#Lifestyle (Hobbit lifestyles)</li><li>[1]: <a href="htpps://en.wikipedia.org/wiki/Hobbit#Lifestyle">htpps://en.wikipedia.org/wiki/Hobbit#Lifestyle</a> (Hobbit lifestyles)</li></ul></li></ol><h2 id="Markdown-图片语法"><a href="#Markdown-图片语法" class="headerlink" title="Markdown 图片语法"></a>Markdown 图片语法</h2><p>1、略</p><p>2、链接图片：</p><pre><code>- [![沙漠中的岩石图片](https://markdown.com.cn/assets/img/shiprock.c3b9a023.jpg &quot;Shiprock&quot;)](https://markdown.com.cn)</code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>第一篇文章</title>
      <link href="/posts/5c2fafc7.html"/>
      <url>/posts/5c2fafc7.html</url>
      
        <content type="html"><![CDATA[<div class="tip info"><p>参考博客教程链接:</p></div><div class="tip bolt"><p>博主： 安知鱼<br>    链接： <a href="https://anzhiy.cn/posts/sdxhu.html">https://anzhiy.cn/posts/sdxhu.html</a><br>    bilibili: <a href="https://www.bilibili.com/video/BV1CG41157fr/?spm_id_from=pageDriver&amp;vd_source=cde63aff900a4e125307eefbea7e6079">https://www.bilibili.com/video/BV1CG41157fr/?spm_id_from=pageDriver&amp;vd_source=cde63aff900a4e125307eefbea7e6079</a></p></div>]]></content>
      
      
      
    </entry>
    
    
  
  
    
    
    <entry>
      <title></title>
      <link href="/js/ali_font.js"/>
      <url>/js/ali_font.js</url>
      
        <content type="html"><![CDATA[!function(c){var l,h,a,t,i,v='<svg><symbol id="icon-dragon_chen" viewBox="0 0 1024 1024"><path d="M512 512m-296.421053 0a296.421053 296.421053 0 1 0 592.842106 0 296.421053 296.421053 0 1 0-592.842106 0Z" fill="#D6B196" ></path><path d="M970.105263 512c0 224.983579-163.166316 412.186947-377.263158 450.533053v-54.460632C777.135158 870.507789 916.210526 707.206737 916.210526 512c0-222.881684-181.328842-404.210526-404.210526-404.210526S107.789474 289.118316 107.789474 512s181.328842 404.210526 404.210526 404.210526c9.081263 0 18.000842-0.754526 26.947368-1.374315v53.894736c-8.973474 0.538947-17.866105 1.374316-26.947368 1.374316-252.604632 0-458.105263-205.500632-458.105263-458.105263S259.395368 53.894737 512 53.894737s458.105263 205.500632 458.105263 458.105263z m-498.122105 265.620211L431.157895 754.526316V485.052632h-66.074948c-14.470737 110.645895-44.355368 197.066105-102.696421 260.742736l-39.747368-36.432842C306.526316 617.876211 323.368421 462.901895 323.368421 242.526316V215.578947h377.263158v53.894737H377.182316c-0.404211 58.260211-2.209684 112.128-6.359579 161.684211H700.631579v53.894737h-122.152421a481.172211 481.172211 0 0 0 76.826947 119.70021l66.479158-39.855158 27.728842 46.214737-54.460631 32.687158c29.507368 24.953263 63.757474 45.675789 102.80421 58.098526l-16.303158 51.361684c-134.224842-42.711579-222.773895-167.073684-261.551158-268.207157H485.052632v221.857684l68.985263-41.391158 27.728842 46.214737-109.783579 65.886316zM646.736842 377.263158h-215.578947v-53.894737h215.578947v53.894737z" fill="#231F20" ></path></symbol><symbol id="icon-dog_xu" viewBox="0 0 1024 1024"><path d="M512 512m-296.421053 0a296.421053 296.421053 0 1 0 592.842106 0 296.421053 296.421053 0 1 0-592.842106 0Z" fill="#D6B196" ></path><path d="M970.105263 512c0 224.983579-163.166316 412.186947-377.263158 450.533053v-54.460632C777.135158 870.507789 916.210526 707.206737 916.210526 512c0-222.881684-181.328842-404.210526-404.210526-404.210526S107.789474 289.118316 107.789474 512s181.328842 404.210526 404.210526 404.210526c9.081263 0 18.000842-0.754526 26.947368-1.374315v53.894736c-8.973474 0.538947-17.866105 1.374316-26.947368 1.374316-252.604632 0-458.105263-205.500632-458.105263-458.105263S259.395368 53.894737 512 53.894737s458.105263 205.500632 458.105263 458.105263z m-375.592421 150.393263c33.684211 44.544 75.210105 74.698105 124.739369 90.812632l11.425684 3.718737 10.401684-6.009264C781.204211 727.740632 808.421053 622.565053 808.421053 592.842105h-53.894737c0 22.069895-19.132632 80.869053-33.711158 103.504842-34.816-14.605474-64.538947-39.262316-89.249684-74.13221 48.316632-55.269053 92.079158-117.328842 120.535579-179.900632l-49.044211-22.285473c-23.767579 52.250947-59.742316 104.717474-100.055579 152.656842-24.010105-50.930526-41.148632-115.927579-51.658105-195.395369H700.631579v-53.894737h-155.189895A1848.050526 1848.050526 0 0 1 538.947368 161.684211h-53.894736c0 58.206316 2.155789 112.074105 6.494315 161.68421H323.368421v26.947368c0 216.549053-13.177263 263.545263-100.702316 359.046737l39.747369 36.432842c63.326316-69.093053 92.806737-118.272 105.714526-206.848H485.052632v-53.894736h-111.319579a1742.147368 1742.147368 0 0 0 3.449263-107.789474h120.158316c12.611368 98.250105 35.031579 177.475368 67.395368 238.187789-61.978947 65.536-128.053895 117.975579-173.298526 142.282106l25.519158 47.481263c47.589053-25.573053 114.095158-77.446737 177.55621-142.821053z m125.170526-411.971368l-80.842105-80.842106-38.103579 38.103579 80.842105 80.842106 38.103579-38.103579z" fill="#231F20" ></path></symbol><symbol id="icon-dog" viewBox="0 0 1024 1024"><path d="M894.814316 904.434526l83.240421-183.134315-13.824-13.204211c-0.485053-0.458105-45.648842-47.589053-47.939369-185.263158-0.134737-7.922526-0.134737-33.953684-0.134736-55.996631-30.693053 15.306105-70.090105 19.887158-106.09179 19.887157-92.752842 0-163.624421-23.983158-210.647579-71.275789a192.512 192.512 0 0 1-27.944421-36.513684H377.263158v377.263158c342.662737 0 403.105684 51.092211 494.592 128.377263 7.922526 6.682947 15.521684 13.312 22.959158 19.86021z" fill="#85C3DE" ></path><path d="M326.063158 282.947368c0 34.250105-13.231158 44.463158-29.642105 44.463158s-29.642105-10.213053-29.642106-44.463158c0-34.223158 13.231158-44.463158 29.642106-44.463157s29.642105 10.24 29.642105 44.463157zM269.473684 430.295579v311.646316L190.275368 916.210526h59.203369L323.368421 753.637053V377.263158h-26.947368c-119.403789 0-172.732632-53.382737-185.505685-107.789474h35.624421c51.092211 0 68.581053-15.764211 120.535579-62.544842 12.773053-11.506526 28.079158-25.276632 47.023158-41.741474l18.351158-15.952842-69.658947-99.139368-44.085895 30.989474 41.768421 59.472842c-11.183158 9.862737-20.884211 18.593684-29.480421 26.327579C180.736 212.156632 176.235789 215.578947 146.539789 215.578947H53.894737v26.947369c0 88.710737 66.910316 178.149053 215.578947 187.769263z m216.710737-161.414737c2.290526 71.733895 28.698947 136.326737 75.048421 182.918737C618.711579 509.628632 702.437053 538.947368 810.091789 538.947368c18.593684 0 36.190316-1.158737 52.628211-3.449263 3.745684 111.265684 33.630316 170.334316 51.496421 196.015158l-38.507789 84.722526C782.174316 742.049684 688.774737 700.631579 377.263158 700.631579v53.894737c34.277053 0 65.697684 0.512 94.639158 1.509052L374.595368 970.105263h59.203369l96.013474-211.240421c66.182737 4.338526 117.005474 11.829895 157.911578 22.016L626.229895 916.210526h59.176421l54.16421-119.134315c47.616 18.405053 79.737263 42.091789 113.125053 69.739789L805.753263 970.105263h59.203369l113.071157-248.778105-13.824-13.204211c-0.485053-0.458105-45.648842-47.589053-47.939368-185.263158C985.168842 498.553263 1024 447.811368 1024 377.263158c0-95.205053-66.506105-161.684211-161.684211-161.684211v53.894737c65.482105 0 107.789474 42.307368 107.789474 107.789474 0 89.088-87.013053 107.789474-160.013474 107.789474-92.752842 0-163.624421-23.983158-210.647578-71.27579-30.315789-30.504421-45.891368-65.832421-53.35579-98.735158 11.210105 6.952421 22.932211 13.338947 35.274105 19.186527l23.04-48.720843c-92.106105-43.654737-148.992-128.646737-219.243789-243.981473l-46.026105 28.05221c49.448421 81.246316 92.968421 148.506947 147.051789 199.302737z" fill="#231F20" ></path></symbol><symbol id="icon-goat" viewBox="0 0 1024 1024"><path d="M548.378947 646.736842a952.32 952.32 0 0 1 140.90779-161.68421H107.789474c0 107.600842 0 107.600842-63.649685 169.283368l-13.069473 12.665263L66.721684 754.526316h417.172211c20.345263-41.472 43.654737-77.446737 64.485052-107.789474z" fill="#F7C768" ></path><path d="M608.256 144.734316C555.762526 115.577263 506.098526 107.789474 485.052632 107.789474V53.894737c32.579368 0 91.270737 11.452632 149.369263 43.735579 75.290947 41.822316 130.694737 94.531368 171.385263 150.878316C755.873684 288.013474 697.101474 323.368421 646.736842 323.368421h-107.789474v-53.894737h107.789474c20.506947 0 48.424421-11.210105 80.437895-31.285895a471.04 471.04 0 0 0-118.918737-93.453473zM832.673684 342.231579c-16.384 0-29.642105 10.24-29.642105 44.463158 0 34.250105 13.231158 44.463158 29.642105 44.463158s29.642105-10.213053 29.642105-44.463158c0-34.223158-13.231158-44.463158-29.642105-44.463158zM1024 619.789474C1024 347.109053 901.066105 122.448842 686.753684 3.395368l-26.165895 47.104C914.324211 191.461053 964.688842 440.400842 969.647158 592.842105h-84.506947c-17.92-35.624421-45.352421-69.12-87.013053-101.995789l-16.788211-13.285053-16.734315 13.392842c-66.128842 52.897684-134.629053 127.083789-187.311158 209.677474H102.965895l-8.272842-20.318316C159.043368 617.013895 161.684211 603.109053 161.684211 485.052632v-53.894737h485.052631v-53.894737H161.684211c0-80.384 14.309053-110.026105 66.586947-137.916632l-25.384421-47.535158C123.365053 234.226526 107.789474 291.920842 107.789474 377.263158v107.789474c0 107.600842 0 107.600842-63.649685 169.283368l-13.069473 12.665263L110.618947 862.315789h58.206316l-43.897263-107.789473h103.477895l43.897263 107.789473h58.206316l-43.897263-107.789473h259.47621C508.981895 824.939789 485.052632 899.152842 485.052632 970.105263h53.894736c0-68.688842 27.270737-144.060632 68.958316-215.578947H687.157895c7.410526 0 13.473684 6.063158 13.473684 13.473684V862.315789h53.894737v-94.315789c0-37.160421-30.208-67.368421-67.368421-67.368421h-44.65179c40.771368-58.017684 89.438316-111.427368 138.913684-153.626947C841.512421 600.037053 862.315789 655.225263 862.315789 754.526316h53.894737c0-38.912-2.748632-74.482526-11.102315-107.789474H1024v-26.947368z" fill="#231F20" ></path></symbol><symbol id="icon-goat_wei" viewBox="0 0 1024 1024"><path d="M512 512m-296.421053 0a296.421053 296.421053 0 1 0 592.842106 0 296.421053 296.421053 0 1 0-592.842106 0Z" fill="#D6B196" ></path><path d="M970.105263 512c0 224.983579-163.166316 412.186947-377.263158 450.533053v-54.460632C777.135158 870.507789 916.210526 707.206737 916.210526 512c0-222.881684-181.328842-404.210526-404.210526-404.210526S107.789474 289.118316 107.789474 512s181.328842 404.210526 404.210526 404.210526c9.081263 0 18.000842-0.754526 26.947368-1.374315v53.894736c-8.973474 0.538947-17.866105 1.374316-26.947368 1.374316-252.604632 0-458.105263-205.500632-458.105263-458.105263S259.395368 53.894737 512 53.894737s458.105263 205.500632 458.105263 458.105263z m-431.157895 50.202947c52.304842 70.925474 136.973474 152.144842 232.528843 190.383158l19.994947-50.041263c-109.271579-43.708632-202.805895-152.629895-238.780632-217.49221H808.421053v-53.894737H538.947368v-53.894737h215.578948v-53.894737h-215.578948V161.684211h-53.894736v161.68421h-215.578948v53.894737h215.578948v53.894737H215.578947v53.894737h255.757474c-35.974737 64.862316-129.536 173.783579-238.807579 217.49221l20.021895 50.041263c95.528421-38.238316 180.197053-119.484632 232.501895-190.383158V808.421053h53.894736v-246.218106z" fill="#231F20" ></path></symbol><symbol id="icon-dragon" viewBox="0 0 1024 1024"><path d="M366.376421 344.441263l152.980211-152.98021c43.142737-43.142737 141.204211-9.216 270.201263 115.738947-15.225263 9.835789-25.114947 15.818105-44.13979 32.256s-38.076632 35.489684-59.418947 56.832c-4.203789 4.203789-51.173053 53.221053-78.740211 82.027789-10.805895-12.126316-22.743579-24.171789-34.654315-36.082526L493.136842 362.792421l-54.218105 54.218105-72.542316-72.569263zM862.315789 512c0 46.834526-45.352421 80.842105-107.789473 80.842105-108.948211 0-189.359158-28.806737-267.129263-56.697263C414.100211 509.871158 344.872421 485.052632 258.182737 485.052632 80.788211 485.052632 0 588.126316 0 683.897263h53.894737C73.216 659.779368 135.302737 646.736842 177.340632 646.736842c77.338947 0 223.124211 23.282526 291.893894 47.912421C547.462737 722.701474 615.989895 754.526316 734.315789 754.526316 862.315789 754.526316 916.210526 670.315789 916.210526 512h-53.894737z" fill="#FF8787" ></path><path d="M552.421053 1024c-69.766737 0-113.825684-13.958737-156.402527-27.459368-54.487579-17.273263-110.807579-35.004632-232.421052-26.516211l-3.826527-53.733053c131.718737-9.458526 195.934316 10.967579 252.52379 28.887579 42.226526 13.365895 78.686316 24.926316 140.126316 24.926316 92.752842 0 148.210526-57.936842 148.210526-113.960421 0-16.949895-5.524211-101.618526-114.634105-101.618526-64.970105 0-112.747789 23.336421-163.328 48.02021C365.325474 830.571789 300.301474 862.315789 204.288 862.315789 85.908211 862.315789 0 787.294316 0 683.897263 0 588.126316 80.788211 485.052632 258.182737 485.052632c86.689684 0 155.917474 24.818526 229.214316 51.09221 45.810526 16.410947 92.564211 33.172211 145.488842 44.166737 9.000421-7.033263 13.850947-16.276211 13.850947-26.758737 0-37.187368-37.672421-74.859789-74.13221-111.265684l-3.287579-3.287579 38.103579-38.103579 3.260631 3.287579C652.853895 446.275368 700.631579 494.026105 700.631579 553.552842c0 12.719158-2.802526 24.926316-7.976421 36.109474A594.997895 594.997895 0 0 0 754.526316 592.842105c62.437053 0 107.789474-34.007579 107.789473-80.842105 0-58.853053-52.870737-110.268632-108.840421-164.702316l-8.057263-7.841684c-19.024842 16.437895-38.076632 35.489684-59.418947 56.832l-38.103579-38.103579c74.805895-74.832842 134.898526-134.898526 268.314947-141.931789V55.619368c-63.407158 7.787789-120.993684 39.424-121.667368 39.801264l-15.818105 8.811789-14.120421-11.344842C731.701895 66.452211 709.712842 53.894737 673.684211 53.894737c-41.418105 0-74.347789 25.869474-109.190737 53.301895-26.624 20.911158-54.137263 42.549895-86.851369 53.194105L469.342316 161.684211h-69.093053l-105.525895 105.525894-38.103579-38.130526L324.015158 161.684211H161.684211V107.789474h303.104c22.231579-8.272842 43.708632-25.168842 66.398315-42.981053C569.829053 34.438737 613.618526 0 673.684211 0c48.909474 0 81.408 17.946947 110.888421 40.097684C813.702737 26.300632 877.729684 0 943.157895 0h26.947368v323.368421h-53.894737v-53.167158c-54.164211 3.098947-92.914526 15.845053-127.002947 36.675369l1.832421 1.778526C852.587789 368.505263 916.210526 430.376421 916.210526 512c0 60.928-43.708632 109.945263-107.789473 127.622737V700.631579h53.894736v-53.894737h53.894737v53.894737h53.894737v53.894737h-53.894737v53.894737h-53.894737v-53.894737h-53.894736c-29.722947 0-53.894737-24.171789-53.894737-53.894737v-53.894737c-118.325895 0-207.063579-31.797895-285.318737-59.877053C400.437895 562.229895 335.494737 538.947368 258.182737 538.947368 117.059368 538.947368 53.894737 611.732211 53.894737 683.897263 53.894737 757.221053 115.738947 808.421053 204.288 808.421053c11.910737 0 23.228632-0.538947 34.034526-1.536C248.454737 796.321684 269.473684 770.640842 269.473684 739.166316c0-33.118316-43.088842-70.979368-58.152421-81.596632l30.935579-44.139789c8.299789 5.793684 81.111579 58.664421 81.111579 125.736421 0 19.429053-4.527158 37.052632-10.994526 52.304842 30.773895-10.051368 58.314105-23.498105 86.662737-37.349053C452.877474 727.848421 508.577684 700.631579 585.997474 700.631579 702.410105 700.631579 754.526316 778.725053 754.526316 856.144842 754.526316 938.657684 678.912 1024 552.421053 1024z m-21.180632-623.104L493.136842 362.792421l137.889684-137.889684 38.103579 38.103579-137.889684 137.889684z m-126.760421-18.351158l-38.103579-38.103579 152.980211-152.98021 38.103579 38.103579-152.980211 152.98021z m282.004211-218.624c15.494737-9.754947 43.331368-31.447579 43.331368-31.447579-25.734737-27.809684-49.556211-33.333895-67.368421-29.07621-19.240421 4.608-37.753263 24.602947-37.753263 24.602947s42.253474 22.447158 61.790316 35.920842z" fill="#231F20" ></path></symbol><symbol id="icon-horse" viewBox="0 0 1024 1024"><path d="M776.003368 646.736842c16.599579-99.947789 43.439158-181.086316 83.213474-256.538947l6.817684-12.934737H269.473684c-36.756211 0-53.894737 54.945684-53.894737 92.05221 0 46.753684 6.656 77.527579 70.278737 176.074106l84.533895 128.269473L498.876632 646.736842h277.126736z" fill="#FFAF6E" ></path><path d="M1024 0v404.210526c0 33.333895 0 134.736842-92.079158 134.736842h-13.824l-78.362947-109.056c-22.743579 49.906526-40.340211 103.046737-53.490527 162.950737h115.092211C937.310316 592.842105 970.105263 625.637053 970.105263 661.638737c0 60.631579-69.389474 154.300632-77.312 164.75621l-43.008-32.471579C875.466105 759.861895 916.210526 693.813895 916.210526 661.638737c0-5.982316-8.919579-14.901895-14.901894-14.901895h-125.332211C761.128421 736.121263 754.526316 840.569263 754.526316 970.105263h-53.894737c0-283.971368 31.097263-453.605053 110.888421-605.049263l20.318316-38.534737 112.801684 156.995369c14.443789-4.419368 25.465263-20.938105 25.465263-79.306106V0h53.894737z m-161.684211 161.684211h53.894737V0h-53.894737v80.842105c-17.381053-14.955789-38.184421-26.947368-80.842105-26.947368h-134.736842v53.894737h134.736842c37.672421 0 80.842105 40.906105 80.842105 53.894737z m-107.789473 0h-215.578948v53.894736h161.684211l53.894737-53.894736zM300.894316 766.544842L400.680421 916.210526h64.754526l-95.043368-142.551579L498.876632 646.736842h167.855157a1212.631579 1212.631579 0 0 1 9.431579-53.894737h-199.383579l-175.885473 173.702737z m109.97221-184.400842l-37.861052-38.319158-132.419369 130.802526C173.729684 571.095579 161.684211 529.812211 161.684211 469.315368 161.684211 398.578526 199.464421 323.368421 269.473684 323.368421h323.368421l53.894737-53.894737H269.473684c-6.709895 0-13.258105 0.565895-19.698526 1.482105C234.927158 249.451789 204.638316 215.578947 160.633263 215.578947 65.967158 215.578947 0 349.291789 0 469.315368c0 70.170947 16.141474 136.650105 49.232842 202.671158L6.197895 723.833263l41.472 34.41179 66.128842-79.737264-8.704-16.033684C83.105684 622.133895 53.894737 558.214737 53.894737 469.315368 53.894737 368.451368 106.765474 269.473684 160.633263 269.473684c13.231158 0 25.815579 9.889684 35.43579 20.533895C142.874947 321.967158 107.789474 388.500211 107.789474 469.315368c0 78.201263 19.698526 130.937263 93.642105 243.981474l-55.296 54.622316L280.899368 970.105263h64.754527l-130.048-195.072 195.260631-192.889263z" fill="#231F20" ></path></symbol><symbol id="icon-monkey_shen" viewBox="0 0 1024 1024"><path d="M512 512m-296.421053 0a296.421053 296.421053 0 1 0 592.842106 0 296.421053 296.421053 0 1 0-592.842106 0Z" fill="#BBC4C9" ></path><path d="M970.105263 512c0 224.983579-163.166316 412.186947-377.263158 450.533053v-54.460632C777.135158 870.507789 916.210526 707.206737 916.210526 512c0-222.881684-181.328842-404.210526-404.210526-404.210526S107.789474 289.118316 107.789474 512s181.328842 404.210526 404.210526 404.210526c9.081263 0 18.000842-0.754526 26.947368-1.374315v53.894736c-8.973474 0.538947-17.866105 1.374316-26.947368 1.374316-252.604632 0-458.105263-205.500632-458.105263-458.105263S259.395368 53.894737 512 53.894737s458.105263 205.500632 458.105263 458.105263z m-431.157895 134.736842h161.684211v53.894737h53.894737V269.473684h-215.578948V161.684211h-53.894736v107.789473h-215.578948v431.157895h53.894737v-53.894737h161.684211v215.578947h53.894736v-215.578947z m0-161.68421h161.684211v107.789473h-161.684211v-107.789473z m-215.578947 0h161.684211v107.789473h-161.684211v-107.789473z m215.578947-161.684211h161.684211v107.789474h-161.684211v-107.789474z m-215.578947 0h161.684211v107.789474h-161.684211v-107.789474z" fill="#231F20" ></path></symbol><symbol id="icon-ox_chou" viewBox="0 0 1024 1024"><path d="M512 512m-296.421053 0a296.421053 296.421053 0 1 0 592.842106 0 296.421053 296.421053 0 1 0-592.842106 0Z" fill="#D6B196" ></path><path d="M970.105263 512c0 224.983579-163.166316 412.186947-377.263158 450.533053v-54.460632C777.135158 870.507789 916.210526 707.206737 916.210526 512c0-222.881684-181.328842-404.210526-404.210526-404.210526S107.789474 289.118316 107.789474 512s181.328842 404.210526 404.210526 404.210526c9.081263 0 18.000842-0.754526 26.947368-1.374315v53.894736c-8.973474 0.538947-17.866105 1.374316-26.947368 1.374316-252.604632 0-458.105263-205.500632-458.105263-458.105263S259.395368 53.894737 512 53.894737s458.105263 205.500632 458.105263 458.105263z m-161.68421 188.631579h-159.555369c13.985684-172.813474 43.115789-357.429895 70.817684-385.158737L700.631579 269.473684H323.368421v53.894737h107.169684c-1.940211 45.756632-8.192 103.962947-15.76421 161.684211H323.368421v53.894736h83.968c-9.862737 68.446316-20.264421 130.128842-25.734737 161.684211H215.578947v53.894737h592.842106v-53.894737z m-346.543158-161.684211h149.800421a3313.717895 3313.717895 0 0 0-16.842105 161.684211h-158.477474c6.036211-35.247158 16.114526-95.636211 25.519158-161.684211z m22.608842-215.578947h171.735579c-15.198316 41.121684-27.405474 100.594526-36.890948 161.684211h-150.123789c7.383579-57.505684 13.419789-115.361684 15.279158-161.684211z" fill="#231F20" ></path></symbol><symbol id="icon-monkey" viewBox="0 0 1024 1024"><path d="M757.733053 485.052632H565.894737a80.842105 80.842105 0 0 0-80.842105 80.842105v215.578947c0 40.96 43.546947 99.678316 77.446736 139.210105C596.426105 960.215579 603.055158 970.105263 603.055158 970.105263H754.526316s15.144421-18.674526 45.891368-58.071579S862.315789 809.984 862.315789 717.608421c0-89.573053-47.993263-166.346105-104.582736-232.555789z" fill="#C3D686" ></path><path d="M538.947368 1024h-53.894736c0-32.794947 25.869474-87.417263 77.446736-103.316211C528.599579 881.152 485.052632 822.433684 485.052632 781.473684c0-44.570947 36.271158-80.842105 80.842105-80.842105h80.842105v53.894737h-80.842105a26.947368 26.947368 0 0 0-26.947369 26.947368c0 19.725474 36.675368 77.473684 92.133053 134.736842h88.602947c20.210526-14.147368 88.737684-71.464421 88.737685-198.602105 0-108.382316-93.237895-202.967579-168.151579-278.986105-49.502316-50.202947-88.576-89.842526-98.735158-128.61979-11.749053-44.732632-21.584842-112.586105-26.327579-148.318315H377.263158c-45.136842 0-89.519158 8.434526-121.802105 53.894736H431.157895v53.894737c-97.28 0-107.789474 113.071158-107.789474 161.684211v53.894737h53.894737v161.68421h-53.894737v-107.789474h-26.947368c-170.253474 0-188.631579-94.234947-188.631579-134.736842 0-31.043368 35.220211-72.326737 55.727158-93.722947 2.694737-14.686316 5.847579-28.348632 9.431579-41.013895H161.684211V215.578947h31.528421C239.642947 120.993684 317.224421 107.789474 377.263158 107.789474h185.640421l2.802526 23.794526c0.134737 1.050947 12.719158 106.657684 27.944421 164.756211 6.494316 24.872421 44.624842 63.514947 84.965053 104.448C760.481684 483.813053 862.315789 587.129263 862.315789 717.608421c0 92.375579-31.124211 155.028211-61.898105 194.425263C904.919579 892.146526 970.105263 803.004632 970.105263 673.684211c0-91.405474-42.819368-154.381474-84.237474-215.255579C847.791158 402.458947 808.421053 344.576 808.421053 269.473684c0-119.349895 87.093895-161.684211 161.68421-161.68421v53.894737c-32.417684 0-107.789474 10.509474-107.789474 107.789473 0 58.502737 31.555368 104.933053 68.096 158.639158C974.282105 492.597895 1024 565.679158 1024 673.684211c0 177.286737-108.301474 296.421053-269.473684 296.421052h-161.684211c-37.672421 0-53.894737 40.906105-53.894737 53.894737zM229.214316 269.473684a384.808421 384.808421 0 0 0-14.012632 58.341053l-1.401263 8.488421-6.090105 6.117053c-22.878316 22.932211-44.813474 52.601263-46.026105 62.275368 0 56.805053 53.76 75.264 107.789473 79.386947V431.157895c0-58.691368 13.473684-119.619368 46.511158-161.684211h-86.770526zM323.368421 1024h-53.894737c0-32.794947 25.869474-87.417263 77.446737-103.316211C313.020632 881.152 269.473684 822.433684 269.473684 781.473684c0-44.570947 36.271158-80.842105 80.842105-80.842105h45.16379A188.847158 188.847158 0 0 1 565.894737 592.842105h134.736842v53.894737h-134.736842c-74.293895 0-134.736842 60.442947-134.736842 134.736842v26.516211l-53.894737 0.377263V781.473684c0-9.162105 0.646737-18.135579 1.913263-26.947368H350.315789c-14.848 0-26.947368 12.072421-26.947368 26.947368 0 19.725474 36.675368 77.473684 92.133053 134.736842H431.157895v53.894737h-53.894737c-37.672421 0-53.894737 40.906105-53.894737 53.894737z" fill="#231F20" ></path></symbol><symbol id="icon-horse_wu" viewBox="0 0 1024 1024"><path d="M512 512m-296.421053 0a296.421053 296.421053 0 1 0 592.842106 0 296.421053 296.421053 0 1 0-592.842106 0Z" fill="#FF8787" ></path><path d="M970.105263 512c0 224.983579-163.166316 412.186947-377.263158 450.533053v-54.460632C777.135158 870.507789 916.210526 707.206737 916.210526 512c0-222.881684-181.328842-404.210526-404.210526-404.210526S107.789474 289.118316 107.789474 512s181.328842 404.210526 404.210526 404.210526c9.081263 0 18.000842-0.754526 26.947368-1.374315v53.894736c-8.973474 0.538947-17.866105 1.374316-26.947368 1.374316-252.604632 0-458.105263-205.500632-458.105263-458.105263S259.395368 53.894737 512 53.894737s458.105263 205.500632 458.105263 458.105263z m-431.157895 26.947368h269.473685v-53.894736H538.947368v-161.684211h161.684211v-53.894737H411.001263c12.045474-33.28 20.156632-69.793684 20.156632-107.789473h-53.894737c0 121.963789-105.364211 233.391158-106.415158 234.496l38.858105 37.349052c2.883368-3.018105 43.816421-46.133895 77.392842-110.160842H485.052632v161.684211H215.578947v53.894736h269.473685v323.368421h53.894736V538.947368z" fill="#231F20" ></path></symbol><symbol id="icon-ox" viewBox="0 0 1025 1024"><path d="M540.294737 754.526316h215.578947c20.210526 0 35.112421 1.374316 53.894737 4.581052 91.863579 15.656421 145.354105 67.691789 161.684211 86.069895V916.210526h53.894736V635.580632l-7.895579-7.895579c-9.269895-9.269895-36.513684-49.232842-44.032-196.527158H540.294737a161.684211 161.684211 0 0 0-161.684211 161.68421v131.098948c43.304421 20.210526 97.28 30.585263 161.684211 30.585263z" fill="#FFAF6E" ></path><path d="M1025.347368 635.580632V916.210526h-53.894736v-71.033263c-16.330105-18.405053-69.820632-70.413474-161.684211-86.069895V916.210526h-53.894737v-161.68421h-107.789473v215.578947h-53.894737V700.631579h161.68421c100.998737 0 172.570947 38.669474 215.578948 71.868632v-115.738948c-33.684211-43.627789-51.712-137.458526-53.706106-279.498105H701.978947c-76.934737 0-127.218526-26.219789-175.804631-51.550316a1556.048842 1556.048842 0 0 0-26.839579-13.743158c-26.839579 26.004211-66.209684 44.921263-115.738948 55.511579 24.441263 22.986105 60.874105 52.116211 106.469053 72.838737l-22.312421 49.044211c-76.584421-34.816-129.589895-88.926316-150.824421-113.125053-10.644211 0.619789-21.477053 1.024-32.687158 1.024a473.734737 473.734737 0 0 1-123.365053-15.952842l-93.022315 186.314105 68.581052 53.86779C167.882105 579.557053 237.891368 538.947368 324.715789 538.947368v53.894737c-95.986526 0-170.361263 62.490947-171.088842 63.137684l-16.78821 14.282106-136.838737-107.358316 109.729684-219.809684C46.430316 314.448842 1.347368 267.371789 1.347368 199.868632 1.347368 89.815579 121.586526 53.894737 163.031579 53.894737v53.894737c-14.120421 0-107.789474 17.165474-107.789474 92.079158C55.242105 290.465684 192.188632 323.368421 284.240842 323.368421c67.907368 0 122.421895-12.988632 157.696-35.624421-42.711579-14.336-95.097263-23.120842-169.337263-18.324211l-3.503158-53.786947c95.878737-6.117053 160.148211 8.515368 211.429053 28.833684C484.244211 235.439158 486.4 225.818947 486.4 215.578947c0-48.855579-57.829053-76.288-58.394947-76.557473l22.393263-49.017263C454.063158 91.648 540.294737 131.826526 540.294737 215.578947c0 18.566737-3.422316 35.84-9.997474 51.631158 7.060211 3.584 13.985684 7.168 20.776421 10.698106C597.854316 302.322526 638.248421 323.368421 701.978947 323.368421h269.473685v26.947368c0 214.689684 35.220211 266.590316 45.999157 277.369264l7.895579 7.895579z m-729.384421 25.141894l-98.789052 118.541474 86.797473 137.835789 45.594948-28.725894-65.913263-104.690527 37.052631-44.43621C358.642526 785.192421 439.080421 808.421053 540.294737 808.421053v-53.894737c-99.893895 0-175.077053-24.549053-223.474526-72.946527l-20.857264-20.857263z" fill="#231F20" ></path></symbol><symbol id="icon-rabbit_mao" viewBox="0 0 1024 1024"><path d="M512 512m-296.421053 0a296.421053 296.421053 0 1 0 592.842106 0 296.421053 296.421053 0 1 0-592.842106 0Z" fill="#7DD47F" ></path><path d="M970.105263 512c0 224.983579-163.166316 412.186947-377.263158 450.533053v-54.460632C777.135158 870.507789 916.210526 707.206737 916.210526 512c0-222.881684-181.328842-404.210526-404.210526-404.210526S107.789474 289.118316 107.789474 512s181.328842 404.210526 404.210526 404.210526c9.081263 0 18.000842-0.754526 26.947368-1.374315v53.894736c-8.973474 0.538947-17.866105 1.374316-26.947368 1.374316-252.604632 0-458.105263-205.500632-458.105263-458.105263S259.395368 53.894737 512 53.894737s458.105263 205.500632 458.105263 458.105263z m-377.263158-188.631579h107.789474v323.368421c-20.48 0-39.936-11.264-40.016842-11.317895l-27.728842 46.214737c3.206737 1.940211 32.660211 18.997895 67.745684 18.997895 30.746947 0 53.894737-23.147789 53.894737-53.894737V269.473684h-215.578948v538.947369h53.894737V323.368421z m-107.789473 242.526316v-242.526316h-53.894737v196.904421l-107.789474 40.421053v-243.927579l169.094737-48.316632-14.821053-51.819789L269.473684 276.102737v304.801684l-36.405895 13.662316 18.917053 50.472421 178.741895-67.018105c-5.039158 69.928421-55.269053 106.981053-165.133474 122.933894l7.733895 53.328842C325.712842 746.657684 485.052632 723.536842 485.052632 565.894737z" fill="#231F20" ></path></symbol><symbol id="icon-rabbit" viewBox="0 0 1024 1024"><path d="M680.96 488.744421a1666.667789 1666.667789 0 0 0-54.433684-23.95621c-16.006737 12.234105-33.899789 20.264421-60.631579 20.264421h-80.842105c-36.810105 0-83.644632 30.396632-104.394106 67.772631-42.819368 77.123368-53.409684 117.813895-11.021473 201.701053C397.096421 808.879158 431.157895 876.409263 431.157895 970.105263h338.539789l68.338527-138.859789c20.129684-40.96 24.252632-73.701053 24.252631-110.349474 0.026947-57.397895-25.061053-159.717053-181.328842-232.151579z" fill="#FFBDD8" ></path><path d="M862.315789 720.896c0 36.621474-4.122947 69.389474-24.252631 110.349474L769.697684 970.105263H485.052632v-53.894737h48.370526C507.877053 880.074105 485.052632 833.509053 485.052632 781.473684c0-59.418947 24.171789-113.313684 63.218526-152.360421l38.103579 38.103579A161.091368 161.091368 0 0 0 538.947368 781.473684c0 54.784 35.381895 104.043789 63.514948 134.736842h133.712842l53.490526-108.759579c15.710316-31.851789 18.755368-55.834947 18.755369-86.554947 0-80.976842-63.434105-150.096842-178.607158-195.503158-17.542737 8.138105-38.292211 13.554526-63.919158 13.554526h-80.842105c-13.958737 0-43.924211 15.979789-57.290106 40.016843l-47.104-26.165895C401.408 515.449263 448.242526 485.052632 485.052632 485.052632h80.842105c37.268211 0 57.478737-15.440842 79.090526-36.45979C625.367579 336.195368 549.753263 269.473684 485.052632 269.473684h-107.789474a21.288421 21.288421 0 0 0-5.955369 2.021053A683.762526 683.762526 0 0 0 302.187789 194.021053c-35.84-34.223158-61.763368-58.933895-94.908631-79.440842A42.442105 42.442105 0 0 0 185.478737 107.789474a22.824421 22.824421 0 0 0-17.381053 7.194947c-10.913684 11.425684-6.063158 28.240842 1.428211 39.181474 21.989053 32.121263 47.912421 56.858947 83.752421 91.109052 20.614737 19.671579 49.259789 43.169684 77.392842 63.08379C281.007158 367.400421 215.578947 484.432842 215.578947 592.842105c0 74.482526 24.791579 124.065684 51.065264 176.586106C294.534737 825.209263 323.368421 882.903579 323.368421 970.105263h-53.894737c0-74.482526-24.791579-124.065684-51.065263-176.586105C190.517895 737.738105 161.684211 680.043789 161.684211 592.842105c0-90.866526 42.226526-197.685895 93.453473-274.485894a803.759158 803.759158 0 0 1-39.046737-34.115369C177.852632 247.754105 150.231579 221.399579 125.035789 184.616421c-24.441263-35.759158-22.797474-78.686316 4.069053-106.819368 26.300632-27.567158 70.898526-31.043368 106.522947-9.000421 37.941895 23.444211 65.562947 49.798737 103.774316 86.258526 9.970526 9.512421 33.037474 32.309895 56.93979 60.550737h68.634947c-27.621053-37.780211-60.416-72.730947-88.522105-99.543579-28.833684-27.540211-54.730105-52.116211-84.533895-74.024421L326.305684 0.296421c31.232 23.228632 57.802105 48.532211 87.309474 76.719158 53.840842 51.388632 94.450526 100.594526 121.74821 146.83621 82.836211 26.650947 150.042947 116.870737 165.025685 230.750316l1.724631 13.177263-9.404631 9.404632c-3.772632 3.772632-7.706947 7.653053-11.802948 11.587368C837.227789 561.178947 862.315789 663.498105 862.315789 720.896zM309.463579 754.526316c3.934316 8.057263 7.895579 16.087579 11.991579 24.144842C348.887579 832.970105 377.263158 889.128421 377.263158 970.105263h53.894737c0-93.696-34.061474-161.226105-61.520842-215.578947h-60.173474z m597.90821 53.894737c-3.422316 9.404632-7.814737 19.806316-13.770105 31.959579L829.790316 970.105263h60.065684l52.143158-105.957052c10.778947-21.935158 17.515789-40.016842 21.90821-55.727158h-56.535579zM514.694737 390.736842c0-34.223158-13.231158-44.463158-29.642105-44.463158s-29.642105 10.24-29.642106 44.463158c0 34.250105 13.231158 44.463158 29.642106 44.463158s29.642105-10.213053 29.642105-44.463158z" fill="#231F20" ></path></symbol><symbol id="icon-rat_zi" viewBox="0 0 1024 1024"><path d="M512 512m-296.421053 0a296.421053 296.421053 0 1 0 592.842106 0 296.421053 296.421053 0 1 0-592.842106 0Z" fill="#85C3DE" ></path><path d="M970.105263 512c0 224.983579-163.166316 412.186947-377.263158 450.533053v-54.460632C777.135158 870.507789 916.210526 707.206737 916.210526 512c0-222.881684-181.328842-404.210526-404.210526-404.210526S107.789474 289.118316 107.789474 512s181.328842 404.210526 404.210526 404.210526c9.081263 0 18.000842-0.754526 26.947368-1.374315v53.894736c-8.973474 0.538947-17.866105 1.374316-26.947368 1.374316-252.604632 0-458.105263-205.500632-458.105263-458.105263S259.395368 53.894737 512 53.894737s458.105263 205.500632 458.105263 458.105263z m-431.157895 188.631579v-215.578947h269.473685v-53.894737H538.947368v-39.585684c26.543158-18.081684 94.585263-65.050947 177.852632-127.488L700.631579 215.578947H323.368421v53.894737h295.316211a4221.008842 4221.008842 0 0 1-121.640421 85.369263l-11.991579 8.003369V431.157895H242.526316v53.894737h242.526316v215.578947c0 48.343579-13.850947 53.894737-134.736843 53.894737v53.894737c105.391158 0 188.631579 0 188.631579-107.789474z" fill="#231F20" ></path></symbol><symbol id="icon-rat" viewBox="0 0 1024 1024"><path d="M727.659789 431.157895c-132.581053 0-220.348632 47.454316-285.803789 154.354526-19.779368 32.309895-15.845053 76.503579-9.404632 96.579368 3.260632 10.159158 7.760842 18.647579 12.422737 25.546106C464.761263 737.010526 499.927579 754.526316 538.947368 754.526316h66.829474c1.158737 17.893053-1.967158 34.762105-15.144421 53.975579-12.692211 18.539789-37.807158 40.151579-56.32 54.810947 25.249684-0.673684 52.709053-0.997053 83.240421-0.997053C877.487158 862.315789 970.105263 711.922526 970.105263 571.176421 936.421053 512 882.364632 431.157895 727.659789 431.157895z" fill="#85C3DE" ></path><path d="M210.432 1012.897684l-43.573895-31.690105c106.954105-147.051789 185.317053-171.196632 423.828211-172.705684 21.396211-31.258947 16.249263-56.266105 9.377684-89.70779-3.557053-17.138526-7.221895-34.842947-7.221895-54.433684 0-68.958316 25.330526-104.636632 63.407158-136.973474l34.896842 41.040842c-29.453474 25.061053-44.409263 46.780632-44.409263 95.932632 0 14.093474 2.937263 28.402526 6.063158 43.546947 5.901474 28.510316 12.8 62.032842-1.131789 99.462737 166.373053-10.24 264.542316-96.902737 264.542315-236.193684C916.210526 418.330947 827.580632 323.368421 684.921263 323.368421c-83.644632 0-153.303579 29.696-174.187789 39.612632a224.875789 224.875789 0 0 1-20.533895 31.339789l-41.741474-34.115368 20.884211 17.057684-20.911158-16.976842C448.781474 359.828211 485.052632 314.287158 485.052632 262.736842c0-34.816-8.946526-60.766316-26.570106-77.069474-17.515789-16.249263-44.786526-24.602947-81.219368-24.953263V323.368421h-53.894737V109.783579l24.872421-1.913263c64.700632-4.931368 114.095158 7.895579 146.863158 38.238316C524.207158 173.056 538.947368 212.291368 538.947368 262.736842c0 11.102316-1.131789 21.908211-3.072 32.202105 37.268211-12.584421 89.842526-25.465263 149.045895-25.465263C858.165895 269.473684 970.105263 387.907368 970.105263 571.176421 970.105263 711.922526 877.487158 862.315789 617.552842 862.315789c-258.667789 0-311.942737 19.698526-407.120842 150.581895z m19.105684-256.835368c-12.045474 0-24.387368-0.565895-37.025684-1.64379l-22.096842-1.859368-2.425263-22.016C167.747368 728.144842 161.684211 672.444632 161.684211 631.026526c0-103.585684 21.450105-178.903579 53.894736-259.045052V107.789474h53.894737v274.782315l-2.021052 4.904422C235.439158 465.758316 215.578947 533.800421 215.578947 631.026526c0 22.878316 2.101895 51.442526 3.826527 70.979369 99.678316 2.802526 172.813474-35.408842 222.450526-116.493474l48.020211 24.090947c-11.237053 28.133053-11.371789 51.577263-0.377264 67.853474 9.701053 14.282105 28.645053 23.174737 49.448421 23.174737v53.894737c-39.019789 0-74.186105-17.515789-94.073263-46.888421a100.244211 100.244211 0 0 1-12.422737-25.546106c-53.221053 49.178947-121.128421 73.943579-202.913684 73.970527zM379.957895 525.473684c0-34.223158-13.231158-44.463158-29.642106-44.463158s-29.642105 10.24-29.642105 44.463158c0 34.250105 13.231158 44.463158 29.642105 44.463158s29.642105-10.213053 29.642106-44.463158z" fill="#231F20" ></path></symbol><symbol id="icon-rooster_you" viewBox="0 0 1024 1024"><path d="M512 512m-296.421053 0a296.421053 296.421053 0 1 0 592.842106 0 296.421053 296.421053 0 1 0-592.842106 0Z" fill="#BBC4C9" ></path><path d="M970.105263 512c0 224.983579-163.166316 412.186947-377.263158 450.533053v-54.460632C777.135158 870.507789 916.210526 707.206737 916.210526 512c0-222.881684-181.328842-404.210526-404.210526-404.210526S107.789474 289.118316 107.789474 512s181.328842 404.210526 404.210526 404.210526c9.081263 0 18.000842-0.754526 26.947368-1.374315v53.894736c-8.973474 0.538947-17.866105 1.374316-26.947368 1.374316-252.604632 0-458.105263-205.500632-458.105263-458.105263S259.395368 53.894737 512 53.894737s458.105263 205.500632 458.105263 458.105263z m-215.578947-188.631579h-161.684211v-26.947368h161.684211V242.526316H269.473684v53.894737h161.684211v26.947368h-161.684211v485.052632h53.894737v-53.894737h377.263158v53.894737h53.894737V323.368421zM323.368421 646.736842h377.263158v53.894737H323.368421v-53.894737z m0-269.473684h107.789474c0 103.316211-72.784842 107.654737-81.084632 107.789474L350.315789 538.947368c46.592 0 134.736842-33.792 134.736843-161.68421h53.894736v107.789474c0 29.722947 24.171789 53.894737 53.894737 53.894736h107.789474v53.894737H323.368421v-215.578947z m377.263158 0v107.789474h-107.789474v-107.789474h107.789474z m-215.578947-80.842105h53.894736v26.947368h-53.894736v-26.947368z" fill="#231F20" ></path></symbol><symbol id="icon-rooster" viewBox="0 0 1024 1024"><path d="M891.688421 506.421895C877.244632 455.033263 862.315789 401.893053 862.315789 323.368421V116.224l-323.368421 195.745684V323.368421c0 78.524632 14.928842 131.664842 29.372632 183.053474 12.611368 44.894316 24.522105 87.282526 24.522105 140.314947 0 101.618526-77.931789 176.693895-168.286316 203.991579l5.416422 11.587368h215.578947c24.333474 0 43.385263-0.242526 58.556631-2.128842C811.52 846.821053 916.210526 764.550737 916.210526 646.736842c0-53.032421-11.910737-95.420632-24.522105-140.314947z" fill="#FF8787" ></path><path d="M673.684211 354.357895c-16.384 0-29.642105-10.213053-29.642106-44.463158 0-34.223158 13.231158-44.463158 29.642106-44.463158s29.642105 10.24 29.642105 44.463158c0 34.250105-13.258105 44.463158-29.642105 44.463158zM540.106105 970.105263l-50.58021-107.789474h156.05221l50.607158 107.789474h59.553684l-51.60421-109.918316C811.52 846.821053 916.210526 764.550737 916.210526 646.736842c0-53.032421-11.910737-95.420632-24.522105-140.314947C877.244632 455.033263 862.315789 401.893053 862.315789 323.368421V107.789474c0-59.445895-48.343579-107.789474-107.789473-107.789474a107.924211 107.924211 0 0 0-107.789474 106.172632 100.890947 100.890947 0 0 0-24.117895-3.314527 88.710737 88.710737 0 0 0-88.602947 88.602948c0 20.668632 5.227789 39.720421 10.671158 53.921684l-99.489684 59.688421 93.749894 14.470737V377.263158c0 14.416842-5.901474 21.692632-33.360842 49.152l-11.129263 11.129263C398.228211 326.521263 324.985263 269.473684 215.740632 269.473684 96.768 269.473684 0 366.241684 0 485.214316V646.736842h53.894737v-161.522526A162.007579 162.007579 0 0 1 215.740632 323.368421c82.081684 0 140.422737 36.244211 240.64 152.252632l-38.615579 38.615579C367.804632 461.285053 323.098947 431.157895 259.584 431.157895A151.983158 151.983158 0 0 0 107.789474 582.952421V754.526316h53.894737v-171.573895A98.007579 98.007579 0 0 1 259.584 485.052632c46.322526 0 79.629474 20.911158 137.027368 86.016l18.970948 21.530947 128.080842-128.080842C572.200421 435.981474 592.842105 415.366737 592.842105 377.263158v-97.926737l23.309474-14.120421-13.662316-23.04c-0.161684-0.242526-14.578526-24.899368-14.578526-50.688 0-19.132632 15.575579-34.708211 34.70821-34.708211 5.093053 0 26.785684 3.179789 39.558737 18.647579l26.327579 46.026106 39.774316-24.090948-20.372211-49.367579C704.754526 140.449684 700.631579 117.517474 700.631579 107.789474c0-29.722947 24.171789-53.894737 53.894737-53.894737s53.894737 24.171789 53.894737 53.894737v215.578947c0 85.935158 16.680421 145.300211 31.366736 197.632C851.887158 564.008421 862.315789 601.141895 862.315789 646.736842c0 95.285895-99.408842 161.684211-188.631578 161.684211h-209.461895l-68.419369-145.704421C375.242105 618.954105 338.108632 592.842105 296.448 592.842105A80.976842 80.976842 0 0 0 215.578947 673.711158V862.315789h53.894737v-188.604631c0-14.874947 12.099368-26.974316 26.974316-26.974316 20.533895 0 38.965895 14.147368 50.553263 38.858105L480.579368 970.105263h59.526737z" fill="#231F20" ></path></symbol><symbol id="icon-snake_si" viewBox="0 0 1024 1024"><path d="M512 512m-296.421053 0a296.421053 296.421053 0 1 0 592.842106 0 296.421053 296.421053 0 1 0-592.842106 0Z" fill="#FF8787" ></path><path d="M970.105263 512c0 224.983579-163.166316 412.186947-377.263158 450.533053v-54.460632C777.135158 870.507789 916.210526 707.206737 916.210526 512c0-222.881684-181.328842-404.210526-404.210526-404.210526S107.789474 289.118316 107.789474 512s181.328842 404.210526 404.210526 404.210526c9.081263 0 18.000842-0.754526 26.947368-1.374315v53.894736c-8.973474 0.538947-17.866105 1.374316-26.947368 1.374316-252.604632 0-458.105263-205.500632-458.105263-458.105263S259.395368 53.894737 512 53.894737s458.105263 205.500632 458.105263 458.105263z m-242.041263 180.762947l-52.116211-13.797052C657.219368 749.864421 651.425684 754.526316 619.789474 754.526316h-242.526316V485.052632h269.473684v53.894736h53.894737V215.578947H323.368421v538.947369c0 29.722947 24.171789 53.894737 53.894737 53.894737h242.526316c77.689263 0 91.189895-51.065263 108.274526-115.658106zM377.263158 269.473684h269.473684v161.684211H377.263158v-161.684211z" fill="#231F20" ></path></symbol><symbol id="icon-tiger_yin" viewBox="0 0 1024 1024"><path d="M512 512m-296.421053 0a296.421053 296.421053 0 1 0 592.842106 0 296.421053 296.421053 0 1 0-592.842106 0Z" fill="#7DD47F" ></path><path d="M970.105263 512c0 224.983579-163.166316 412.186947-377.263158 450.533053v-54.460632C777.135158 870.507789 916.210526 707.206737 916.210526 512c0-222.881684-181.328842-404.210526-404.210526-404.210526S107.789474 289.118316 107.789474 512s181.328842 404.210526 404.210526 404.210526c9.081263 0 18.000842-0.754526 26.947368-1.374315v53.894736c-8.973474 0.538947-17.866105 1.374316-26.947368 1.374316-252.604632 0-458.105263-205.500632-458.105263-458.105263S259.395368 53.894737 512 53.894737s458.105263 205.500632 458.105263 458.105263z m-257.42821 299.250526l-107.789474-53.894737-24.117895 48.208843 107.789474 53.894736 24.117895-48.208842z m-269.473685-5.658947l-24.117894-48.208842-107.789474 53.894737 24.117895 48.208842 107.789473-53.894737zM700.631579 431.157895h-161.684211v-53.894737h107.789474v-53.894737H377.263158v53.894737h107.789474v53.894737h-161.684211v323.368421h53.894737v-53.894737h269.473684v53.894737h53.894737V431.157895z m-161.684211 161.68421h107.789474v53.894737h-107.789474v-53.894737z m-161.68421 0h107.789474v53.894737h-107.789474v-53.894737z m161.68421-107.789473h107.789474v53.894736h-107.789474v-53.894736z m-161.68421 0h107.789474v53.894736h-107.789474v-53.894736zM754.526316 215.578947h-223.097263l-20.803369-62.410105-51.119158 17.057684L474.624 215.578947H269.473684v107.789474h53.894737v-53.894737h377.263158v53.894737h53.894737V215.578947z" fill="#231F20" ></path></symbol><symbol id="icon-snake" viewBox="0 0 1024 1024"><path d="M107.789474 790.474105c0-72.434526 67.880421-91.513263 121.451789-91.513263 74.401684 0 153.815579 34.438737 237.891369 70.925474 50.580211 21.935158 104.609684 45.325474 162.250105 63.083789-52.412632 44.786526-118.784 74.347789-195.152842 83.078737-143.171368 16.357053-326.440421 7.006316-326.440421-125.574737zM377.263158 215.578947c-15.575579 0-30.288842 3.449263-43.654737 9.377685A250.691368 250.691368 0 0 0 323.368421 296.421053c0 115.550316 76.422737 169.391158 137.83579 212.614736 8.138105 5.712842 16.141474 11.371789 23.848421 17.057685V323.368421a107.789474 107.789474 0 0 0-107.789474-107.789474z" fill="#C3D686" ></path><path d="M671.528421 788.857263c44.328421 11.964632 89.626947 19.563789 136.892632 19.56379 89.168842 0 161.684211-60.442947 161.68421-134.736842s-72.515368-134.736842-161.68421-134.736843c-19.078737 0-37.025684 1.509053-54.218106 4.015158-0.754526-101.402947-38.211368-172.355368-79.413894-219.648L673.684211 323.368421a1749.962105 1749.962105 0 0 1-79.036632-1.751579c45.702737 35.866947 108.705684 107.870316 105.984 232.367158 0 0.431158-0.080842 0.808421-0.10779 1.239579-34.923789 10.994526-66.155789 26.731789-95.097263 45.190737a163.085474 163.085474 0 0 0-15.845052-42.388211c-21.557895-39.639579-60.065684-66.775579-97.360842-93.022316C433.098105 423.343158 377.263158 384 377.263158 296.421053c0-130.290526 108.274526-188.631579 215.578947-188.631579 64.134737 0 132.715789 12.045474 214.366316 37.807158C802.330947 180.250947 780.099368 209.381053 700.631579 214.635789V161.684211h-53.894737v53.679157c-63.272421-1.024-104.528842-5.200842-104.986947-5.254736l-5.578106 53.598315C538.408421 263.949474 592.357053 269.473684 673.684211 269.473684c125.170526 0 188.631579-48.128 188.631578-143.063579V106.981053l-18.432-6.144C747.789474 68.823579 668.025263 53.894737 592.842105 53.894737c-158.666105 0-269.473684 99.732211-269.473684 242.526316 0 115.550316 76.422737 169.391158 137.83579 212.614736 33.684211 23.713684 65.509053 46.106947 81.003789 74.698106 9.539368 17.542737 13.285053 33.414737 12.341895 47.750737 21.153684 9.108211 42.118737 17.839158 62.949052 25.977263C671.151158 620.193684 729.977263 592.842105 808.421053 592.842105c59.445895 0 107.789474 36.271158 107.789473 80.842106s-48.343579 80.842105-107.789473 80.842105c-105.472 0-203.237053-42.388211-297.768421-83.429053-94.800842-41.094737-184.346947-79.952842-281.411369-79.952842C122.718316 591.171368 53.894737 644.715789 53.894737 727.578947c0 79.063579 67.098947 136.434526 159.555368 136.434527 142.174316 0 230.426947-66.883368 306.79579-129.886316 31.420632 13.419789 62.787368 26.058105 94.450526 37.133474-47.077053 49.637053-110.969263 82.566737-186.610526 91.270736l5.066105 53.625264c93.453474-7.006316 143.144421 9.350737 195.718737 26.543157 46.457263 15.225263 94.127158 30.854737 169.822316 30.854737 19.994947 0 41.957053-1.077895 66.344421-3.557052l-5.416421-53.625263c-105.283368 10.778947-158.100211-6.548211-213.935158-24.872422-22.150737-7.275789-44.624842-14.632421-70.305684-20.345263a334.848 334.848 0 0 0 96.14821-82.297263z m-458.078316 21.261474C162.573474 810.118737 107.789474 784.276211 107.789474 727.578947c0-60.847158 62.733474-82.539789 121.451789-82.539789 77.850947 0 154.731789 30.288842 235.250526 64.943158-66.263579 52.924632-139.722105 100.136421-251.041684 100.136421z" fill="#231F20" ></path></symbol><symbol id="icon-tiger" viewBox="0 0 1024 1024"><path d="M431.157895 162.250105V134.736842c0-41.552842-39.289263-80.842105-80.842106-80.842105-28.833684 0-57.128421 4.661895-58.314105 4.850526L269.473684 62.490947v83.887158C144.788211 223.824842 89.222737 346.839579 66.991158 431.157895h266.051368c240.747789 0 415.851789 107.789474 415.85179 269.473684-14.848-25.114947-43.924211-53.894737-88.68379-53.894737-67.988211 0-121.263158 71.033263-121.263158 161.684211 0 66.802526 30.477474 119.888842 60.712421 156.16 12.638316 15.171368 36.055579 37.726316 59.014737 58.88 5.066105 0.107789 9.781895 0.538947 15.009685 0.538947 219.297684 0 350.315789-191.811368 350.315789-377.263158C1024 327.545263 679.855158 172.813474 431.157895 162.250105z" fill="#F7C768" ></path><path d="M673.684211 1024c-114.768842 0-188.820211-33.333895-254.167579-62.787368-53.625263-24.144842-99.974737-45.002105-161.28-45.002106-40.448 0-83.590737 23.255579-103.639579 45.16379l-39.747369-36.432842C142.497684 894.787368 199.168 862.315789 258.236632 862.315789c68.392421 0 119.861895 21.288421 172.921263 45.056V673.684211c0-35.166316-17.542737-64.107789-30.639158-80.815158-15.198316 9.835789-32.067368 18.890105-50.741895 26.947368l-21.342316-49.475368C469.800421 509.413053 485.052632 377.317053 485.052632 323.368421V221.642105A597.827368 597.827368 0 0 0 404.210526 215.578947h-26.947368V134.736842c0-12.099368-14.848-26.947368-26.947369-26.947368-9.377684 0-18.836211 0.592842-26.947368 1.347368V269.473684h-53.894737V211.671579c-136.030316 102.912-158.450526 266.886737-161.306947 295.882105 9.135158 9.108211 38.992842 25.061053 71.976421 38.669474l38.103579-59.365053 12.449684-1.589894C321.212632 473.653895 377.263158 392.192 377.263158 323.368421h53.894737c0 88.333474-68.796632 192.242526-180.870737 213.342316l-48.397474 75.398737-20.291368-7.437474C53.894737 557.756632 53.894737 523.317895 53.894737 512c0-50.041263 37.025684-254.733474 215.578947-365.621895V62.490947l22.528-3.745684C293.187368 58.556632 321.482105 53.894737 350.315789 53.894737c41.552842 0 80.842105 39.289263 80.842106 80.842105v27.513263c248.697263 10.563368 592.842105 165.295158 592.842105 484.486737 0 185.451789-131.018105 377.263158-350.315789 377.263158z m-13.473685-323.368421c-36.513684 0-67.368421 49.367579-67.368421 107.789474 0 85.746526 68.096 145.084632 89.465263 161.549473 91.540211-2.533053 164.378947-45.487158 213.827369-107.654737H700.631579v-53.894736h230.238316c8.919579-17.273263 16.357053-35.354947 22.285473-53.894737h-239.885473l-6.467369-17.650527C706.290526 735.582316 692.439579 700.631579 660.210526 700.631579zM485.052632 931.112421c33.926737 14.066526 70.521263 26.597053 114.607157 33.468632C569.424842 928.309895 538.947368 875.223579 538.947368 808.421053c0-90.650947 53.274947-161.684211 121.263158-161.684211 44.759579 0 73.835789 28.779789 88.68379 53.894737h217.007158c2.775579-17.866105 4.203789-35.920842 4.203789-53.894737 0-38.938947-5.658947-74.752-15.925895-107.627789l-126.706526 126.679579-38.103579-38.103579L932.001684 485.052632a367.939368 367.939368 0 0 0-57.775158-81.596632l-154.543158 154.543158-38.103579-38.103579 153.573053-153.573053a537.869474 537.869474 0 0 0-82.593684-56.751158l-140.665263 140.638316-38.103579-38.103579 128.134737-128.134737A794.731789 794.731789 0 0 0 538.947368 231.046737V323.368421c0 50.149053-11.102316 156.698947-95.932631 236.328421 18.378105 23.417263 42.037895 63.407158 42.037895 113.987369v257.42821zM215.578947 431.157895v-53.894737c39.774316 0 53.894737-29.022316 53.894737-53.894737h53.894737c0 53.571368-37.025684 107.789474-107.789474 107.789474z" fill="#231F20" ></path></symbol><symbol id="icon-boar" viewBox="0 0 1024 1024"><path d="M732.079158 377.263158c-107.789474 0-186.421895 31.393684-281.869474 126.841263L180.331789 773.982316C257.724632 807.909053 348.725895 808.421053 485.052632 808.421053h96.013473c55.834947-34.411789 133.551158-53.894737 227.354948-53.894737h121.344L970.105263 680.555789V572.631579c0-94.315789-130.236632-195.368421-238.026105-195.368421z" fill="#FFBDD8" ></path><path d="M808.421053 700.631579v53.894737c-196.446316 0-323.368421 84.641684-323.368421 215.578947h-53.894737c0-163.705263 148.075789-269.473684 377.263158-269.473684z m-323.368421 107.789474v-53.894737c-158.342737 0-245.598316 0-319.649685-49.367579L158.612211 700.631579H80.842105c-21.692632 0-26.624-14.821053-26.947368-26.947368v-82.620632c84.156632-11.183158 161.684211-74.913684 161.68421-186.853053V215.578947H161.684211v161.684211H134.736842c-66.964211 0-134.736842 37.025684-134.736842 107.789474h53.894737c0-42.630737 52.870737-53.894737 80.842105-53.894737h24.629895C147.132632 504.912842 85.153684 538.947368 26.947368 538.947368H0v134.736843c0 32.498526 21.530947 80.842105 80.842105 80.842105h61.682527c32.687158 20.506947 67.125895 33.145263 105.957052 41.013895A232.879158 232.879158 0 0 0 215.578947 916.210526h53.894737c0-41.930105 14.012632-80.303158 39.424-112.505263C358.885053 808.151579 415.959579 808.421053 485.052632 808.421053z m-72.946527-342.420211L323.368421 554.738526V431.157895h-53.894737v253.682526l180.736-180.736-38.103579-38.103579zM323.368421 161.684211h-53.894737v190.032842a769.536 769.536 0 0 1 53.894737-49.098106V161.684211z m323.368421-53.894737c-72.623158 0-146.809263 23.336421-215.578947 58.637473V107.789474h-53.894737v154.138947C458.832842 205.392842 555.331368 161.684211 646.736842 161.684211c148.587789 0 269.473684 120.885895 269.473684 269.473684v235.654737L809.579789 862.315789h61.359158L970.105263 680.555789V431.157895c0-178.310737-145.057684-323.368421-323.368421-323.368421z" fill="#231F20" ></path></symbol><symbol id="icon-boar_hai" viewBox="0 0 1024 1024"><path d="M512 512m-296.421053 0a296.421053 296.421053 0 1 0 592.842106 0 296.421053 296.421053 0 1 0-592.842106 0Z" fill="#85C3DE" ></path><path d="M309.975579 804.756211l-27.136-46.592c103.073684-60.011789 183.026526-132.473263 241.475368-219.24379H350.315789l-13.473684-50.283789c58.88-33.980632 99.435789-117.571368 118.703158-165.295158H242.526316v-53.894737h538.947368v53.894737h-268.18021c-12.395789 34.088421-42.469053 106.603789-90.435369 161.68421h134.009263a680.555789 680.555789 0 0 0 46.349474-107.708631l51.092211 17.057684c-58.421895 175.265684-171.034947 309.490526-344.333474 410.381474z m192.350316-2.937264L467.806316 760.454737c88.414316-73.728 154.516211-158.773895 202.105263-259.907369l48.801684 22.959158a797.372632 797.372632 0 0 1-82.351158 137.781895c32.741053 15.009684 83.456 44.867368 137.647158 101.591579l-38.938947 37.268211c-57.236211-59.877053-109.325474-85.557895-133.766737-95.178106a850.997895 850.997895 0 0 1-98.977684 96.848842z m48.613052-536.872421l-80.842105-53.894737 29.884632-44.840421 80.842105 53.894737-29.884632 44.840421zM512 53.894737C259.395368 53.894737 53.894737 259.395368 53.894737 512s205.500632 458.105263 458.105263 458.105263c9.081263 0 17.973895-0.835368 26.947368-1.374316v-53.894736c-8.946526 0.619789-17.866105 1.374316-26.947368 1.374315-222.881684 0-404.210526-181.328842-404.210526-404.210526S289.118316 107.789474 512 107.789474s404.210526 181.328842 404.210526 404.210526c0 195.206737-139.075368 358.507789-323.368421 396.045474v54.460631c214.096842-38.346105 377.263158-225.549474 377.263158-450.533052C970.105263 259.395368 764.604632 53.894737 512 53.894737z" fill="#231F20" ></path></symbol><symbol id="icon-bilibili1" viewBox="0 0 1129 1024"><path d="M234.909 9.656a80.468 80.468 0 0 1 68.398 0 167.374 167.374 0 0 1 41.843 30.578l160.937 140.82h115.07l160.936-140.82a168.983 168.983 0 0 1 41.843-30.578A80.468 80.468 0 0 1 930.96 76.445a80.468 80.468 0 0 1-17.703 53.914 449.818 449.818 0 0 1-35.406 32.187 232.553 232.553 0 0 1-22.531 18.508h100.585a170.593 170.593 0 0 1 118.289 53.109 171.397 171.397 0 0 1 53.914 118.288v462.693a325.897 325.897 0 0 1-4.024 70.007 178.64 178.64 0 0 1-80.468 112.656 173.007 173.007 0 0 1-92.539 25.75H212.377a341.186 341.186 0 0 1-72.421-4.024A177.835 177.835 0 0 1 28.91 939.065a172.202 172.202 0 0 1-27.36-92.539V388.662a360.498 360.498 0 0 1 0-66.789A177.03 177.03 0 0 1 162.487 178.64h105.414c-16.899-12.07-31.383-26.555-46.672-39.43a80.468 80.468 0 0 1-25.75-65.984 80.468 80.468 0 0 1 39.43-63.57M216.4 321.873a80.468 80.468 0 0 0-63.57 57.937 108.632 108.632 0 0 0 0 30.578v380.615a80.468 80.468 0 0 0 55.523 80.469 106.218 106.218 0 0 0 34.601 5.632h654.208a80.468 80.468 0 0 0 76.444-47.476 112.656 112.656 0 0 0 8.047-53.109v-354.06a135.187 135.187 0 0 0 0-38.625 80.468 80.468 0 0 0-52.304-54.719 129.554 129.554 0 0 0-49.89-7.242H254.22a268.764 268.764 0 0 0-37.82 0z m0 0" fill="#20B0E3" ></path><path d="M348.369 447.404a80.468 80.468 0 0 1 55.523 18.507 80.468 80.468 0 0 1 28.164 59.547v80.468a80.468 80.468 0 0 1-16.094 51.5 80.468 80.468 0 0 1-131.968-9.656 104.609 104.609 0 0 1-10.46-54.719v-80.468a80.468 80.468 0 0 1 70.007-67.593z m416.02 0a80.468 80.468 0 0 1 86.102 75.64v80.468a94.148 94.148 0 0 1-12.07 53.11 80.468 80.468 0 0 1-132.773 0 95.757 95.757 0 0 1-12.875-57.133V519.02a80.468 80.468 0 0 1 70.007-70.812z m0 0" fill="#20B0E3" ></path></symbol><symbol id="icon-yinle" viewBox="0 0 1024 1024"><path d="M512.2976 0a531.2 531.2 0 0 0-512 548.48V960h128V548.48a398.72 398.72 0 0 1 384-411.52 398.72 398.72 0 0 1 384 411.52V960h128V548.48A531.2 531.2 0 0 0 512.2976 0z" fill="#5c8add" ></path><path d="M64.2976 576l256 0 0 448-256 0 0-448Z" fill="#5c8add" ></path><path d="M704.2976 576l256 0 0 448-256 0 0-448Z" fill="#5c8add" ></path></symbol><symbol id="icon-icon-test-copy" viewBox="0 0 1024 1024"><path d="M512 512m-229.517241 0a229.517241 229.517241 0 1 0 459.034482 0 229.517241 229.517241 0 1 0-459.034482 0Z" fill="#5c8add" ></path><path d="M512 1024A512 512 0 1 1 1024 512 512 512 0 0 1 512 1024z m0-141.241379A370.758621 370.758621 0 1 0 141.241379 512 370.758621 370.758621 0 0 0 512 882.758621z" fill="#5c8add" ></path></symbol><symbol id="icon-V" viewBox="0 0 1024 1024"><path d="M1012.47774251 492.58192592L544.94137566 87.22962963a49.96686561 49.96686561 0 0 0-65.88275132 0L11.63784127 492.6975097c-21.03624691 18.26223633-23.3479224 49.93219048-5.08568606 70.96843739 18.03106878 21.03624691 49.93219048 23.3479224 70.96843738 5.08568607L512 191.83294532l434.71057495 376.91868784c9.47786949 8.20644797 21.26741446 12.25188008 32.82579189 12.13629629 14.10122046 0 27.97127337-5.77918871 38.02706173-17.33756613 18.14665256-20.92066314 15.95056084-52.70620106-5.08568606-70.9684374z" fill="#5c8add" ></path><path d="M109.30613051 567.59579541V896.89396825c0 42.53482892 34.90629982 77.44112875 77.44112875 77.44112875h220.76500882V666.30433862c0-25.54401411 20.92066314-46.46467725 46.46467724-46.46467724h116.16169313c25.54401411 0 46.46467725 20.92066314 46.46467725 46.46467724V974.335097h220.76500882c42.53482892 0 77.44112875-34.90629982 77.44112874-77.44112875l0.11558377-329.29817284L512 218.18604586 109.30613051 567.59579541zM848.00203175 197.49655027h-63.91782716c-12.82979894 0-23.23233862 10.40253968-23.23233863 23.23233862v24.27259259l110.49808818 95.70336508V220.72888889h-0.11558377c0-12.82979894-10.40253968-23.23233862-23.23233862-23.23233862zM905.44716754 83.18419754s-34.90629982 56.86721693-89.11508994 100.32671603c152.68616579 13.98563668 127.83565432-133.26809171 127.83565432-133.2680917-134.07717813-10.28695591-132.92134039 102.29164021-131.072 127.83565432 20.92066314-20.92066314 49.70102293-62.64640564 92.35143562-94.89427865zM798.53217637 174.61096297c-19.64924162-16.52847972-40.56990476-43.45949912-51.203612-53.97762258 0 0 32.94137566 20.57391182 56.40488184 49.3542716 2.42725926-18.37782011 6.47269135-93.3916896-93.16052205-85.3008254 0 0-13.98563668 104.71889947 87.95925221 89.92417638z" fill="#5c8add" ></path></symbol><symbol id="icon-zhifeiji" viewBox="0 0 1167 1024"><path d="M41.201759 463.52493L1110.665064 30.117647c10.32605-4.159104 21.942857 0.860504 26.101961 11.043137 1.434174 3.728852 1.864426 7.744538 1.003921 11.616807L949.033691 978.823529c-2.151261 10.89972-12.764146 17.927171-23.663865 15.632493-2.72493-0.573669-5.306443-1.721008-7.601121-3.298599L634.80624 789.79944l-163.065546 133.951821c-16.492997 13.62465-40.87395 11.186555-54.498599-5.306443-3.011765-3.728852-5.306443-7.887955-6.884034-12.477311l-102.973669-313.080112-265.178712-91.787115c-10.469468-3.585434-16.062745-15.058824-12.333893-25.528291 1.864426-5.44986 6.023529-9.895798 11.329972-12.047059z" fill="#FCFDFC" ></path><path d="M929.385512 1023.569748c-3.155182 0-6.453782-0.286835-9.752381-1.003922-6.740616-1.434174-12.907563-4.015686-18.50084-8.031372L635.953579 825.940616l-146.142297 120.040336c-13.911485 11.473389-31.408403 16.779832-49.335574 15.058824-17.927171-1.721008-34.133333-10.32605-45.463305-24.237535-5.306443-6.453782-9.322129-13.768067-11.903642-21.79944l-98.527731-299.598879-251.697479-87.19776c-12.333894-4.302521-22.229692-13.05098-27.966386-24.811204s-6.453782-24.954622-2.151261-37.288515c4.589356-13.337815 14.771989-23.9507 27.82297-29.257143L1099.908761 3.585434c24.954622-10.039216 53.351261 2.007843 63.533894 26.819048 3.585434 8.891877 4.445938 18.644258 2.581513 28.109804L977.143495 984.560224c-4.732773 23.090196-25.098039 39.009524-47.757983 39.009524z m-294.579272-233.770308l282.962465 201.357983c2.294678 1.577591 4.87619 2.72493 7.601121 3.298599 10.89972 2.151261 21.512605-4.87619 23.663865-15.632493L1137.914364 52.777591c0.860504-3.872269 0.430252-7.887955-1.003922-11.616807-4.159104-10.32605-15.919328-15.202241-26.101961-11.043137L41.201759 463.52493c-5.306443 2.151261-9.465546 6.597199-11.47339 12.047059-1.721008 5.019608-1.434174 10.469468 0.860505 15.345658 2.294678 4.87619 6.453782 8.461625 11.473389 10.182633l265.178711 91.787115L410.214644 905.967507c1.434174 4.589356 3.872269 8.748459 6.884033 12.477311 6.597199 8.031373 15.919328 12.907563 26.101961 13.911485 10.32605 1.003922 20.365266-2.007843 28.396639-8.605042l163.208963-133.951821z" fill="#4A4A4A" ></path><path d="M307.097557 592.743978l105.698599 316.091876c6.310364 18.787675 26.532213 28.970308 45.319888 22.659944 4.159104-1.434174 7.887955-3.442017 11.186555-6.166946l164.786555-133.951821-165.360224-118.892997c297.017367-287.982073 447.462185-433.980952 451.191036-437.853222 0.573669-0.573669 2.581513-3.442017 0.430252-7.027451-1.290756-1.577591-3.298599-3.298599-7.027451-2.15126-202.218487 120.327171-404.293557 242.805602-606.22521 367.291877z" fill="#CAE0EE" ></path><path d="M446.786072 934.794398c-5.736695 0-11.329972-1.290756-16.636414-3.872269-8.891877-4.445938-15.632493-12.047059-18.787675-21.512605L305.376549 592.313725l1.003921-0.573669C507.308201 467.684034 711.391114 344.058263 912.60568 224.161345l0.286835-0.143418c3.585434-1.147339 6.310364-0.286835 8.605042 2.581513l0.143417 0.143417c2.438095 4.015686 0.573669 7.457703-0.573669 8.74846-3.872269 4.015686-155.177591 150.87507-450.043698 436.705882l165.503642 119.036414-166.220728 135.09916c-3.442017 2.868347-7.457703 5.019608-11.760225 6.453782-3.728852 1.290756-7.744538 2.007843-11.760224 2.007843z m-137.967507-341.333334l105.268348 314.944538c2.868347 8.748459 9.035294 15.77591 17.210084 19.935014 8.17479 4.159104 17.496919 4.732773 26.245378 1.864426 3.872269-1.290756 7.60112-3.298599 10.756302-5.880112l163.352381-132.804482L466.434252 672.627451l1.290756-1.147339C763.308201 384.932213 915.043775 237.642577 918.772627 233.626891c0 0 2.007843-2.294678 0.286835-5.306443-1.003922-1.290756-2.438095-2.438095-5.306443-1.577591-200.784314 119.610084-404.293557 242.94902-604.934454 366.718207z" fill="#CAE0EE" ></path><path d="M460.840974 924.898599l7.457703-253.561904 165.933894 119.896918-168.658824 135.959664c-1.290756 1.003922-3.011765 0.860504-4.015686-0.430252-0.430252-0.430252-0.717087-1.147339-0.717087-1.864426z" fill="#94C3E2" ></path><path d="M463.709322 929.344538c-1.290756 0-2.438095-0.573669-3.2986-1.577591-0.573669-0.860504-1.003922-1.864426-1.003921-2.868348l7.60112-256.286834 169.519328 122.621848-1.434174 1.147339-168.658823 135.959664c-0.860504 0.717087-1.721008 1.003922-2.72493 1.003922z m6.023529-255.282913l-7.457703 250.836974c0 0.286835 0.143417 0.717087 0.286835 1.003922 0.430252 0.573669 1.434174 0.717087 2.007843 0.286835l167.22465-134.812325-162.061625-117.315406z" fill="#94C3E2" ></path></symbol><symbol id="icon-lianjie" viewBox="0 0 1079 1024"><path d="M695.355535 432.666896c-0.553495-1.10699-0.885592-2.186305-1.383737-3.265619-0.193723-0.193723-0.193723-0.359772-0.359771-0.719543-12.508983-26.318678-39.436506-43.366319-69.325226-41.013966-39.076734 3.265619-68.439634 39.021384-65.312388 79.841627 0.857917 10.516401 3.653066 20.147211 7.998 28.83708 19.78744 46.659613 11.097571 103.448181-25.377737 141.750022l-191.094085 199.950001a118.088119 118.088119 0 0 1-171.998513 0c-47.434506-49.537786-47.434506-130.098956 0-179.636742l71.234782-74.389703-0.52582-0.553494a75.911814 75.911814 0 0 0 24.326097-61.880721c-3.127246-40.820243-37.3609-71.51153-76.437634-68.24591a69.463599 69.463599 0 0 0-46.908685 23.966325l-0.166049-0.193723-72.618519 75.856464c-103.226783 107.793115-103.226783 282.36538 0 390.158495 103.171433 107.793115 270.299193 107.793115 373.498301 0l191.619904-200.1714c80.256748-83.992838 97.636485-208.307773 52.83108-310.289193z" fill="#5c8add" ></path><path d="M1002.047012 80.865592c-103.226783-107.82079-270.382217-107.82079-373.581325 0l-191.619905 200.199075c-80.284423 83.854464-97.66416 208.197074-52.997128 310.233843 0.52582 1.079315 0.857917 2.15863 1.383737 3.26562 0.166048 0.166048 0.166048 0.359772 0.332097 0.719543 12.536658 26.291004 39.46418 43.366319 69.3529 41.013966 39.076734-3.265619 68.439634-39.021384 65.312388-79.869302a78.679288 78.679288 0 0 0-7.998-28.864755c-19.78744-46.631938-11.097571-103.448181 25.377737-141.750022l191.287808-199.839302a118.088119 118.088119 0 0 1 172.026188 0c47.434506 49.537786 47.434506 130.126631 0 179.692091l-71.234782 74.417378 0.52582 0.553495a75.939489 75.939489 0 0 0-24.353772 61.88072c3.15492 40.847917 37.3609 71.51153 76.465309 68.245911a69.463599 69.463599 0 0 0 46.908685-23.938651l0.166049 0.166048 72.646194-75.856464c103.03306-107.82079 103.03306-282.642127 0-390.269194z" fill="#5c8add" ></path></symbol><symbol id="icon-liaotian" viewBox="0 0 1171 1024"><path d="M1068.71699 0.243751H102.193768C46.228437 0.243751 0.500666 45.045267 0.500666 99.74309v696.251622c0 54.697824 45.727771 99.450589 101.693102 99.450589h329.113198l120.851966 114.465677a48.652788 48.652788 0 0 0 66.641644 0l120.851966-114.465677h329.064448c55.965331 0 101.741852-44.752765 101.741852-99.450589V99.74309C1170.458842 45.045267 1124.682321 0.243751 1068.71699 0.243751z m-439.776354 596.849784h-370.989696c-27.933915 0-50.846551-22.425133-50.846551-49.774045 0-27.348912 22.912636-49.725294 50.846551-49.725294h370.989696c27.933915 0 50.846551 22.376382 50.846551 49.725294 0 27.348912-22.912636 49.774045-50.846551 49.774045z m287.18795-211.381252H254.782171a50.456549 50.456549 0 0 1-50.846551-49.725294c0-27.397662 22.912636-49.774045 50.846551-49.774045h661.346415c27.933915 0 50.846551 22.376382 50.846551 49.774045 0 27.348912-22.912636 49.725294-50.846551 49.725294z" fill="#5C8ADD" ></path></symbol><symbol id="icon-xinfeng" viewBox="0 0 1400 1024"><path d="M1301.63733163 214.78520234a207.81921797 207.81921797 0 0 1 7.02423018 52.42036465v489.73590176a205.10753818 205.10753818 0 0 1-205.05853125 205.05853125H283.05853124A205.15654424 205.15654424 0 0 1 77.99999999 756.79444971V267.20556699a201.36672685 201.36672685 0 0 1 7.02423106-52.42036465L586.24393329 562.1905874c69.44187217 51.96297217 146.36536612 49.13694404 214.1736961 0zM1103.60303056 62.0000167H283.05853124A204.50312753 204.50312753 0 0 0 106.37462518 163.41030547l489.71956641 335.75823018c62.43397646 50.77048623 127.85733457 50.31309463 194.62019765 0L1280.28693749 163.41030547A204.68281729 204.68281729 0 0 0 1103.60303056 62.0000167z m0 0" fill="#5c8add" ></path></symbol><symbol id="icon-QQ1" viewBox="0 0 1024 1024"><path d="M0 512a512 512 0 1 0 1024 0A512 512 0 1 0 0 512z" fill="#18ACFC" ></path><path d="M500.113 228.39c118.396-1.518 178.924 61.004 201 156 3.497 15.048 0.15 34.807 0 50 27.143 5.682 33.087 60.106 10 75v1h1c8.26 14.33 19.04 28.125 26 44 7.332 16.723 9.306 35.16 14 55 4.024 17.01-2.287 51.505-10 57-0.771 0.683-2.231 1.312-3 2-14.601-3.016-30.377-16.865-38-27-3.065-4.074-5.275-9.672-10-12-0.395 21.568-12.503 41.15-22 55-3.514 5.123-14.073 13.217-14 18 3.691 2.836 8.305 2.956 13 5 10.513 4.577 25.449 13.168 32 22 2.334 3.146 5.548 7.555 7 11 16.193 38.414-36.527 48.314-63 54-27.185 5.839-77.818-10.224-92-19-8.749-5.414-16.863-18.573-29-19-3.666 2.389-14.438 1.132-20 1-16.829 32.804-101.913 47.868-148 31-14.061-5.146-43.398-17.695-38-40 4.437-18.327 19.947-29.224 35-37 5.759-2.975 18.915-4.419 22-10-13.141-8.988-24.521-28.659-31-44-3.412-8.077-4.193-25.775-9-32-7.789 12.245-32.097 36.91-52 33-3.071-4.553-7.213-9.097-9-15-4.792-15.835-1.81-40.379 2-54 8.117-29.02 16.965-50.623 32-72 4.672-6.643 11.425-12.135 16-19-8.945-9.733-6.951-37.536-1-49 4.002-7.709 9.701-7.413 10-20-1.92-3.022-0.071-8.604-1-13-4.383-20.75 3.273-47.552 9-63 19.8-53.421 53.712-90.466 105-112 11.986-5.033 25.833-7.783 39-11 5.322-1.3 11.969 0.518 16-2z" fill="#FFFFFF" ></path></symbol><symbol id="icon-rss" viewBox="0 0 1024 1024"><path d="M749.61196492 908.06119793C749.61196492 560.41848146 463.58151854 274.36328126 115.93880207 274.36328126V115.93880207c434.50388795 0 792.12239584 357.61850789 792.12239586 792.12239586zM224.55858562 690.72261555a108.91682943 108.91682943 0 0 1 108.69404499 108.74355267C333.25263061 859.29616292 284.24005737 908.06119793 224.31104736 908.06119793 164.48105265 908.06119793 115.96355592 859.41993206 115.96355592 799.46616822s48.69077351-108.71879883 108.61978351-108.74355267zM641.01693522 908.06119793h-153.96879069c0-203.60020956-167.50913289-371.13409627-371.10934246-371.13409629v-153.96879068c288.03550619 0 525.07813313 237.11688843 525.07813315 525.10288697z" fill="#FFA500" ></path></symbol><symbol id="icon-youxiang" viewBox="0 0 1024 1024"><path d="M583.60666667 972h-68.08c-8.43333333 0-15.33333333-6.9-15.33333334-15.33333333V609.52c0-8.43333333 6.9-15.33333333 15.33333334-15.33333333h68.08c8.43333333 0 15.33333333 6.9 15.33333333 15.33333333V956.66666667c0 8.43333333-6.9 15.33333333-15.33333333 15.33333333z" fill="#629FF9" ></path><path d="M294.42 167c-113.62 0-205.77333333 92-205.77333333 205.31333333v336.72h411.39333333V372.31333333c0.15333333-113.31333333-92-205.31333333-205.62-205.31333333z" fill="#2166CC" ></path><path d="M519.97333333 627H216.98666667c-25.45333333 0-46-20.54666667-46-46V393.78c0-25.45333333 20.54666667-46 46-46h302.98666666c25.45333333 0 46 20.54666667 46 46V581c0 25.45333333-20.54666667 46-46 46z" fill="#D2E4FF" ></path><path d="M565.97333333 397a49.22 49.22 0 0 0-49.37333333-49.22H220.36c-27.29333333 0-49.37333333 22.08-49.37333333 49.22v10.27333333l179.4 94.60666667c11.34666667 5.98 24.84 5.98 36.18666666 0l179.4-94.60666667v-10.27333333z" fill="#FFFFFF" ></path><path d="M730.5 167h-427.8v0.46c109.78666667 4.29333333 197.49333333 94.3 197.49333333 205.00666667v336.72h411.39333334c27.29333333 0 49.37333333-22.08 49.37333333-49.22V397c0-126.96-103.19333333-230-230.46-230z" fill="#4E8DF6" ></path><path d="M845.80666667 52H681.12666667c-9.04666667 0-16.40666667 7.36-16.40666667 16.40666667v336.72a24.67133333 24.67133333 0 1 0 49.37333333 0V134.18666667h131.71333334c9.04666667 0 16.40666667-7.36 16.40666666-16.40666667V68.40666667c0-9.04666667-7.36-16.40666667-16.40666666-16.40666667z" fill="#2166CC" ></path><path d="M896.25333333 659.81333333h-35.11333333c-8.43333333 0-15.33333333-6.9-15.33333333-15.33333333v-35.11333333c0-8.43333333 6.9-15.33333333 15.33333333-15.33333334h35.11333333c8.43333333 0 15.33333333 6.9 15.33333334 15.33333334v35.11333333c0 8.58666667-6.9 15.33333333-15.33333334 15.33333333z" fill="#FFFFFF" ></path><path d="M88.8 709.18666667l-24.22666667 131.40666666c-9.66 54.43333333 26.83333333 98.59333333 81.26666667 98.59333334h213.9c54.58666667 0 106.56666667-44.16 116.22666667-98.59333334l23.15333333-131.40666666H88.8z" fill="#2974CE" ></path></symbol><symbol id="icon-gitHub" viewBox="0 0 1049 1024"><path d="M523.6581816 52C262.83923907 52 52 262.8401375 52 523.6581816c0 208.49703047 135.09433812 384.97758117 322.50789391 447.44906532 23.42658172 4.68531653 32.01647887-10.15136894 32.01647796-22.64584583 0-10.93210574-0.78163433-48.41463703-0.78163433-87.45953855-131.18885996 28.11189824-158.5200223-56.22379738-158.52002231-56.22379739-21.08437312-54.66232469-52.3201152-68.71827336-52.3201152-68.71827335-42.94858371-28.89353348 3.12384382-28.89353348 3.12384384-28.89353348 47.63479867 3.12384382 72.62285398 48.41643391 72.62285398 48.4164339 42.16784782 71.84121875 110.10538527 51.53758242 137.43654672 39.04400399 3.90457972-30.45500618 16.3990566-51.5393793 29.67427028-63.25222094-104.64023039-10.93300418-214.74561566-51.53848086-214.74561657-232.70524742 0-51.53848086 18.74126609-93.70632867 48.4164339-126.50444187-4.68621496-11.71284164-21.08527156-60.12837711 4.6844181-124.94207075 0 0 39.82563922-12.49447688 129.62738726 48.41463704 37.48253129-10.15136894 78.08980484-15.61742227 117.91454562-15.61742137s80.43201433 5.46605242 117.91454473 15.61742137c89.80264648-60.90911391 129.62828571-48.41463703 129.62828571-48.41463704 25.76879122 64.81369363 9.37063305 113.22922911 4.68531651 124.94207075 30.45410773 32.79721477 48.41463703 74.96506258 48.41463703 126.50444187 0 181.16676656-110.10538527 220.99150644-215.52545401 232.70524742 17.1797934 14.83668547 32.01647887 42.94858371 32.01647886 87.45953946 0 63.25222094-0.78163433 114.009965-0.78163523 129.62738636 0 12.49447688 8.59079468 27.33116234 32.01737731 22.64584583 187.41265734-62.4705866 322.50699547-238.95203574 322.50699546-447.44996375C995.31636231 262.8401375 783.69369203 52 523.6581816 52z" fill="#663399" ></path><path d="M230.82365863 729.03136735c-0.7807359 2.34310703-4.68531653 3.12384382-7.80916035 1.56237113s-5.46605242-4.68531653-3.90368129-7.02842356c0.7807359-2.34220859 4.68531653-3.12384382 7.80826192-1.56147269s4.68531653 4.68531653 3.90457972 7.02752512z m18.7412661 21.08437312c-2.34220859 2.34220859-7.02752512 0.78163433-9.37063305-2.34310703-3.12294539-3.12294539-3.90457972-7.80826192-1.5614727-10.15136894 2.34220859-2.34220859 6.24678922-0.7807359 9.37063305 2.34310702 3.12384382 3.90457972 3.90457972 8.58899782 1.5614727 10.15136895zM268.30618992 777.44690281c-3.12294539 2.34220859-7.80826192 0-10.15136895-3.90457972-3.12384382-3.90457972-3.12384382-9.37063305 0-10.93210574 3.12384382-2.34310703 7.80916035 0 10.15226739 3.90457972 3.12294539 3.90368129 3.12294539 8.58899782 0 10.93210574z m25.76968965 26.55042555c-2.34220859 3.12294539-7.80916035 2.34220859-12.49447688-1.56237113-3.90457972-3.90368129-5.46605242-9.37063305-2.34220859-11.71284164 2.34220859-3.12384382 7.80826192-2.34310703 12.49447687 1.56147269 3.90368129 3.12384382 4.68531653 8.58989625 2.3422086 11.71374008z m35.1403227 14.83668637c-0.78163433 3.90457972-6.24768766 5.46605242-11.71374008 3.90457972-5.46605242-1.5614727-8.58899782-6.24768766-7.80916036-9.37063305 0.78163433-3.90457972 6.24768766-5.46605242 11.71374009-3.90457972 5.46605242 1.5614727 8.58899782 5.46605242 7.80916035 9.37063305z m38.26416562 3.12384382c0 3.90457972-4.68621496 7.02752512-10.15226738 7.02752512-5.46605242 0-10.15226738-3.12294539-10.15226739-7.02752512s4.68621496-7.02842356 10.15226739-7.02842445c5.46605242 0 10.15226738 3.12384382 10.15226738 7.02842445z m35.92016106-6.24768766c0.78163433 3.90457972-3.12384382 7.80916035-8.58899872 8.58989625-5.46695086 0.78163433-10.15226738-1.5614727-10.93390172-5.46605241-0.77983747-3.90457972 3.12384382-7.80916035 8.5907947-8.58899872 5.46605242-0.78163433 10.15136894 1.56057426 10.93210574 5.46515488z m0 0" fill="#663399" ></path></symbol><symbol id="icon-bilibili" viewBox="0 0 1024 1024"><path d="M832.61667555 181.33447111h-164.32545185l74.45617778-74.45617778c12.84020148-12.84020148 12.84020148-30.8140563 0-43.65425778-12.84020148-12.84020148-30.8140563-12.84020148-43.65425778 0L573.2882963 189.04101925H450.04420741L324.2272237 63.23617185c-10.26730667-12.84020148-25.68040297-15.40096-41.08136295-7.70654815-2.57289482 0-2.57289482 2.57289482-5.13365334 5.13365333-12.84020148 12.84020148-12.84020148 30.8140563 0 43.65425779l77.02907259 77.02907259h-164.32545185c-89.86927408 0-164.32545185 74.45617778-164.32545185 164.32545184v408.24073483c0 87.29637925 74.45617778 161.75255703 164.32545185 161.75255703h25.68040296c0 30.8140563 25.68040297 53.92156445 53.92156444 53.92156444s53.92156445-25.68040297 53.92156445-53.92156444H704.23893333c2.57289482 30.8140563 28.24116148 53.92156445 59.05521778 51.34866964 28.24116148-2.57289482 48.78791111-23.10750815 51.34866964-51.34866964h20.53461333c89.86927408 0 164.32545185-74.45617778 164.32545184-164.32545186V343.09916445c-2.56075852-89.86927408-77.02907259-161.76469333-166.88621037-161.76469334z m-5.13365333 634.19429926H200.99527111c-33.37481482 0-59.05521778-28.24116148-61.61597629-61.61597629l-2.57289482-415.94728297c0-33.37481482 28.24116148-61.6159763 61.6159763-61.61597629h626.48775111c33.37481482 0 59.05521778 28.24116148 61.61597629 61.61597629l2.57289482 415.94728297c-2.57289482 35.93557333-28.24116148 61.6159763-61.6159763 61.61597629z" fill="#ff7299" ></path><path d="M403.82919111 417.55534222l15.40096 77.0290726-205.40681481 38.50846815-15.40096-77.0290726 205.40681481-38.50846815z m197.70026667 77.0290726l15.40096-77.0290726 205.40681481 38.50846815-15.40096 77.0290726-205.40681481-38.50846815z m41.08136297 161.75255703c0 2.57289482 0 7.70654815-2.57289483 10.26730667-12.84020148 28.24116148-41.08136297 46.2150163-74.45617777 48.78791111-20.53461333 0-41.08136297-10.26730667-53.92156445-25.68040296-15.40096 15.40096-33.37481482 25.68040297-53.92156445 25.68040296-30.8140563-2.57289482-59.05521778-20.53461333-74.45617777-48.78791111 0-2.57289482-2.57289482-5.13365333-2.57289481-10.26730667 0-10.26730667 7.70654815-17.97385482 17.97385481-20.53461333h2.57289482c7.70654815 0 12.84020148 2.57289482 15.40096 10.26730666 0 0 20.53461333 28.24116148 38.50846815 28.24116149 35.94770963 0 35.94770963-30.8140563 56.48232296-53.92156445 23.10750815 25.68040297 23.10750815 53.92156445 56.48232296 53.92156445 23.10750815 0 38.50846815-28.24116148 38.50846815-28.24116149 2.57289482-5.13365333 10.26730667-10.26730667 15.40096-10.26730666 10.26730667-2.57289482 17.97385482 5.13365333 20.53461333 15.40096v5.13365333h0.0364089z" fill="#ff7299" ></path></symbol></svg>',o=(o=document.getElementsByTagName("script"))[o.length-1].getAttribute("data-injectcss"),p=function(c,l){l.parentNode.insertBefore(c,l)};if(o&&!c.__iconfont__svg__cssinject__){c.__iconfont__svg__cssinject__=!0;try{document.write("<style>.svgfont {display: inline-block;width: 1em;height: 1em;fill: currentColor;vertical-align: -0.1em;font-size:16px;}</style>")}catch(c){console&&console.log(c)}}function d(){i||(i=!0,a())}function m(){try{t.documentElement.doScroll("left")}catch(c){return void setTimeout(m,50)}d()}l=function(){var c,l=document.createElement("div");l.innerHTML=v,v=null,(l=l.getElementsByTagName("svg")[0])&&(l.setAttribute("aria-hidden","true"),l.style.position="absolute",l.style.width=0,l.style.height=0,l.style.overflow="hidden",l=l,(c=document.body).firstChild?p(l,c.firstChild):c.appendChild(l))},document.addEventListener?~["complete","loaded","interactive"].indexOf(document.readyState)?setTimeout(l,0):(h=function(){document.removeEventListener("DOMContentLoaded",h,!1),l()},document.addEventListener("DOMContentLoaded",h,!1)):document.attachEvent&&(a=l,t=c.document,i=!1,m(),t.onreadystatechange=function(){"complete"==t.readyState&&(t.onreadystatechange=null,d())})}(window);]]></content>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/css/custom.css"/>
      <url>/css/custom.css</url>
      
        <content type="html"><![CDATA[/* @font-face {  font-family: Candyhome;  src: url(https://npm.elemecdn.com/anzhiyu-blog@1.1.6/fonts/Candyhome.ttf);  font-display: swap;  font-weight: lighter;} */@font-face {    font-family: ZhuZiAYuanJWD;    src: url(https://npm.elemecdn.com/anzhiyu-blog@1.1.6/fonts/ZhuZiAWan.woff2);    font-display: swap;    font-weight: lighter;  }    div#menus {    font-family: 'ZhuZiAYuanJWD';  }  h1#site-title {    font-family: ZhuZiAYuanJWD;    font-size: 3em !important;  }  a.article-title,  a.blog-slider__title,  a.categoryBar-list-link,  h1.post-title {    font-family: ZhuZiAYuanJWD;  }    .iconfont {    font-family: 'iconfont' !important;    font-size: 3em;    /* 可以定义图标大小 */    font-style: normal;    -webkit-font-smoothing: antialiased;    -moz-osx-font-smoothing: grayscale;  }    /* 时间轴生肖icon */  svg.icon {    /* 这里定义svg.icon，避免和Butterfly自带的note标签冲突 */    width: 1em;    height: 1em;    /* width和height定义图标的默认宽度和高度*/    vertical-align: -0.15em;    fill: currentColor;    overflow: hidden;  }    .icon-zhongbiao::before {    color: #f7c768;  }    /* bilibli番剧插件 */  .bangumi-active {    background: #dbecfe !important;    border-radius: 10px !important;  }  a.bangumi-tab:hover {    text-decoration: none !important;  }  .bangumi-button:hover {    background: #dbecfe !important;    border-radius: 10px !important;  }  a.bangumi-button.bangumi-nextpage:hover {    text-decoration: none !important;  }  .bangumi-button {    padding: 5px 10px !important;  }    a.bangumi-tab {    padding: 5px 10px !important;  }  svg.icon.faa-tada {    font-size: 1.1em;  }    /* 解决artitalk的图标问题 */  #uploadSource > svg {    width: 1.19em;    height: 1.5em;  }    /*top-img黑色透明玻璃效果移除，不建议加，除非你执着于完全一图流或者背景图对比色明显 */  #page-header:not(.not-top-img):before {    background-color: transparent !important;  }    /* 首页文章卡片 */  #recent-posts > .recent-post-item {    background: rgba(255, 255, 255, 0.9);  }    /* 首页侧栏卡片 */  #aside-content .card-widget {    background: rgba(255, 255, 255, 0.9);  }    /* 文章页面正文背景 */  div#post {    background: rgba(255, 255, 255, 0.9);  }    /* 分页页面 */  div#page {    background: rgba(255, 255, 255, 0.9);  }    /* 归档页面 */  div#archive {    background: rgba(255, 255, 255, 0.9);  }    /* 标签页面 */  div#tag {    background: rgba(255, 255, 255, 0.9);  }    /* 分类页面 */  div#category {    background: rgba(255, 255, 255, 0.9);  }    /*夜间模式伪类遮罩层透明*/  [data-theme='dark'] #recent-posts > .recent-post-item {    background: #121212;  }    [data-theme='dark'] .card-widget {    background: #121212 !important;  }    [data-theme='dark'] div#post {    background: #121212 !important;  }    [data-theme='dark'] div#tag {    background: #121212 !important;  }    [data-theme='dark'] div#archive {    background: #121212 !important;  }    [data-theme='dark'] div#page {    background: #121212 !important;  }    [data-theme='dark'] div#category {    background: #121212 !important;  }    [data-theme='dark'] div#category {    background: transparent !important;  }    /* 页脚透明 -- 不需要一图流 可删除 */  #footer {    background: transparent !important;  }    /* 头图透明 --  不需要一图流 可删除 */  #page-header {    background: transparent !important;  }    #rightside > div > button {    border-radius: 5px;  }    /* 滚动条 */    ::-webkit-scrollbar {    width: 10px;    height: 10px;  }    ::-webkit-scrollbar-thumb {    background-color: #49b1f5;    border-radius: 2em;  }    ::-webkit-scrollbar-corner {    background-color: transparent;  }    ::-moz-selection {    color: #fff;    background-color: #49b1f5;  }    /* 音乐播放器 */    /* .aplayer .aplayer-lrc {    display: none !important;  } */    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {    left: -66px !important;    transition: all 0.3s;    /* 默认情况下缩进左侧66px，只留一点箭头部分 */  }    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {    left: 0 !important;    transition: all 0.3s;    /* 鼠标悬停是左侧缩进归零，完全显示按钮 */  }    .aplayer.aplayer-fixed {    z-index: 999999 !important;  }    /* 评论框  */  .vwrap {    box-shadow: 2px 2px 5px #bbb;    background: rgba(255, 255, 255, 0.3);    border-radius: 8px;    padding: 30px;    margin: 30px 0px 30px 0px;  }    /* 设置评论框 */    .vcard {    box-shadow: 2px 2px 5px #bbb;    background: rgba(255, 255, 255, 0.3);    border-radius: 8px;    padding: 30px;    margin: 30px 0px 0px 0px;  }    /* 鼠标图标 */  body {    cursor: url('/img/x1.cur'), auto;  }  a,  [type='button']:not(:disabled),  [type='reset']:not(:disabled),  [type='submit']:not(:disabled),  button:not(:disabled) {    cursor: url('/img/x2.cur'), auto !important;  }  /* md网站下划线 */  #article-container a:hover {    text-decoration: none !important;  }    #article-container #hpp_talk p img {    display: inline;  }    /* 404页面 */  #error-wrap {    position: absolute;    top: 40%;    right: 0;    left: 0;    margin: 0 auto;    padding: 0 1rem;    max-width: 1000px;    transform: translate(0, -50%);  }    #error-wrap .error-content {    display: flex;    flex-direction: row;    justify-content: center;    align-items: center;    margin: 0 1rem;    height: 18rem;    border-radius: 8px;    background: var(--card-bg);    box-shadow: var(--card-box-shadow);    transition: all 0.3s;  }    #error-wrap .error-content .error-img {    box-flex: 1;    flex: 1;    height: 100%;    border-top-left-radius: 8px;    border-bottom-left-radius: 8px;    background-color: #49b1f5;    background-position: center;    background-size: cover;  }    #error-wrap .error-content .error-info {    box-flex: 1;    flex: 1;    padding: 0.5rem;    text-align: center;    font-size: 14px;    font-family: Titillium Web, 'PingFang SC', 'Hiragino Sans GB', 'Microsoft JhengHei', 'Microsoft YaHei', sans-serif;  }  #error-wrap .error-content .error-info .error_title {    margin-top: -4rem;    font-size: 9em;  }  #error-wrap .error-content .error-info .error_subtitle {    margin-top: -3.5rem;    word-break: break-word;    font-size: 1.6em;  }  #error-wrap .error-content .error-info a {    display: inline-block;    margin-top: 0.5rem;    padding: 0.3rem 1.5rem;    background: var(--btn-bg);    color: var(--btn-color);  }    #body-wrap.error .aside-list {    display: flex;    flex-direction: row;    flex-wrap: nowrap;    bottom: 0px;    position: absolute;    padding: 1rem;    width: 100%;    overflow: scroll;  }    #body-wrap.error .aside-list .aside-list-group {    display: flex;    flex-direction: row;    flex-wrap: nowrap;    max-width: 1200px;    margin: 0 auto;  }    #body-wrap.error .aside-list .aside-list-item {    padding: 0.5rem;  }    #body-wrap.error .aside-list .aside-list-item img {    width: 100%;    object-fit: cover;    border-radius: 12px;  }    #body-wrap.error .aside-list .aside-list-item .thumbnail {    overflow: hidden;    width: 230px;    height: 143px;    background: var(--heo-card-bg);    display: flex;  }    #body-wrap.error .aside-list .aside-list-item .content .title {    -webkit-line-clamp: 2;    overflow: hidden;    display: -webkit-box;    -webkit-box-orient: vertical;    line-height: 1.5;    justify-content: center;    align-items: flex-end;    align-content: center;    padding-top: 0.5rem;    color: white;  }    #body-wrap.error .aside-list .aside-list-item .content time {    display: none;  }    /* 代码框主题 */  #article-container figure.highlight {    border-radius: 10px;  }  ]]></content>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/js/runtime/runtime.min.js"/>
      <url>/js/runtime/runtime.min.js</url>
      
        <content type="html"><![CDATA[var now=new Date;function createtime(){var grt=new Date("09/01/2022 00:00:00");now.setTime(now.getTime()+250);var days=(now-grt)/1e3/60/60/24,dnum=Math.floor(days),hours=(now-grt)/1e3/60/60-24*dnum,hnum=Math.floor(hours);1==String(hnum).length&&(hnum="0"+hnum);var minutes=(now-grt)/1e3/60-1440*dnum-60*hnum,mnum=Math.floor(minutes);1==String(mnum).length&&(mnum="0"+mnum);var seconds=(now-grt)/1e3-86400*dnum-3600*hnum-60*mnum,snum=Math.round(seconds);1==String(snum).length&&(snum="0"+snum);let currentTimeHtml="";currentTimeHtml=hnum<18&&hnum>=9?`<img class='boardsign' src='https://npm.elemecdn.com/anzhiyu-blog@2.0.4/img/badge/安知鱼-上班摸鱼中.svg' title='距离月入25k也就还差一个大佬带我~'><span class='textTip'> <br> 本站居然运行了 ${dnum} 天</span><span id='runtime'> ${hnum} 小时 ${mnum} 分 ${snum} 秒 </span> <i class='fas fa-heartbeat' style='color:red'></i>`:`<img class='boardsign' src='https://npm.elemecdn.com/anzhiyu-blog@2.0.4/img/badge/安知鱼-下班啦.svg' title='下班了就该开开心心的玩耍，嘿嘿~'><span class='textTip'> <br> 本站居然运行了 ${dnum} 天</span><span id='runtime'> ${hnum} 小时 ${mnum} 分 ${snum} 秒 </span> <i class='fas fa-heartbeat' style='color:red'></i>`,document.getElementById("workboard")&&(document.getElementById("workboard").innerHTML=currentTimeHtml)}setInterval(()=>{createtime()},250);]]></content>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/js/runtime/rumtime.js"/>
      <url>/js/runtime/rumtime.js</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
  
</search>
